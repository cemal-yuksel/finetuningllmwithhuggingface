{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5165b6",
   "metadata": {},
   "source": [
    "# ğŸ“ BERT Architecture Deep Dive: Tokenization & Training Fundamentals\n",
    "\n",
    "## ğŸš€ YBS Ã–ÄŸrencileri Ä°Ã§in KapsamlÄ± BERT Ä°Ã§ YapÄ± Rehberi\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white;\">\n",
    "    <h2>ğŸ¯ Bu Notebook'ta Neler Ã–ÄŸreneceÄŸiz?</h2>\n",
    "    <ul style=\"font-size: 16px;\">\n",
    "        <li>âœ… WordPiece tokenization'Ä±n mantÄ±ÄŸÄ± ve neden gerekli olduÄŸu</li>\n",
    "        <li>âœ… BERT'in Ã¶zel token'larÄ± ([CLS], [SEP], [MASK]) ve iÅŸlevleri</li>\n",
    "        <li>âœ… ÃœÃ§ bileÅŸenli embedding sistemi (Token + Segment + Position)</li>\n",
    "        <li>âœ… BaÄŸlamsal (contextual) vs statik embedding farkÄ±</li>\n",
    "        <li>âœ… MLM (Masked Language Modeling) eÄŸitim stratejisi</li>\n",
    "        <li>âœ… NSP (Next Sentence Prediction) ve cÃ¼mle iliÅŸkisi</li>\n",
    "        <li>âœ… Fine-tuning sÃ¼reci ve YBS uygulamalarÄ±</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– Ders NotlarÄ± SÃ¼rÃ¼m Bilgisi\n",
    "- **HazÄ±rlayan:** YBS EÄŸitim Serisi  \n",
    "- **Tarih:** 18 Ocak 2026  \n",
    "- **Seviye:** BaÅŸlangÄ±Ã§ â†’ Ä°leri  \n",
    "- **Tahmini SÃ¼re:** 180 dakika  \n",
    "- **Gereksinimler:** Python 3.8+, transformers kÃ¼tÃ¼phanesi\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ Tek CÃ¼mlelik Ã–zet\n",
    "\n",
    "<div style=\"background-color: #fff3cd; border-left: 5px solid #ffc107; padding: 15px; margin: 20px 0;\">\n",
    "    <p style=\"font-size: 16px; margin: 0;\"><strong>BERT'e metin verince Ã¶nce kelimeler parÃ§alanÄ±r (WordPiece), sonra her parÃ§aya Ã¼Ã§ kimlik eklenir (token+segment+position), sonra Transformer bu giriÅŸten her token iÃ§in baÄŸlam vektÃ¶rÃ¼ Ã¼retir, sonra da ihtiyacÄ±nÄ±za gÃ¶re Ã¼stÃ¼ne bir baÅŸlÄ±k takÄ±p sÄ±nÄ±flandÄ±rma, soru-cevap veya varlÄ±k tanÄ±ma gibi iÅŸleri yaptÄ±rÄ±rsÄ±nÄ±z.</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7aa367",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ ADIM 1: ğŸ”¤ WordPiece Tokenizer - Kelimeleri Neden ParÃ§alÄ±yoruz?\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; border-left: 5px solid #4caf50; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ’¡ Temel Fikir</h3>\n",
    "    <p style=\"font-size: 16px; margin: 0;\"><strong>GÃ¼nlÃ¼k hayatta \"oynamayÄ±\" tek kelime gÃ¶rÃ¼rÃ¼z, ama modelin sÃ¶zlÃ¼ÄŸÃ¼ sÄ±nÄ±rlÄ±dÄ±r!</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36642d",
   "metadata": {},
   "source": [
    "## ğŸ¯ 1.1. Problem: SÄ±nÄ±rsÄ±z Kelime vs SÄ±nÄ±rlÄ± SÃ¶zlÃ¼k\n",
    "\n",
    "Dillerde **sÄ±nÄ±rsÄ±z sayÄ±da kelime** Ã¼retilebilir:\n",
    "- TÃ¼rkÃ§e: \"ev\" â†’ \"evler\", \"evlerde\", \"evlerden\", \"evlerimizdeki\" ...\n",
    "- Ä°ngilizce: \"play\" â†’ \"playing\", \"played\", \"player\", \"replaying\" ...\n",
    "\n",
    "Ancak **BERT'in sÃ¶zlÃ¼ÄŸÃ¼ sÄ±nÄ±rlÄ±:**\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  BERT Vocabulary Size â‰ˆ 30,000 tokens  â”‚\n",
    "â”‚  Dildeki Kelime SayÄ±sÄ± â‰ˆ âˆ (sonsuz!)   â”‚\n",
    "â”‚  âŒ HER KELÄ°MEYÄ° KOYMAK Ä°MKANSIZ!       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab96987d",
   "metadata": {},
   "source": [
    "## ğŸ’¡ 1.2. Ã‡Ã¶zÃ¼m: WordPiece Tokenization\n",
    "\n",
    "**WordPiece** kelimeleri **daha kÃ¼Ã§Ã¼k anlamlÄ± parÃ§alara** bÃ¶ler:\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"playing\"] -->|WordPiece| B[\"play\"]\n",
    "    A -->|WordPiece| C[\"##ing\"]\n",
    "    \n",
    "    style A fill:#ffccbc,stroke:#ff5722,stroke-width:3px\n",
    "    style B fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style C fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "```\n",
    "\n",
    "### ğŸ“ TÃ¼rkÃ§e Ã–rnekler:\n",
    "\n",
    "| ğŸ”¤ Orijinal Kelime | âœ‚ï¸ WordPiece ParÃ§alarÄ± | ğŸ’¬ AÃ§Ä±klama |\n",
    "|-------------------|------------------------|-------------|\n",
    "| **kitaplÄ±k** | `[\"kitap\", \"##lÄ±k\"]` | kÃ¶k + ek |\n",
    "| **oyuncak** | `[\"oyun\", \"##cak\"]` | kÃ¶k + ek |\n",
    "| **evlerden** | `[\"ev\", \"##ler\", \"##den\"]` | kÃ¶k + Ã§oÄŸul + hal eki |\n",
    "| **oynamayÄ±** | `[\"oyun\", \"##ma\", \"##yÄ±\"]` | kÃ¶k + fiilimsi + belirtme hali |\n",
    "\n",
    "### ğŸ“ Ä°ngilizce Ã–rnekler:\n",
    "\n",
    "| ğŸ”¤ Orijinal Kelime | âœ‚ï¸ WordPiece ParÃ§alarÄ± | ğŸ’¬ AÃ§Ä±klama |\n",
    "|-------------------|------------------------|-------------|\n",
    "| **playing** | `[\"play\", \"##ing\"]` | root + suffix |\n",
    "| **unbelievable** | `[\"un\", \"##believable\"]` veya `[\"un\", \"##believ\", \"##able\"]` | prefix + root + suffix |\n",
    "| **reproduction** | `[\"re\", \"##production\"]` | prefix + root |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071eedf3",
   "metadata": {},
   "source": [
    "## ğŸ” 1.3. \"##\" Ä°ÅŸaretinin AnlamÄ±\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; border-left: 5px solid #2196f3; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>âš¡ Kritik Bilgi</h3>\n",
    "    <p style=\"font-size: 15px;\"><strong>\"##\" iÅŸareti</strong> â†’ \"Bu token bir kelimenin <strong>devamÄ±dÄ±r</strong>, baÅŸlangÄ±Ã§ deÄŸil!\"</p>\n",
    "    <ul>\n",
    "        <li>âœ… \"play\" â†’ Kelimenin baÅŸlangÄ±cÄ± (## YOK)</li>\n",
    "        <li>âœ… \"##ing\" â†’ Kelimenin devamÄ± (## VAR)</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"Kelime: playing\"] --> B{\"ParÃ§alanma\"}\n",
    "    B -->|BaÅŸlangÄ±Ã§| C[\"play\"]\n",
    "    B -->|Devam| D[\"##ing\"]\n",
    "    \n",
    "    C --> E[\"âœ… Kelime baÅŸÄ±<br/>## iÅŸareti YOK\"]\n",
    "    D --> F[\"âœ… Kelime devamÄ±<br/>## iÅŸareti VAR\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style C fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style D fill:#b3e5fc,stroke:#0288d1,stroke-width:2px\n",
    "    style E fill:#dcedc8,stroke:#689f38,stroke-width:2px\n",
    "    style F fill:#b2ebf2,stroke:#0097a7,stroke-width:2px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ab357",
   "metadata": {},
   "source": [
    "## ğŸ 1.4. WordPiece'in AvantajlarÄ±\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 20px; border-radius: 10px; color: white; margin: 20px 0;\">\n",
    "    <h3>ğŸš€ Neden WordPiece KullanÄ±yoruz?</h3>\n",
    "    <table style=\"width: 100%; color: white; font-size: 15px; border-collapse: collapse;\">\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-bottom: 1px solid rgba(255,255,255,0.3);\"><strong>1ï¸âƒ£ KÃ¼Ã§Ã¼k SÃ¶zlÃ¼k</strong></td>\n",
    "            <td style=\"padding: 10px; border-bottom: 1px solid rgba(255,255,255,0.3);\">30 bin token ile milyonlarca kelimeyi temsil eder</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-bottom: 1px solid rgba(255,255,255,0.3);\"><strong>2ï¸âƒ£ OOV Sorunu Ã‡Ã¶zÃ¼mÃ¼</strong></td>\n",
    "            <td style=\"padding: 10px; border-bottom: 1px solid rgba(255,255,255,0.3);\">HiÃ§ gÃ¶rÃ¼lmemiÅŸ kelimeler bile parÃ§alara bÃ¶lÃ¼nÃ¼r (Out-of-Vocabulary yok)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; border-bottom: 1px solid rgba(255,255,255,0.3);\"><strong>3ï¸âƒ£ Ek TanÄ±ma</strong></td>\n",
    "            <td style=\"padding: 10px; border-bottom: 1px solid rgba(255,255,255,0.3);\">\"-lÄ±k\", \"-den\", \"-ing\" gibi ekleri Ã¶ÄŸrenir ve yeniden kullanÄ±r</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px;\"><strong>4ï¸âƒ£ Tahmin GÃ¼cÃ¼</strong></td>\n",
    "            <td style=\"padding: 10px;\">Yeni kelimeler bile parÃ§alarÄ±ndan anlamlandÄ±rÄ±labilir</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d7ff0",
   "metadata": {},
   "source": [
    "## ğŸ’» 1.5. Pratik Ã–rnek: WordPiece'i GÃ¶zlemleyelim\n",
    "\n",
    "Åimdi gerÃ§ek bir BERT tokenizer ile WordPiece tokenization'Ä± gÃ¶relim!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e949ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Gerekli kÃ¼tÃ¼phaneleri yÃ¼kle\n",
    "!pip install transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7323334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69ccda8308949fc8cca730478d5c022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be88f4f7a3d749309eab4f87ce695e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cc4986bf3f41218bf2d52dcb69355c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c830138310e41d79f22c8153a4209f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ BERT WordPiece Tokenization Demo\n",
      "======================================================================\n",
      "ğŸ“š SÃ¶zlÃ¼k boyutu: 30522 token\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# BERT tokenizer'Ä± yÃ¼kle (Ä°ngilizce, kÃ¼Ã§Ã¼k harf)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"ğŸ¯ BERT WordPiece Tokenization Demo\")\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“š SÃ¶zlÃ¼k boyutu:\", len(tokenizer.vocab), \"token\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbbedc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Ã–RNEK 1: Basit Kelime\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ”¤ Orijinal : 'playing'\n",
      "âœ‚ï¸  Token'lar: ['playing']\n",
      "ğŸ’¡ AÃ§Ä±klama : 'playing' kelimesi 1 parÃ§aya bÃ¶lÃ¼ndÃ¼\n",
      "             â†³ 'play' = kÃ¶k kelime (## YOK)\n",
      "             â†³ '##ing' = ek (## VAR, devamÄ± gÃ¶sterir)\n"
     ]
    }
   ],
   "source": [
    "# Ã–rnek 1: Basit kelime\n",
    "text1 = \"playing\"\n",
    "tokens1 = tokenizer.tokenize(text1)\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ“ Ã–RNEK 1: Basit Kelime\")\n",
    "print(\"â”€\"*70)\n",
    "print(f\"ğŸ”¤ Orijinal : '{text1}'\")\n",
    "print(f\"âœ‚ï¸  Token'lar: {tokens1}\")\n",
    "print(f\"ğŸ’¡ AÃ§Ä±klama : '{text1}' kelimesi {len(tokens1)} parÃ§aya bÃ¶lÃ¼ndÃ¼\")\n",
    "print(f\"             â†³ 'play' = kÃ¶k kelime (## YOK)\")\n",
    "print(f\"             â†³ '##ing' = ek (## VAR, devamÄ± gÃ¶sterir)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf02c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Ã–RNEK 2: KarmaÅŸÄ±k Kelime\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ”¤ Orijinal : 'unbelievable'\n",
      "âœ‚ï¸  Token'lar: ['unbelievable']\n",
      "ğŸ’¡ AÃ§Ä±klama : 'unbelievable' kelimesi 1 parÃ§aya bÃ¶lÃ¼ndÃ¼\n"
     ]
    }
   ],
   "source": [
    "# Ã–rnek 2: Daha karmaÅŸÄ±k kelime\n",
    "text2 = \"unbelievable\"\n",
    "tokens2 = tokenizer.tokenize(text2)\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ“ Ã–RNEK 2: KarmaÅŸÄ±k Kelime\")\n",
    "print(\"â”€\"*70)\n",
    "print(f\"ğŸ”¤ Orijinal : '{text2}'\")\n",
    "print(f\"âœ‚ï¸  Token'lar: {tokens2}\")\n",
    "print(f\"ğŸ’¡ AÃ§Ä±klama : '{text2}' kelimesi {len(tokens2)} parÃ§aya bÃ¶lÃ¼ndÃ¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e4aad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Ã–RNEK 3: Tam CÃ¼mle\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ”¤ Orijinal : 'The playing children were unbelievable.'\n",
      "âœ‚ï¸  Token'lar: ['the', 'playing', 'children', 'were', 'unbelievable', '.']\n",
      "ğŸ’¡ Toplam   : 6 token\n",
      "\n",
      "ğŸ” Token Analizi:\n",
      "    1. 'the            ' â† Kelime baÅŸÄ± (## yok)\n",
      "    2. 'playing        ' â† Kelime baÅŸÄ± (## yok)\n",
      "    3. 'children       ' â† Kelime baÅŸÄ± (## yok)\n",
      "    4. 'were           ' â† Kelime baÅŸÄ± (## yok)\n",
      "    5. 'unbelievable   ' â† Kelime baÅŸÄ± (## yok)\n",
      "    6. '.              ' â† Kelime baÅŸÄ± (## yok)\n"
     ]
    }
   ],
   "source": [
    "# Ã–rnek 3: Tam cÃ¼mle\n",
    "text3 = \"The playing children were unbelievable.\"\n",
    "tokens3 = tokenizer.tokenize(text3)\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ“ Ã–RNEK 3: Tam CÃ¼mle\")\n",
    "print(\"â”€\"*70)\n",
    "print(f\"ğŸ”¤ Orijinal : '{text3}'\")\n",
    "print(f\"âœ‚ï¸  Token'lar: {tokens3}\")\n",
    "print(f\"ğŸ’¡ Toplam   : {len(tokens3)} token\")\n",
    "print(\"\\nğŸ” Token Analizi:\")\n",
    "for i, token in enumerate(tokens3, 1):\n",
    "    if token.startswith(\"##\"):\n",
    "        print(f\"   {i:2d}. '{token:15s}' â† Ek/devam (## var)\")\n",
    "    else:\n",
    "        print(f\"   {i:2d}. '{token:15s}' â† Kelime baÅŸÄ± (## yok)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66a7b3",
   "metadata": {},
   "source": [
    "## ğŸ¢ 1.6. YBS Perspektifinden: E-Ticaret MÃ¼ÅŸteri YorumlarÄ±\n",
    "\n",
    "<div style=\"background-color: #f3e5f5; border-left: 5px solid #9c27b0; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“Š GerÃ§ek DÃ¼nya Senaryosu</h3>\n",
    "    <p style=\"font-size: 15px;\"><strong>Durum:</strong> Bir e-ticaret platformunda mÃ¼ÅŸteri yorumlarÄ±nÄ± analiz ediyorsunuz.</p>\n",
    "    <p style=\"font-size: 15px;\"><strong>Zorluk:</strong> Yorumlarda sÃ¼rekli yeni kelime tÃ¼revleri oluÅŸuyor!</p>\n",
    "</div>\n",
    "\n",
    "**SÄ±k KarÅŸÄ±laÅŸÄ±lan Kelime Aileleri:**\n",
    "- ğŸ“¦ **Teslimat:** \"hÄ±zlÄ±\", \"hÄ±zlÄ±ca\", \"hÄ±zlandÄ±rma\", \"hÄ±zlÄ±ydÄ±\"\n",
    "- â­ **Kalite:** \"kalite\", \"kaliteli\", \"kalitesiz\", \"kalitesizlik\"\n",
    "- ğŸ˜Š **Memnuniyet:** \"memnun\", \"memnuniyet\", \"memnuniyetsizlik\"\n",
    "\n",
    "**WordPiece ile Ã‡Ã¶zÃ¼m:**\n",
    "```\n",
    "âœ… Her kelimeyi ayrÄ± sÃ¶zlÃ¼ÄŸe koymaya gerek YOK!\n",
    "âœ… KÃ¶k kelimeler + ekler = Daha kÃ¼Ã§Ã¼k sÃ¶zlÃ¼k\n",
    "âœ… SonuÃ§: Daha hÄ±zlÄ± eÄŸitim, daha az bellek!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37232edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ›’ YBS E-TÄ°CARET YORUM ANALÄ°ZÄ°\n",
      "======================================================================\n",
      "\n",
      "pozitif ğŸ˜Š Yorum 1:\n",
      "â”œâ”€ ğŸ“ Metin    : ÃœrÃ¼n Ã§ok kaliteli ve hÄ±zlÄ± geldi.\n",
      "â”œâ”€ ğŸ·ï¸  Kategori: Kalite & Teslimat\n",
      "â”œâ”€ ğŸ”¢ Token    : 16 adet\n",
      "â””â”€ âœ‚ï¸  Ä°lk 5   : ['ur', '##un', 'co', '##k', 'kali']...\n",
      "\n",
      "negatif ğŸ˜ Yorum 2:\n",
      "â”œâ”€ ğŸ“ Metin    : Kalitenin Ã§ok dÃ¼ÅŸÃ¼k olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum.\n",
      "â”œâ”€ ğŸ·ï¸  Kategori: Kalite Åikayeti\n",
      "â”œâ”€ ğŸ”¢ Token    : 17 adet\n",
      "â””â”€ âœ‚ï¸  Ä°lk 5   : ['kali', '##ten', '##in', 'co', '##k']...\n",
      "\n",
      "pozitif ğŸ˜Š Yorum 3:\n",
      "â”œâ”€ ğŸ“ Metin    : Memnuniyetimizi belirtmek isteriz.\n",
      "â”œâ”€ ğŸ·ï¸  Kategori: Genel Memnuniyet\n",
      "â”œâ”€ ğŸ”¢ Token    : 16 adet\n",
      "â””â”€ âœ‚ï¸  Ä°lk 5   : ['me', '##m', '##nu', '##ni', '##ye']...\n",
      "\n",
      "Ã¶neri ğŸ’¡ Yorum 4:\n",
      "â”œâ”€ ğŸ“ Metin    : Teslimat hÄ±zlandÄ±rÄ±lmalÄ± ve kalite artÄ±rÄ±lmalÄ±.\n",
      "â”œâ”€ ğŸ·ï¸  Kategori: Ä°yileÅŸtirme Ã–nerisi\n",
      "â”œâ”€ ğŸ”¢ Token    : 25 adet\n",
      "â””â”€ âœ‚ï¸  Ä°lk 5   : ['te', '##sl', '##ima', '##t', 'h']...\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¢ YBS Ã–rneÄŸi: E-Ticaret Yorum Analizi\n",
    "\n",
    "ybs_yorumlar = [\n",
    "    {\n",
    "        \"yorum\": \"ÃœrÃ¼n Ã§ok kaliteli ve hÄ±zlÄ± geldi.\",\n",
    "        \"duygu\": \"pozitif ğŸ˜Š\",\n",
    "        \"kategori\": \"Kalite & Teslimat\"\n",
    "    },\n",
    "    {\n",
    "        \"yorum\": \"Kalitenin Ã§ok dÃ¼ÅŸÃ¼k olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum.\",\n",
    "        \"duygu\": \"negatif ğŸ˜\",\n",
    "        \"kategori\": \"Kalite Åikayeti\"\n",
    "    },\n",
    "    {\n",
    "        \"yorum\": \"Memnuniyetimizi belirtmek isteriz.\",\n",
    "        \"duygu\": \"pozitif ğŸ˜Š\",\n",
    "        \"kategori\": \"Genel Memnuniyet\"\n",
    "    },\n",
    "    {\n",
    "        \"yorum\": \"Teslimat hÄ±zlandÄ±rÄ±lmalÄ± ve kalite artÄ±rÄ±lmalÄ±.\",\n",
    "        \"duygu\": \"Ã¶neri ğŸ’¡\",\n",
    "        \"kategori\": \"Ä°yileÅŸtirme Ã–nerisi\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ›’ YBS E-TÄ°CARET YORUM ANALÄ°ZÄ°\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, veri in enumerate(ybs_yorumlar, 1):\n",
    "    yorum = veri[\"yorum\"]\n",
    "    tokens = tokenizer.tokenize(yorum.lower())  # TÃ¼rkÃ§e desteÄŸi sÄ±nÄ±rlÄ± ama mantÄ±ÄŸÄ± gÃ¶sterir\n",
    "    \n",
    "    print(f\"\\n{veri['duygu']} Yorum {i}:\")\n",
    "    print(f\"â”œâ”€ ğŸ“ Metin    : {yorum}\")\n",
    "    print(f\"â”œâ”€ ğŸ·ï¸  Kategori: {veri['kategori']}\")\n",
    "    print(f\"â”œâ”€ ğŸ”¢ Token    : {len(tokens)} adet\")\n",
    "    print(f\"â””â”€ âœ‚ï¸  Ä°lk 5   : {tokens[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9492da79",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 1.8. Ã–zet Diyagram\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ”¤ Kelime: oynamayÄ±\"] --> B{\"â“ Problem\"}\n",
    "    B --> C[\"âŒ SÃ¶zlÃ¼ÄŸe tÃ¼m tÃ¼revleri<br/>koyamayÄ±z\"]\n",
    "    C --> D[\"ğŸ’¡ Ã‡Ã¶zÃ¼m: WordPiece\"]\n",
    "    D --> E[\"âœ‚ï¸ ParÃ§ala\"]\n",
    "    E --> F[\"oyun\"]\n",
    "    E --> G[\"##ma\"]\n",
    "    E --> H[\"##yÄ±\"]\n",
    "    \n",
    "    F --> I[\"âœ… 30k sÃ¶zlÃ¼kle<br/>milyonlarca kelime\"]\n",
    "    G --> I\n",
    "    H --> I\n",
    "    \n",
    "    style A fill:#ffccbc,stroke:#ff5722,stroke-width:3px\n",
    "    style C fill:#ffcdd2,stroke:#f44336,stroke-width:2px\n",
    "    style D fill:#fff9c4,stroke:#fbc02d,stroke-width:3px\n",
    "    style F fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style G fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style H fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style I fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; padding: 20px; border-radius: 10px; border: 2px solid #4caf50;\">\n",
    "    <h3>âœ… ADIM 1 TamamlandÄ±!</h3>\n",
    "    <p style=\"font-size: 15px; margin-bottom: 0;\">WordPiece tokenization'Ä±n mantÄ±ÄŸÄ±nÄ± ve ## iÅŸaretinin anlamÄ±nÄ± Ã¶ÄŸrendik. Åimdi BERT'in Ã¶zel token'larÄ±na ([CLS], [SEP]) geÃ§ebiliriz!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed11764",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ ADIM 2: ğŸ·ï¸ Ã–zel Tokenlar - [CLS], [SEP] ve Ä°ki CÃ¼mle GiriÅŸi\n",
    "\n",
    "<div style=\"background-color: #fff3cd; border-left: 5px solid #ffc107; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ’¡ Temel Fikir</h3>\n",
    "    <p style=\"font-size: 16px; margin: 0;\"><strong>BERT iki cÃ¼mleyi birden iÅŸleyebilir ve her cÃ¼mleyi Ã¶zel token'larla iÅŸaretler!</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d659f6e",
   "metadata": {},
   "source": [
    "## ğŸ¯ 2.1. BERT'in Ã–zel Token'larÄ±\n",
    "\n",
    "BERT giriÅŸlerinde **Ã¼Ã§ Ã¶zel token** kullanÄ±r:\n",
    "\n",
    "| ğŸ·ï¸ Token | ğŸ“› Ä°sim | ğŸ¯ KullanÄ±m AmacÄ± | ğŸ“ Konumu |\n",
    "|----------|---------|-------------------|-----------|\n",
    "| **[CLS]** | Classification | TÃ¼m giriÅŸin Ã¶zet temsilini tutar | En baÅŸta (her zaman) |\n",
    "| **[SEP]** | Separator | CÃ¼mleleri ayÄ±rÄ±r | Her cÃ¼mle sonunda |\n",
    "| **[MASK]** | Mask | EÄŸitim sÄ±rasÄ±nda gizlenen kelimeler | Rastgele pozisyonlarda (MLM iÃ§in) |\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"[CLS]\"] --> B[\"CÃ¼mle A token'larÄ±\"]\n",
    "    B --> C[\"[SEP]\"]\n",
    "    C --> D[\"CÃ¼mle B token'larÄ±\"]\n",
    "    D --> E[\"[SEP]\"]\n",
    "    \n",
    "    style A fill:#ffccbc,stroke:#ff5722,stroke-width:3px\n",
    "    style C fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style E fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style B fill:#e1bee7,stroke:#9c27b0,stroke-width:2px\n",
    "    style D fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b84eb",
   "metadata": {},
   "source": [
    "## ğŸ” 2.2. [CLS] Token: Ã–zet DÃ¼ÄŸmesi\n",
    "\n",
    "<div style=\"background-color: #ffebee; border-left: 5px solid #f44336; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>âš¡ Kritik Kavram: [CLS] = \"Classification\" Token'Ä±</h3>\n",
    "    <p style=\"font-size: 15px;\"><strong>[CLS]</strong> token'Ä± her giriÅŸin en baÅŸÄ±nda olur ve <strong>tÃ¼m cÃ¼mlenin/cÃ¼mlelerin Ã¶zetini</strong> taÅŸÄ±r.</p>\n",
    "    <ul style=\"font-size: 15px;\">\n",
    "        <li>ğŸ¯ Her BERT giriÅŸi <strong>[CLS]</strong> ile baÅŸlar</li>\n",
    "        <li>ğŸ“Š BERT iÅŸlemi bittiÄŸinde, [CLS] pozisyonundaki Ã§Ä±ktÄ± vektÃ¶rÃ¼ <strong>\"tÃ¼m giriÅŸin Ã¶zeti\"</strong> olur</li>\n",
    "        <li>ğŸ”§ SÄ±nÄ±flandÄ±rma gÃ¶revlerinde genellikle bu vektÃ¶r kullanÄ±lÄ±r</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### ğŸ’¡ [CLS] Token'Ä±nÄ± DÃ¼ÄŸmeye Benzetin:\n",
    "\n",
    "Bir uzaktan kumandadaki **\"Ã–zet\"** dÃ¼ÄŸmesi gibi dÃ¼ÅŸÃ¼nÃ¼n:\n",
    "- Kumanda = BERT modeli\n",
    "- TÃ¼m butonlar = TÃ¼m token'lar\n",
    "- **[CLS] dÃ¼ÄŸmesi** = BasÄ±ldÄ±ÄŸÄ±nda tÃ¼m durumun Ã¶zetini verir\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ¬ [CLS]<br/>Ã–zet DÃ¼ÄŸmesi\"] --> B[\"CÃ¼mle 1:<br/>KÃ¶peÄŸim Ã§ok tatlÄ±\"]\n",
    "    A --> C[\"CÃ¼mle 2:<br/>OynamayÄ± seviyor\"]\n",
    "    \n",
    "    B --> D[\"BERT Ä°ÅŸleme\"]\n",
    "    C --> D\n",
    "    \n",
    "    D --> E[\"[CLS] Ã§Ä±ktÄ± vektÃ¶rÃ¼\"]\n",
    "    E --> F[\"ğŸ“‹ TÃ¼m giriÅŸin Ã¶zeti<br/>(SÄ±nÄ±flandÄ±rma iÃ§in kullan)\"]\n",
    "    \n",
    "    style A fill:#ffccbc,stroke:#ff5722,stroke-width:4px\n",
    "    style E fill:#fff9c4,stroke:#fbc02d,stroke-width:3px\n",
    "    style F fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style D fill:#e1bee7,stroke:#9c27b0,stroke-width:2px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb5640",
   "metadata": {},
   "source": [
    "## ğŸ” 2.3. [SEP] Token: SÄ±nÄ±r Ã‡izgisi\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; border-left: 5px solid #4caf50; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>âš¡ Kritik Kavram: [SEP] = \"Separator\" Token'Ä±</h3>\n",
    "    <p style=\"font-size: 15px;\"><strong>[SEP]</strong> token'Ä± cÃ¼mleleri birbirinden ayÄ±rÄ±r.</p>\n",
    "    <ul style=\"font-size: 15px;\">\n",
    "        <li>ğŸ”¹ Her cÃ¼mle sonunda <strong>[SEP]</strong> koyulur</li>\n",
    "        <li>ğŸ”¹ \"Burada cÃ¼mle bitti, diÄŸeri baÅŸlÄ±yor\" sinyali verir</li>\n",
    "        <li>ğŸ”¹ Model bu sayede hangi token'Ä±n hangi cÃ¼mleye ait olduÄŸunu bilir</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### ğŸ“ [SEP] Token'Ä±nÄ± Duvara Benzetin:\n",
    "\n",
    "Ä°ki oda arasÄ±ndaki **duvar** gibi dÃ¼ÅŸÃ¼nÃ¼n:\n",
    "- Oda 1 = CÃ¼mle A\n",
    "- Duvar = [SEP]\n",
    "- Oda 2 = CÃ¼mle B\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"CÃ¼mle A:<br/>KÃ¶peÄŸim Ã§ok tatlÄ±\"] --> B[\"[SEP]<br/>â”â”â”â”â”â”â”\"]\n",
    "    B --> C[\"CÃ¼mle B:<br/>OynamayÄ± seviyor\"]\n",
    "    C --> D[\"[SEP]<br/>â”â”â”â”â”â”â”\"]\n",
    "    \n",
    "    style A fill:#e1bee7,stroke:#9c27b0,stroke-width:2px\n",
    "    style B fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style C fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style D fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8170b25d",
   "metadata": {},
   "source": [
    "## ğŸ’» 2.4. Pratik Ã–rnek: Ä°ki CÃ¼mle BERT'e NasÄ±l Veriliyor?\n",
    "\n",
    "Åimdi gerÃ§ek bir Ã¶rnekle gÃ¶relim!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789777ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ¯ Ä°KÄ° CÃœMLE BERT GÄ°RÄ°ÅÄ°\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ CÃ¼mle A: KÃ¶peÄŸim Ã§ok tatlÄ±.\n",
      "ğŸ“ CÃ¼mle B: OynamayÄ± seviyor.\n",
      "\n",
      "ğŸ¤– BERT'e verilen format:\n",
      "   [CLS] KÃ¶peÄŸim Ã§ok tatlÄ±. [SEP] OynamayÄ± seviyor. [SEP]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š Token YapÄ±sÄ±:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   [CLS]              â† Ã–zet dÃ¼ÄŸmesi (en baÅŸta)\n",
      "   KÃ¶peÄŸim Ã§ok tatlÄ±. â† CÃ¼mle A\n",
      "   [SEP]              â† AyraÃ§ (CÃ¼mle A bitti)\n",
      "   OynamayÄ± seviyor.  â† CÃ¼mle B\n",
      "   [SEP]              â† AyraÃ§ (CÃ¼mle B bitti)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ Ä°ki cÃ¼mleyi BERT formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme\n",
    "\n",
    "cumle_a = \"KÃ¶peÄŸim Ã§ok tatlÄ±.\"\n",
    "cumle_b = \"OynamayÄ± seviyor.\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ¯ Ä°KÄ° CÃœMLE BERT GÄ°RÄ°ÅÄ°\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nğŸ“ CÃ¼mle A: {cumle_a}\")\n",
    "print(f\"ğŸ“ CÃ¼mle B: {cumle_b}\")\n",
    "\n",
    "# BERT'e verilecek format\n",
    "bert_format = f\"[CLS] {cumle_a} [SEP] {cumle_b} [SEP]\"\n",
    "\n",
    "print(f\"\\nğŸ¤– BERT'e verilen format:\")\n",
    "print(f\"   {bert_format}\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"ğŸ“Š Token YapÄ±sÄ±:\")\n",
    "print(\"â”€\" * 70)\n",
    "print(\"   [CLS]              â† Ã–zet dÃ¼ÄŸmesi (en baÅŸta)\")\n",
    "print(\"   KÃ¶peÄŸim Ã§ok tatlÄ±. â† CÃ¼mle A\")\n",
    "print(\"   [SEP]              â† AyraÃ§ (CÃ¼mle A bitti)\")\n",
    "print(\"   OynamayÄ± seviyor.  â† CÃ¼mle B\")\n",
    "print(\"   [SEP]              â† AyraÃ§ (CÃ¼mle B bitti)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b66ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”¬ BERT TOKENIZER ANALÄ°ZÄ°\n",
      "======================================================================\n",
      "\n",
      "âœ‚ï¸ Token'lar:\n",
      "    0. [CLS]           â† ğŸ¬ Ã–zet dÃ¼ÄŸmesi\n",
      "    1. my             \n",
      "    2. dog            \n",
      "    3. is             \n",
      "    4. cute           \n",
      "    5. .              \n",
      "    6. [SEP]           â† ğŸ”¹ AyraÃ§\n",
      "    7. he             \n",
      "    8. loves          \n",
      "    9. playing        \n",
      "   10. .              \n",
      "   11. [SEP]           â† ğŸ”¹ AyraÃ§\n",
      "\n",
      "ğŸ“Š Toplam token sayÄ±sÄ±: 12\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¬ GerÃ§ek BERT tokenizer ile test edelim\n",
    "\n",
    "sentence_a = \"My dog is cute.\"\n",
    "sentence_b = \"He loves playing.\"\n",
    "\n",
    "# Encode ile tÃ¼m sÃ¼reci otomatik yapalÄ±m\n",
    "encoding = tokenizer.encode_plus(\n",
    "    sentence_a,\n",
    "    sentence_b,\n",
    "    add_special_tokens=True,  # [CLS] ve [SEP] ekle\n",
    "    return_tensors=None\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ”¬ BERT TOKENIZER ANALÄ°ZÄ°\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Token'larÄ± gÃ¶relim\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n",
    "print(f\"\\nâœ‚ï¸ Token'lar:\")\n",
    "for i, token in enumerate(tokens):\n",
    "    if token == '[CLS]':\n",
    "        print(f\"   {i:2d}. {token:15s} â† ğŸ¬ Ã–zet dÃ¼ÄŸmesi\")\n",
    "    elif token == '[SEP]':\n",
    "        print(f\"   {i:2d}. {token:15s} â† ğŸ”¹ AyraÃ§\")\n",
    "    else:\n",
    "        print(f\"   {i:2d}. {token:15s}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Toplam token sayÄ±sÄ±: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8841c",
   "metadata": {},
   "source": [
    "## ğŸ¢ 2.5. YBS Perspektifinden: E-Ticaret Ä°liÅŸki Analizi\n",
    "\n",
    "<div style=\"background-color: #f3e5f5; border-left: 5px solid #9c27b0; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“Š GerÃ§ek DÃ¼nya Senaryosu</h3>\n",
    "    <p style=\"font-size: 15px;\"><strong>Problem:</strong> Bir e-ticaret sisteminde iki metin arasÄ±ndaki iliÅŸkiyi Ã¶lÃ§mek istiyorsunuz.</p>\n",
    "    <p style=\"font-size: 15px;\"><strong>AmaÃ§:</strong> Ä°ki metin birbirleriyle iliÅŸkili mi deÄŸil mi?</p>\n",
    "</div>\n",
    "\n",
    "### ğŸ’¼ Ã–rnek Senaryolar:\n",
    "\n",
    "#### âœ… Senaryo 1: Ä°liÅŸkili Metinler\n",
    "- **CÃ¼mle A:** \"Bu Ã¼rÃ¼nÃ¼n kargosu gecikti.\"\n",
    "- **CÃ¼mle B:** \"MÃ¼ÅŸteri iade talebi oluÅŸturdu.\"\n",
    "- **Ä°liÅŸki:** âœ… EVET (Kargo gecikmesi â†’ Ä°ade talebi mantÄ±klÄ±)\n",
    "\n",
    "#### âŒ Senaryo 2: Ä°liÅŸkisiz Metinler\n",
    "- **CÃ¼mle A:** \"Bu Ã¼rÃ¼nÃ¼n kargosu gecikti.\"\n",
    "- **CÃ¼mle B:** \"BugÃ¼n kampÃ¼ste hava yaÄŸmurlu.\"\n",
    "- **Ä°liÅŸki:** âŒ HAYIR (Ä°ki cÃ¼mle alakasÄ±z)\n",
    "\n",
    "### ğŸ¤– BERT'e NasÄ±l Veriliriz?\n",
    "\n",
    "```\n",
    "[CLS] Bu Ã¼rÃ¼nÃ¼n kargosu gecikti. [SEP] MÃ¼ÅŸteri iade talebi oluÅŸturdu. [SEP]\n",
    "```\n",
    "\n",
    "BERT bu giriÅŸi iÅŸledikten sonra **[CLS]** pozisyonundaki Ã§Ä±ktÄ±ya bakarak:\n",
    "- 1 = Ä°liÅŸkili\n",
    "- 0 = Ä°liÅŸkisiz\n",
    "\n",
    "diye sÄ±nÄ±flandÄ±rma yapabilir!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd4082af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¢ YBS E-TÄ°CARET METÄ°N Ä°LÄ°ÅKÄ°SÄ° ANALÄ°ZÄ°\n",
      "======================================================================\n",
      "\n",
      "ğŸŸ¢ Ã–RNEK 1: âœ… Ä°liÅŸkili\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ CÃ¼mle A: Bu Ã¼rÃ¼nÃ¼n kargosu gecikti.\n",
      "ğŸ“ CÃ¼mle B: MÃ¼ÅŸteri iade talebi oluÅŸturdu.\n",
      "\n",
      "ğŸ¤– BERT GiriÅŸi:\n",
      "   [CLS] Bu Ã¼rÃ¼nÃ¼n kargosu gecikti. [SEP] MÃ¼ÅŸteri iade talebi oluÅŸturdu. [SEP]\n",
      "\n",
      "ğŸ¯ Beklenen Ã‡Ä±ktÄ± ([CLS] vektÃ¶rÃ¼nden): 1\n",
      "   â†³ 1 = Ä°liÅŸkili, 0 = Ä°liÅŸkisiz\n",
      "\n",
      "ğŸŸ¢ Ã–RNEK 2: âœ… Ä°liÅŸkili\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ CÃ¼mle A: ÃœrÃ¼n hasarlÄ± geldi.\n",
      "ğŸ“ CÃ¼mle B: MÃ¼ÅŸteri fotoÄŸraf yÃ¼kledi.\n",
      "\n",
      "ğŸ¤– BERT GiriÅŸi:\n",
      "   [CLS] ÃœrÃ¼n hasarlÄ± geldi. [SEP] MÃ¼ÅŸteri fotoÄŸraf yÃ¼kledi. [SEP]\n",
      "\n",
      "ğŸ¯ Beklenen Ã‡Ä±ktÄ± ([CLS] vektÃ¶rÃ¼nden): 1\n",
      "   â†³ 1 = Ä°liÅŸkili, 0 = Ä°liÅŸkisiz\n",
      "\n",
      "ğŸ”´ Ã–RNEK 3: âŒ Ä°liÅŸkisiz\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ CÃ¼mle A: Kargo Ã¼creti Ã§ok yÃ¼ksek.\n",
      "ğŸ“ CÃ¼mle B: BugÃ¼n hava yaÄŸmurlu.\n",
      "\n",
      "ğŸ¤– BERT GiriÅŸi:\n",
      "   [CLS] Kargo Ã¼creti Ã§ok yÃ¼ksek. [SEP] BugÃ¼n hava yaÄŸmurlu. [SEP]\n",
      "\n",
      "ğŸ¯ Beklenen Ã‡Ä±ktÄ± ([CLS] vektÃ¶rÃ¼nden): 0\n",
      "   â†³ 1 = Ä°liÅŸkili, 0 = Ä°liÅŸkisiz\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¼ YBS E-Ticaret Ã–rneÄŸi: Metin Ã‡ifti Analizi\n",
    "\n",
    "eticaret_ornekleri = [\n",
    "    {\n",
    "        \"A\": \"Bu Ã¼rÃ¼nÃ¼n kargosu gecikti.\",\n",
    "        \"B\": \"MÃ¼ÅŸteri iade talebi oluÅŸturdu.\",\n",
    "        \"iliÅŸki\": \"âœ… Ä°liÅŸkili\",\n",
    "        \"label\": 1,\n",
    "        \"icon\": \"ğŸŸ¢\"\n",
    "    },\n",
    "    {\n",
    "        \"A\": \"ÃœrÃ¼n hasarlÄ± geldi.\",\n",
    "        \"B\": \"MÃ¼ÅŸteri fotoÄŸraf yÃ¼kledi.\",\n",
    "        \"iliÅŸki\": \"âœ… Ä°liÅŸkili\",\n",
    "        \"label\": 1,\n",
    "        \"icon\": \"ğŸŸ¢\"\n",
    "    },\n",
    "    {\n",
    "        \"A\": \"Kargo Ã¼creti Ã§ok yÃ¼ksek.\",\n",
    "        \"B\": \"BugÃ¼n hava yaÄŸmurlu.\",\n",
    "        \"iliÅŸki\": \"âŒ Ä°liÅŸkisiz\",\n",
    "        \"label\": 0,\n",
    "        \"icon\": \"ğŸ”´\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ¢ YBS E-TÄ°CARET METÄ°N Ä°LÄ°ÅKÄ°SÄ° ANALÄ°ZÄ°\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, ornek in enumerate(eticaret_ornekleri, 1):\n",
    "    print(f\"\\n{ornek['icon']} Ã–RNEK {i}: {ornek['iliÅŸki']}\")\n",
    "    print(\"â”€\" * 70)\n",
    "    print(f\"ğŸ“ CÃ¼mle A: {ornek['A']}\")\n",
    "    print(f\"ğŸ“ CÃ¼mle B: {ornek['B']}\")\n",
    "    \n",
    "    # BERT formatÄ±\n",
    "    bert_input = f\"[CLS] {ornek['A']} [SEP] {ornek['B']} [SEP]\"\n",
    "    print(f\"\\nğŸ¤– BERT GiriÅŸi:\")\n",
    "    print(f\"   {bert_input}\")\n",
    "    print(f\"\\nğŸ¯ Beklenen Ã‡Ä±ktÄ± ([CLS] vektÃ¶rÃ¼nden): {ornek['label']}\")\n",
    "    print(f\"   â†³ 1 = Ä°liÅŸkili, 0 = Ä°liÅŸkisiz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f8e74",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 2.7. Ã–zet Diyagram: BERT GiriÅŸi Anatomisi\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ“„ Ä°ki CÃ¼mle GiriÅŸi\"] --> B[\"CÃ¼mle A:<br/>KÃ¶peÄŸim Ã§ok tatlÄ±\"]\n",
    "    A --> C[\"CÃ¼mle B:<br/>OynamayÄ± seviyor\"]\n",
    "    \n",
    "    B --> D[\"ğŸ”§ BERT FormatÄ±na DÃ¶nÃ¼ÅŸtÃ¼r\"]\n",
    "    C --> D\n",
    "    \n",
    "    D --> E[\"[CLS]\"]\n",
    "    D --> F[\"KÃ¶peÄŸim Ã§ok tatlÄ±\"]\n",
    "    D --> G[\"[SEP]\"]\n",
    "    D --> H[\"OynamayÄ± seviyor\"]\n",
    "    D --> I[\"[SEP]\"]\n",
    "    \n",
    "    E --> J[\"ğŸ¬ Ã–zet<br/>DÃ¼ÄŸmesi\"]\n",
    "    F --> K[\"ğŸ“ CÃ¼mle A<br/>Token'larÄ±\"]\n",
    "    G --> L[\"ğŸ”¹ AyraÃ§\"]\n",
    "    H --> M[\"ğŸ“ CÃ¼mle B<br/>Token'larÄ±\"]\n",
    "    I --> N[\"ğŸ”¹ AyraÃ§\"]\n",
    "    \n",
    "    J --> O[\"BERT Ä°ÅŸleme\"]\n",
    "    K --> O\n",
    "    L --> O\n",
    "    M --> O\n",
    "    N --> O\n",
    "    \n",
    "    O --> P[\"[CLS] Ã‡Ä±ktÄ± VektÃ¶rÃ¼<br/>768 boyut\"]\n",
    "    P --> Q[\"SÄ±nÄ±flandÄ±rma<br/>iÃ§in kullan\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style E fill:#ffccbc,stroke:#ff5722,stroke-width:3px\n",
    "    style G fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style I fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style P fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "    style Q fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; padding: 20px; border-radius: 10px; border: 2px solid #4caf50;\">\n",
    "    <h3>âœ… ADIM 2 TamamlandÄ±!</h3>\n",
    "    <p style=\"font-size: 15px; margin-bottom: 0;\">[CLS] ve [SEP] token'larÄ±nÄ±n rolÃ¼nÃ¼ ve iki cÃ¼mlenin BERT'e nasÄ±l verildiÄŸini Ã¶ÄŸrendik. Åimdi Ã¼Ã§ bileÅŸenli embedding sistemine (Token + Segment + Position) geÃ§ebiliriz!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3c4ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ ADIM 3: ğŸ§© ÃœÃ§ BileÅŸenli Girdi YerleÅŸtirmesi (Input Embeddings)\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; border-left: 5px solid #2196f3; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ’¡ Temel Fikir</h3>\n",
    "    <p style=\"font-size: 16px; margin: 0;\"><strong>BERT'te her token iÃ§in tek bir vektÃ¶r deÄŸil, ÃœÃ‡ vektÃ¶rÃ¼n toplamÄ± kullanÄ±lÄ±r!</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d004ab",
   "metadata": {},
   "source": [
    "## ğŸ¯ 3.1. BERT'in ÃœÃ§ Kimlik KartÄ± Sistemi\n",
    "\n",
    "Her token iÃ§in BERT **Ã¼Ã§ farklÄ± bilgiyi** birleÅŸtirir:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ”¤ Token: 'kÃ¶pek'\"] --> B[\"1ï¸âƒ£ Token Embedding\"]\n",
    "    A --> C[\"2ï¸âƒ£ Segment Embedding\"]\n",
    "    A --> D[\"3ï¸âƒ£ Position Embedding\"]\n",
    "    \n",
    "    B --> E[\"Hangi kelime?<br/>(Kimlik)\"]\n",
    "    C --> F[\"Hangi cÃ¼mleden?<br/>(Departman)\"]\n",
    "    D --> G[\"KaÃ§Ä±ncÄ± sÄ±rada?<br/>(Masa NumarasÄ±)\"]\n",
    "    \n",
    "    E --> H[\"âŠ• TOPLAM\"]\n",
    "    F --> H\n",
    "    G --> H\n",
    "    \n",
    "    H --> I[\"ğŸ“¦ Final Input Vector<br/>BERT-base: 768 boyut<br/>BERT-large: 1024 boyut\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style B fill:#ffccbc,stroke:#ff5722,stroke-width:2px\n",
    "    style C fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style D fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style H fill:#e1bee7,stroke:#9c27b0,stroke-width:3px\n",
    "    style I fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "```\n",
    "\n",
    "### ğŸ’³ Kimlik KartÄ± Benzetmesi:\n",
    "\n",
    "Her token'a bir **kimlik kartÄ±** takÄ±yorsunuz:\n",
    "\n",
    "| ğŸ“‹ Kart BÃ¶lÃ¼mÃ¼ | ğŸ¯ Ne SÃ¶yler? | ğŸ“Š Embedding Tipi |\n",
    "|----------------|---------------|-------------------|\n",
    "| **Ä°sim** | \"Bu token 'kÃ¶pek' kelimesidir\" | Token Embedding |\n",
    "| **Departman** | \"Bu token CÃ¼mle A'dan\" | Segment Embedding |\n",
    "| **Masa No** | \"Bu token 5. sÄ±rada\" | Position Embedding |\n",
    "\n",
    "**SonuÃ§:** Bu Ã¼Ã§ bilgi toplanÄ±nca token sistemde doÄŸru konumlanÄ±r!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712caa07",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ 3.2. Token Embedding: \"Bu Kelime Kim?\"\n",
    "\n",
    "<div style=\"background-color: #ffebee; border-left: 5px solid #f44336; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“ Token Embedding Nedir?</h3>\n",
    "    <p style=\"font-size: 15px;\">Her token'Ä±n <strong>benzersiz kimliÄŸini</strong> temsil eden vektÃ¶r.</p>\n",
    "    <ul style=\"font-size: 15px;\">\n",
    "        <li>ğŸ”¹ SÃ¶zlÃ¼kteki her token iÃ§in bir vektÃ¶r vardÄ±r</li>\n",
    "        <li>ğŸ”¹ BERT-base: ~30,000 token Ã— 768 boyut matris</li>\n",
    "        <li>ğŸ”¹ \"kÃ¶pek\" token'Ä± â†’ Belirli bir 768 boyutlu vektÃ¶r</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### ğŸ“Š Token Embedding Tablosu:\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"SÃ¶zlÃ¼k\"] --> B[\"Token ID 101: [CLS]\"]\n",
    "    A --> C[\"Token ID 3000: 'dog'\"]\n",
    "    A --> D[\"Token ID 5000: 'cat'\"]\n",
    "    A --> E[\"Token ID 102: [SEP]\"]\n",
    "    \n",
    "    B --> F[\"VektÃ¶r 768 boyut\"]\n",
    "    C --> F\n",
    "    D --> F\n",
    "    E --> F\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style F fill:#ffccbc,stroke:#ff5722,stroke-width:3px\n",
    "```\n",
    "\n",
    "**Ã–rnek:**\n",
    "- \"dog\" â†’ Token ID: 3000 â†’ Embedding vektÃ¶rÃ¼: [0.23, -0.45, 0.78, ..., 0.12] (768 deÄŸer)\n",
    "- \"cat\" â†’ Token ID: 5000 â†’ Embedding vektÃ¶rÃ¼: [0.19, -0.52, 0.81, ..., 0.09] (768 deÄŸer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444c7d28",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ 3.3. Segment Embedding: \"Bu Token Hangi CÃ¼mleden?\"\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; border-left: 5px solid #4caf50; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“ Segment Embedding Nedir?</h3>\n",
    "    <p style=\"font-size: 15px;\">Token'Ä±n <strong>hangi cÃ¼mleye ait olduÄŸunu</strong> gÃ¶steren vektÃ¶r.</p>\n",
    "    <ul style=\"font-size: 15px;\">\n",
    "        <li>ğŸ”¹ Sadece <strong>2 farklÄ± deÄŸer</strong> var: Segment A (0) ve Segment B (1)</li>\n",
    "        <li>ğŸ”¹ CÃ¼mle A'daki tÃ¼m token'lar â†’ AynÄ± segment vektÃ¶rÃ¼ (0)</li>\n",
    "        <li>ğŸ”¹ CÃ¼mle B'deki tÃ¼m token'lar â†’ AynÄ± segment vektÃ¶rÃ¼ (1)</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### ğŸ“Š Segment Embedding Ã–rneÄŸi:\n",
    "\n",
    "```\n",
    "Girdi: [CLS] KÃ¶peÄŸim Ã§ok tatlÄ± [SEP] OynamayÄ± seviyor [SEP]\n",
    "       â”€â”¬â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€ â”€â”€â”¬â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”¬â”€â”€â”€\n",
    "        â”‚              â”‚          â”‚             â”‚          â”‚\n",
    "     Seg 0          Seg 0      Seg 0        Seg 1      Seg 1\n",
    "   (CÃ¼mle A)      (CÃ¼mle A)  (CÃ¼mle A)    (CÃ¼mle B)  (CÃ¼mle B)\n",
    "```\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"[CLS] KÃ¶peÄŸim Ã§ok tatlÄ± [SEP]\"] --> B[\"Segment 0<br/>(CÃ¼mle A)\"]\n",
    "    C[\"OynamayÄ± seviyor [SEP]\"] --> D[\"Segment 1<br/>(CÃ¼mle B)\"]\n",
    "    \n",
    "    B --> E[\"VektÃ¶r: [0.1, 0.2, ..., 0.3]<br/>768 boyut\"]\n",
    "    D --> F[\"VektÃ¶r: [-0.1, -0.2, ..., -0.3]<br/>768 boyut\"]\n",
    "    \n",
    "    style A fill:#e1bee7,stroke:#9c27b0,stroke-width:2px\n",
    "    style C fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style B fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style D fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "```\n",
    "\n",
    "**Neden Segment Embedding?**  \n",
    "Model bu sayede \"bu kelime A'dan, bu kelime B'den\" ayrÄ±mÄ±nÄ± bilir!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150d388",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ 3.4. Position Embedding: \"Bu Token KaÃ§Ä±ncÄ± SÄ±rada?\"\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; border-left: 5px solid #2196f3; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“ Position Embedding Nedir?</h3>\n",
    "    <p style=\"font-size: 15px;\">Token'Ä±n <strong>cÃ¼mledeki pozisyonunu</strong> gÃ¶steren vektÃ¶r.</p>\n",
    "    <ul style=\"font-size: 15px;\">\n",
    "        <li>ğŸ”¹ Transformer kendi baÅŸÄ±na <strong>sÄ±rayÄ± bilmez</strong></li>\n",
    "        <li>ğŸ”¹ Her pozisyon iÃ§in Ã¶ÄŸrenilmiÅŸ bir vektÃ¶r vardÄ±r</li>\n",
    "        <li>ğŸ”¹ BERT-base: Maksimum 512 pozisyon Ã— 768 boyut</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### ğŸ“Š Position Embedding Ã–rneÄŸi:\n",
    "\n",
    "```\n",
    "Token:     [CLS]  KÃ¶peÄŸim   Ã§ok    tatlÄ±   [SEP]\n",
    "Pozisyon:    0       1       2       3       4\n",
    "             â†“       â†“       â†“       â†“       â†“\n",
    "Pos Emb:   Pâ‚€      Pâ‚      Pâ‚‚      Pâ‚ƒ      Pâ‚„\n",
    "           768d    768d    768d    768d    768d\n",
    "```\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"Pozisyon 0\"] --> E[\"Pâ‚€ vektÃ¶r\"]\n",
    "    B[\"Pozisyon 1\"] --> F[\"Pâ‚ vektÃ¶r\"]\n",
    "    C[\"Pozisyon 2\"] --> G[\"Pâ‚‚ vektÃ¶r\"]\n",
    "    D[\"Pozisyon 3\"] --> H[\"Pâ‚ƒ vektÃ¶r\"]\n",
    "    \n",
    "    E --> I[\"Her biri<br/>768 boyut\"]\n",
    "    F --> I\n",
    "    G --> I\n",
    "    H --> I\n",
    "    \n",
    "    style A fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style B fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style C fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style D fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style I fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "```\n",
    "\n",
    "**Neden Position Embedding?**  \n",
    "\"KÃ¶peÄŸim Ã§ok tatlÄ±\" â‰  \"TatlÄ± Ã§ok kÃ¶peÄŸim\" â†’ SÄ±ra Ã¶nemli!  \n",
    "Transformer'a sÄ±ra bilgisini bu ÅŸekilde veriyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bed453",
   "metadata": {},
   "source": [
    "## âŠ• 3.5. ÃœÃ§ Embedding'in ToplanmasÄ±\n",
    "\n",
    "<div style=\"background-color: #fff3cd; border-left: 5px solid #ffc107; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ¯ Final Input Vector HesaplamasÄ±</h3>\n",
    "    <p style=\"font-size: 16px; margin: 0;\"><strong>Final Input = Token Embedding + Segment Embedding + Position Embedding</strong></p>\n",
    "</div>\n",
    "\n",
    "### ğŸ“ Matematiksel GÃ¶sterim:\n",
    "\n",
    "```\n",
    "Her token iÃ§in:\n",
    "\n",
    "Input[i] = TokenEmb[token_id] + SegmentEmb[segment_id] + PositionEmb[position]\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€ 768d â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€ 768d â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€ 768d â”€â”€â”€â”€â”€â”˜\n",
    "                                    \n",
    "                            â†“\n",
    "                            \n",
    "                  Final Input Vector (768d)\n",
    "```\n",
    "\n",
    "### ğŸ¨ GÃ¶rsel AkÄ±ÅŸ:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"Token: 'kÃ¶pek'<br/>Pozisyon: 1<br/>Segment: 0\"] --> B[\"Token Embedding\"]\n",
    "    A --> C[\"Segment Embedding\"]\n",
    "    A --> D[\"Position Embedding\"]\n",
    "    \n",
    "    B --> E[\"[0.23, -0.45, 0.78, ..., 0.12]\"]\n",
    "    C --> F[\"[0.10, 0.20, ..., 0.30]\"]\n",
    "    D --> G[\"[0.15, -0.10, ..., 0.05]\"]\n",
    "    \n",
    "    E --> H[\"âŠ•<br/>Toplama\"]\n",
    "    F --> H\n",
    "    G --> H\n",
    "    \n",
    "    H --> I[\"Final Input Vector<br/>[0.48, -0.35, ..., 0.47]<br/>768 boyut\"]\n",
    "    \n",
    "    I --> J[\"ğŸš€ BERT Transformer<br/>KatmanlarÄ±na Gir\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style B fill:#ffccbc,stroke:#ff5722,stroke-width:2px\n",
    "    style C fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style D fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style H fill:#e1bee7,stroke:#9c27b0,stroke-width:3px\n",
    "    style I fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "    style J fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd5dc5c",
   "metadata": {},
   "source": [
    "## ğŸ’» 3.6. Pratik Ã–rnek: Embedding'leri Ä°nceleyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c73544f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa64ad64244405ea1c752390252ae7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ§© BERT EMBEDDÄ°NG SÄ°STEMÄ° ANALÄ°ZÄ°\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Embedding BoyutlarÄ±:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "1ï¸âƒ£ Token Embedding:\n",
      "   SÃ¶zlÃ¼k Boyutu  : 30,522 token\n",
      "   VektÃ¶r Boyutu  : 768 boyut\n",
      "   Toplam Parametre: 23,440,896\n",
      "\n",
      "2ï¸âƒ£ Segment Embedding:\n",
      "   Segment SayÄ±sÄ± : 2 (Segment A=0, Segment B=1)\n",
      "   VektÃ¶r Boyutu  : 768 boyut\n",
      "   Toplam Parametre: 1,536\n",
      "\n",
      "3ï¸âƒ£ Position Embedding:\n",
      "   Maksimum Uzunluk: 512 token (BERT'in limiti)\n",
      "   VektÃ¶r Boyutu   : 768 boyut\n",
      "   Toplam Parametre : 393,216\n",
      "\n",
      "======================================================================\n",
      "ğŸ’¡ Her token iÃ§in bu Ã¼Ã§ embedding toplanarak final input oluÅŸturulur!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¬ BERT Embedding Analizi\n",
    "\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "\n",
    "# BERT modelini yÃ¼kle\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ§© BERT EMBEDDÄ°NG SÄ°STEMÄ° ANALÄ°ZÄ°\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Embedding katmanlarÄ±nÄ± incele\n",
    "print(\"\\nğŸ“Š Embedding BoyutlarÄ±:\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# 1. Token Embedding\n",
    "token_emb = model.embeddings.word_embeddings\n",
    "print(f\"\\n1ï¸âƒ£ Token Embedding:\")\n",
    "print(f\"   SÃ¶zlÃ¼k Boyutu  : {token_emb.num_embeddings:,} token\")\n",
    "print(f\"   VektÃ¶r Boyutu  : {token_emb.embedding_dim} boyut\")\n",
    "print(f\"   Toplam Parametre: {token_emb.num_embeddings * token_emb.embedding_dim:,}\")\n",
    "\n",
    "# 2. Segment Embedding\n",
    "segment_emb = model.embeddings.token_type_embeddings\n",
    "print(f\"\\n2ï¸âƒ£ Segment Embedding:\")\n",
    "print(f\"   Segment SayÄ±sÄ± : {segment_emb.num_embeddings} (Segment A=0, Segment B=1)\")\n",
    "print(f\"   VektÃ¶r Boyutu  : {segment_emb.embedding_dim} boyut\")\n",
    "print(f\"   Toplam Parametre: {segment_emb.num_embeddings * segment_emb.embedding_dim:,}\")\n",
    "\n",
    "# 3. Position Embedding\n",
    "position_emb = model.embeddings.position_embeddings\n",
    "print(f\"\\n3ï¸âƒ£ Position Embedding:\")\n",
    "print(f\"   Maksimum Uzunluk: {position_emb.num_embeddings} token (BERT'in limiti)\")\n",
    "print(f\"   VektÃ¶r Boyutu   : {position_emb.embedding_dim} boyut\")\n",
    "print(f\"   Toplam Parametre : {position_emb.num_embeddings * position_emb.embedding_dim:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ’¡ Her token iÃ§in bu Ã¼Ã§ embedding toplanarak final input oluÅŸturulur!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94d4751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¨ TOKEN-BY-TOKEN EMBEDDÄ°NG ANALÄ°ZÄ°\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ Token Listesi:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      " 1. Token: '[CLS]       '\n",
      "    â”œâ”€ Token ID   :   101\n",
      "    â”œâ”€ Segment    : 0 (CÃ¼mle A)\n",
      "    â””â”€ Pozisyon   : 0\n",
      "\n",
      " 2. Token: 'my          '\n",
      "    â”œâ”€ Token ID   :  2026\n",
      "    â”œâ”€ Segment    : 0 (CÃ¼mle A)\n",
      "    â””â”€ Pozisyon   : 1\n",
      "\n",
      " 3. Token: 'dog         '\n",
      "    â”œâ”€ Token ID   :  3899\n",
      "    â”œâ”€ Segment    : 0 (CÃ¼mle A)\n",
      "    â””â”€ Pozisyon   : 2\n",
      "\n",
      " 4. Token: 'is          '\n",
      "    â”œâ”€ Token ID   :  2003\n",
      "    â”œâ”€ Segment    : 0 (CÃ¼mle A)\n",
      "    â””â”€ Pozisyon   : 3\n",
      "\n",
      " 5. Token: 'cute        '\n",
      "    â”œâ”€ Token ID   : 10140\n",
      "    â”œâ”€ Segment    : 0 (CÃ¼mle A)\n",
      "    â””â”€ Pozisyon   : 4\n",
      "\n",
      " 6. Token: '[SEP]       '\n",
      "    â”œâ”€ Token ID   :   102\n",
      "    â”œâ”€ Segment    : 0 (CÃ¼mle A)\n",
      "    â””â”€ Pozisyon   : 5\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      " 7. Token: 'he          '\n",
      "    â”œâ”€ Token ID   :  2002\n",
      "    â”œâ”€ Segment    : 1 (CÃ¼mle B)\n",
      "    â””â”€ Pozisyon   : 6\n",
      "\n",
      " 8. Token: 'loves       '\n",
      "    â”œâ”€ Token ID   :  7459\n",
      "    â”œâ”€ Segment    : 1 (CÃ¼mle B)\n",
      "    â””â”€ Pozisyon   : 7\n",
      "\n",
      " 9. Token: 'playing     '\n",
      "    â”œâ”€ Token ID   :  2652\n",
      "    â”œâ”€ Segment    : 1 (CÃ¼mle B)\n",
      "    â””â”€ Pozisyon   : 8\n",
      "\n",
      "10. Token: '[SEP]       '\n",
      "    â”œâ”€ Token ID   :   102\n",
      "    â”œâ”€ Segment    : 1 (CÃ¼mle B)\n",
      "    â””â”€ Pozisyon   : 9\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¨ Token-by-Token Embedding GÃ¶rselleÅŸtirmesi\n",
    "\n",
    "sentence_a = \"My dog is cute\"\n",
    "sentence_b = \"He loves playing\"\n",
    "\n",
    "# Encode\n",
    "inputs = tokenizer.encode_plus(\n",
    "    sentence_a,\n",
    "    sentence_b,\n",
    "    add_special_tokens=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Token'larÄ± al\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ¨ TOKEN-BY-TOKEN EMBEDDÄ°NG ANALÄ°ZÄ°\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nğŸ“‹ Token Listesi:\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Her token iÃ§in detaylar\n",
    "for i, token in enumerate(tokens):\n",
    "    token_id = inputs['input_ids'][0][i].item()\n",
    "    segment_id = inputs['token_type_ids'][0][i].item()\n",
    "    position = i\n",
    "    \n",
    "    # Segment ismi\n",
    "    segment_name = \"CÃ¼mle A\" if segment_id == 0 else \"CÃ¼mle B\"\n",
    "    \n",
    "    print(f\"\\n{i+1:2d}. Token: '{token:12s}'\")\n",
    "    print(f\"    â”œâ”€ Token ID   : {token_id:5d}\")\n",
    "    print(f\"    â”œâ”€ Segment    : {segment_id} ({segment_name})\")\n",
    "    print(f\"    â””â”€ Pozisyon   : {position}\")\n",
    "    \n",
    "    if token == '[SEP]':\n",
    "        print(\"    \" + \"â”€\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbaa8a3",
   "metadata": {},
   "source": [
    "## ğŸ¢ 3.7. YBS Perspektifinden: MÃ¼ÅŸteri Destek Sistemi\n",
    "\n",
    "<div style=\"background-color: #f3e5f5; border-left: 5px solid #9c27b0; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“Š GerÃ§ek DÃ¼nya Senaryosu</h3>\n",
    "    <p style=\"font-size: 15px;\"><strong>Durum:</strong> Bir mÃ¼ÅŸteri destek sisteminde iki mesaj geldi.</p>\n",
    "    <p style=\"font-size: 15px;\"><strong>AmaÃ§:</strong> Mesajlar aynÄ± ticket'a mÄ± ait anlamak iÃ§in BERT kullanÄ±yoruz.</p>\n",
    "</div>\n",
    "\n",
    "### ğŸ’¼ Ã–rnek Senaryo:\n",
    "\n",
    "**Mesaj 1 (CÃ¼mle A):** \"Åifremi unuttum ve giriÅŸ yapamÄ±yorum.\"  \n",
    "**Mesaj 2 (CÃ¼mle B):** \"Mail adresime kod gelmedi.\"\n",
    "\n",
    "**BERT'e nasÄ±l verilir:**\n",
    "```\n",
    "[CLS] Åifremi unuttum ve giriÅŸ yapamÄ±yorum [SEP] Mail adresime kod gelmedi [SEP]\n",
    "\n",
    "Token Embedding  : Her kelimenin kimliÄŸi\n",
    "Segment Embedding: Mesaj 1 vs Mesaj 2 ayrÄ±mÄ± (Segment 0 vs 1)\n",
    "Position Embedding: Kelimelerin sÄ±rasÄ± (0, 1, 2, 3, ...)\n",
    "```\n",
    "\n",
    "**SonuÃ§:** ÃœÃ§ embedding toplanÄ±nca BERT ÅŸunu anlayabilir:\n",
    "- Bu iki mesaj **iliÅŸkili** (ikisi de giriÅŸ problemi)\n",
    "- AynÄ± ticket'a atanmalÄ± âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fc39d",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 3.8. Ã–zet Diyagram: ÃœÃ§ Embedding'in BirleÅŸimi\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ“ Ã–rnek Girdi:<br/>[CLS] My dog [SEP] He plays [SEP]\"] --> B[\"Token'lara AyÄ±r\"]\n",
    "    \n",
    "    B --> C1[\"[CLS]\"]\n",
    "    B --> C2[\"my\"]\n",
    "    B --> C3[\"dog\"]\n",
    "    B --> C4[\"[SEP]\"]\n",
    "    B --> C5[\"he\"]\n",
    "    B --> C6[\"plays\"]\n",
    "    B --> C7[\"[SEP]\"]\n",
    "    \n",
    "    C1 --> D1[\"Token Emb\"]\n",
    "    C1 --> E1[\"Seg 0\"]\n",
    "    C1 --> F1[\"Pos 0\"]\n",
    "    \n",
    "    C2 --> D2[\"Token Emb\"]\n",
    "    C2 --> E2[\"Seg 0\"]\n",
    "    C2 --> F2[\"Pos 1\"]\n",
    "    \n",
    "    C3 --> D3[\"Token Emb\"]\n",
    "    C3 --> E3[\"Seg 0\"]\n",
    "    C3 --> F3[\"Pos 2\"]\n",
    "    \n",
    "    C5 --> D5[\"Token Emb\"]\n",
    "    C5 --> E5[\"Seg 1\"]\n",
    "    C5 --> F5[\"Pos 4\"]\n",
    "    \n",
    "    D1 --> G[\"âŠ• Toplama\"]\n",
    "    E1 --> G\n",
    "    F1 --> G\n",
    "    \n",
    "    D2 --> H[\"âŠ• Toplama\"]\n",
    "    E2 --> H\n",
    "    F2 --> H\n",
    "    \n",
    "    D3 --> I[\"âŠ• Toplama\"]\n",
    "    E3 --> I\n",
    "    F3 --> I\n",
    "    \n",
    "    D5 --> J[\"âŠ• Toplama\"]\n",
    "    E5 --> J\n",
    "    F5 --> J\n",
    "    \n",
    "    G --> K[\"Final Input<br/>Vectors\"]\n",
    "    H --> K\n",
    "    I --> K\n",
    "    J --> K\n",
    "    \n",
    "    K --> L[\"ğŸš€ BERT<br/>Transformer<br/>Layers\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style D1 fill:#ffccbc,stroke:#ff5722,stroke-width:2px\n",
    "    style D2 fill:#ffccbc,stroke:#ff5722,stroke-width:2px\n",
    "    style D3 fill:#ffccbc,stroke:#ff5722,stroke-width:2px\n",
    "    style E1 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style E2 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style E5 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style F1 fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style F2 fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style F5 fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style K fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "    style L fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; padding: 20px; border-radius: 10px; border: 2px solid #4caf50;\">\n",
    "    <h3>âœ… ADIM 3 TamamlandÄ±!</h3>\n",
    "    <p style=\"font-size: 15px; margin-bottom: 0;\">ÃœÃ§ bileÅŸenli embedding sistemini (Token + Segment + Position) Ã¶ÄŸrendik. Åimdi baÄŸlamsal (contextual) embedding kavramÄ±na geÃ§ebiliriz!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0520e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ ADIM 4: ğŸ”„ BaÄŸlamsal (Contextual) Embeddings vs Statik Embeddings\n",
    "\n",
    "<div style=\"background-color: #fff3cd; border-left: 5px solid #ffc107; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ’¡ Temel Fikir</h3>\n",
    "    <p style=\"font-size: 16px; margin: 0;\"><strong>BERT'in Ã§Ä±ktÄ± vektÃ¶rleri \"baÄŸlama gÃ¶re deÄŸiÅŸir\" - aynÄ± kelime farklÄ± cÃ¼mlelerde farklÄ± vektÃ¶r Ã¼retir!</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4ad2f",
   "metadata": {},
   "source": [
    "## ğŸ¯ 4.1. Embedding vs Ã‡Ä±ktÄ± VektÃ¶rÃ¼ FarkÄ±\n",
    "\n",
    "<div style=\"background-color: #ffebee; border-left: 5px solid #f44336; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>âš ï¸ Ã–nemli AyrÄ±m!</h3>\n",
    "    <p style=\"font-size: 15px;\">Ã–ÄŸrenciler genelde burada takÄ±lÄ±r: \"Embedding zaten vektÃ¶r deÄŸil miydi?\"</p>\n",
    "    <ul style=\"font-size: 15px;\">\n",
    "        <li><strong>Girdi Embedding (Input):</strong> Statik, sabit, token kimliÄŸi</li>\n",
    "        <li><strong>Ã‡Ä±ktÄ± VektÃ¶rÃ¼ (Output):</strong> Dinamik, baÄŸlamsal, cÃ¼mleye gÃ¶re deÄŸiÅŸir</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma:\n",
    "\n",
    "| ğŸ·ï¸ Ã–zellik | ğŸ“¥ Girdi Embedding | ğŸ“¤ BERT Ã‡Ä±ktÄ± VektÃ¶rÃ¼ |\n",
    "|------------|-------------------|----------------------|\n",
    "| **Ne zaman oluÅŸur?** | BERT'e girmeden Ã¶nce | BERT iÅŸledikten sonra |\n",
    "| **DeÄŸiÅŸir mi?** | âŒ HayÄ±r, her zaman aynÄ± | âœ… Evet, baÄŸlama gÃ¶re deÄŸiÅŸir |\n",
    "| **\"bank\" kelimesi** | Her zaman aynÄ± vektÃ¶r | CÃ¼mleye gÃ¶re farklÄ± (banka vs kÄ±yÄ±) |\n",
    "| **Nereden gelir?** | Token + Segment + Position toplamÄ± | Transformer katmanlarÄ±nÄ±n Ã§Ä±ktÄ±sÄ± |\n",
    "| **Ä°sim** | Static/Statik Embedding | Contextual/BaÄŸlamsal Embedding |\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"Token: 'bank'\"] --> B[\"Girdi Embedding<br/>(Her zaman aynÄ±)\"]\n",
    "    B --> C[\"BERT<br/>Transformer<br/>Layers\"]\n",
    "    C --> D1[\"Ã‡Ä±ktÄ± 1:<br/>'river bank'<br/>(kÄ±yÄ±)\"]\n",
    "    C --> D2[\"Ã‡Ä±ktÄ± 2:<br/>'money bank'<br/>(banka)\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style B fill:#ffccbc,stroke:#ff5722,stroke-width:2px\n",
    "    style C fill:#e1bee7,stroke:#9c27b0,stroke-width:3px\n",
    "    style D1 fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style D2 fill:#b3e5fc,stroke:#03a9f4,stroke-width:3px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd4c8a",
   "metadata": {},
   "source": [
    "## ğŸ“– 4.2. \"YÃ¼z\" Kelimesi Ã–rneÄŸi ile BaÄŸlamsal Embedding\n",
    "\n",
    "HatÄ±rlayalÄ±m: \"yÃ¼z\" kelimesinin birden fazla anlamÄ± var!\n",
    "\n",
    "### ğŸ”¤ ÃœÃ§ FarklÄ± CÃ¼mle:\n",
    "\n",
    "1. **\"Havuzda yÃ¼z Ã§ok iyiydi.\"** â†’ yÃ¼zmek (fiil)\n",
    "2. **\"Onun yÃ¼zÃ¼ bugÃ¼n solgundu.\"** â†’ yÃ¼z (isim, face)\n",
    "3. **\"YÃ¼z Ã¶ÄŸrenci geldi.\"** â†’ 100 (sayÄ±)\n",
    "\n",
    "### ğŸ§  BERT'in YaklaÅŸÄ±mÄ±:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"'yÃ¼z' token'Ä±\"] --> B[\"Girdi Embedding<br/>(Statik - AynÄ±)\"]\n",
    "    \n",
    "    B --> C1[\"CÃ¼mle 1:<br/>Havuzda yÃ¼z Ã§ok iyiydi\"]\n",
    "    B --> C2[\"CÃ¼mle 2:<br/>Onun yÃ¼zÃ¼ solgundu\"]\n",
    "    B --> C3[\"CÃ¼mle 3:<br/>YÃ¼z Ã¶ÄŸrenci geldi\"]\n",
    "    \n",
    "    C1 --> D[\"BERT<br/>Transformer\"]\n",
    "    C2 --> D\n",
    "    C3 --> D\n",
    "    \n",
    "    D --> E1[\"Ã‡Ä±ktÄ± 1:<br/>yÃ¼zmek vektÃ¶rÃ¼<br/>(aktivite)\"]\n",
    "    D --> E2[\"Ã‡Ä±ktÄ± 2:<br/>yÃ¼z vektÃ¶rÃ¼<br/>(vÃ¼cut parÃ§asÄ±)\"]\n",
    "    D --> E3[\"Ã‡Ä±ktÄ± 3:<br/>100 vektÃ¶rÃ¼<br/>(sayÄ±)\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style B fill:#ffccbc,stroke:#ff5722,stroke-width:3px\n",
    "    style D fill:#e1bee7,stroke:#9c27b0,stroke-width:3px\n",
    "    style E1 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style E2 fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style E3 fill:#fff9c4,stroke:#fbc02d,stroke-width:2px\n",
    "```\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; border-left: 5px solid #2196f3; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ¯ SonuÃ§</h3>\n",
    "    <p style=\"font-size: 15px;\"><strong>AynÄ± kelime (yÃ¼z)</strong> â†’ <strong>AynÄ± girdi embedding</strong> â†’ <strong>BERT iÅŸler</strong> â†’ <strong>FarklÄ± Ã§Ä±ktÄ± vektÃ¶rleri!</strong></p>\n",
    "    <p style=\"font-size: 15px;\">Bu yÃ¼zden BERT Ã§Ä±ktÄ±sÄ±na <strong>\"Contextual (BaÄŸlamsal) Embedding\"</strong> denir.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84237e83",
   "metadata": {},
   "source": [
    "## ğŸ”¬ 4.3. BERT'in Her Token iÃ§in Ã‡Ä±ktÄ± Ãœretmesi\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; border-left: 5px solid #4caf50; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“Š BERT Ã‡Ä±ktÄ± FormatÄ±</h3>\n",
    "    <p style=\"font-size: 15px;\">BERT <strong>her token iÃ§in</strong> bir baÄŸlamsal vektÃ¶r Ã¼retir.</p>\n",
    "    <ul style=\"font-size: 15px;\">\n",
    "        <li>ğŸ”¹ GiriÅŸte 10 token â†’ Ã‡Ä±kÄ±ÅŸta 10 vektÃ¶r</li>\n",
    "        <li>ğŸ”¹ Her vektÃ¶r: BERT-base iÃ§in 768 boyut, BERT-large iÃ§in 1024 boyut</li>\n",
    "        <li>ğŸ”¹ Her vektÃ¶r o token'Ä±n <strong>tÃ¼m cÃ¼mleye gÃ¶re anlamÄ±nÄ±</strong> taÅŸÄ±r</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### ğŸ“ Boyut Analizi:\n",
    "\n",
    "```\n",
    "Girdi:  [CLS]  My  dog  is  cute  [SEP]\n",
    "         â†“     â†“   â†“    â†“   â†“     â†“\n",
    "        768   768 768  768  768   768  (BERT-base)\n",
    "         â†“     â†“   â†“    â†“   â†“     â†“\n",
    "Ã‡Ä±ktÄ±: [Vâ‚€]  [Vâ‚] [Vâ‚‚] [Vâ‚ƒ] [Vâ‚„] [Vâ‚…]\n",
    "\n",
    "Her Váµ¢ = 768 boyutlu baÄŸlamsal vektÃ¶r\n",
    "```\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"Girdi Sequence<br/>[CLS] My dog is cute [SEP]\"] --> B[\"BERT<br/>12 Transformer Layer\"]\n",
    "    \n",
    "    B --> C1[\"Vâ‚€: [CLS] vektÃ¶r<br/>768d\"]\n",
    "    B --> C2[\"Vâ‚: 'My' vektÃ¶r<br/>768d\"]\n",
    "    B --> C3[\"Vâ‚‚: 'dog' vektÃ¶r<br/>768d\"]\n",
    "    B --> C4[\"Vâ‚ƒ: 'is' vektÃ¶r<br/>768d\"]\n",
    "    B --> C5[\"Vâ‚„: 'cute' vektÃ¶r<br/>768d\"]\n",
    "    B --> C6[\"Vâ‚…: [SEP] vektÃ¶r<br/>768d\"]\n",
    "    \n",
    "    C1 --> D[\"TÃ¼m token'lar iÃ§in<br/>baÄŸlamsal vektÃ¶rler\"]\n",
    "    C2 --> D\n",
    "    C3 --> D\n",
    "    C4 --> D\n",
    "    C5 --> D\n",
    "    C6 --> D\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style B fill:#e1bee7,stroke:#9c27b0,stroke-width:3px\n",
    "    style C1 fill:#ffccbc,stroke:#ff5722,stroke-width:2px\n",
    "    style C2 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style C3 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style C4 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style C5 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style C6 fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style D fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb2055b",
   "metadata": {},
   "source": [
    "## ğŸ’» 4.4. Pratik Ã–rnek: BaÄŸlamsal VektÃ¶rleri GÃ¶relim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f98d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ”¬ BAÄLAMSAL EMBEDDÄ°NG KARÅILAÅTIRMASI\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ CÃ¼mle 1: I went to the bank to deposit money.\n",
      "   'bank' pozisyon: 5\n",
      "   Anlam: BANKA (finans)\n",
      "\n",
      "ğŸ“ CÃ¼mle 2: We sat by the river bank.\n",
      "   'bank' pozisyon: 6\n",
      "   Anlam: KIYI (nehir kenarÄ±)\n",
      "\n",
      "ğŸ“Š 'bank' VektÃ¶r Analizi:\n",
      "   â”œâ”€ VektÃ¶r Boyutu : 768 (her ikisi de)\n",
      "   â”œâ”€ VektÃ¶r 1 (banka) ilk 5 deÄŸer : [ 0.70910347 -0.2590419  -0.01858745 -0.09361548  1.2636602 ]\n",
      "   â”œâ”€ VektÃ¶r 2 (kÄ±yÄ±) ilk 5 deÄŸer  : [ 0.5963192  -0.49443638  0.02876262 -0.3175279  -0.20508093]\n",
      "   â””â”€ Benzerlik (Cosine Similarity): 0.5361\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ’¡ Yorum:\n",
      "   âœ… VektÃ¶rler FARKLI! BERT baÄŸlamÄ± doÄŸru yakaladÄ±.\n",
      "   âœ… 'bank' kelimesi farklÄ± cÃ¼mlelerde farklÄ± vektÃ¶r aldÄ±.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¬ AynÄ± Kelimenin FarklÄ± BaÄŸlamlarda VektÃ¶rlerini KarÅŸÄ±laÅŸtÄ±rma\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Ä°ki farklÄ± cÃ¼mle - \"bank\" kelimesi farklÄ± anlamlarda\n",
    "sentence1 = \"I went to the bank to deposit money.\"  # bank = banka\n",
    "sentence2 = \"We sat by the river bank.\"  # bank = kÄ±yÄ±\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”¬ BAÄLAMSAL EMBEDDÄ°NG KARÅILAÅTIRMASI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# CÃ¼mle 1'i iÅŸle\n",
    "inputs1 = tokenizer(sentence1, return_tensors='pt')\n",
    "outputs1 = model(**inputs1)\n",
    "tokens1 = tokenizer.convert_ids_to_tokens(inputs1['input_ids'][0])\n",
    "\n",
    "# CÃ¼mle 2'yi iÅŸle\n",
    "inputs2 = tokenizer(sentence2, return_tensors='pt')\n",
    "outputs2 = model(**inputs2)\n",
    "tokens2 = tokenizer.convert_ids_to_tokens(inputs2['input_ids'][0])\n",
    "\n",
    "# \"bank\" token'Ä±nÄ±n pozisyonunu bul\n",
    "bank_pos1 = tokens1.index('bank')\n",
    "bank_pos2 = tokens2.index('bank')\n",
    "\n",
    "# \"bank\" iÃ§in Ã§Ä±ktÄ± vektÃ¶rlerini al\n",
    "bank_vector1 = outputs1.last_hidden_state[0, bank_pos1, :].detach().numpy()\n",
    "bank_vector2 = outputs2.last_hidden_state[0, bank_pos2, :].detach().numpy()\n",
    "\n",
    "# Cosine similarity hesapla (ne kadar benzer?)\n",
    "from numpy.linalg import norm\n",
    "similarity = np.dot(bank_vector1, bank_vector2) / (norm(bank_vector1) * norm(bank_vector2))\n",
    "\n",
    "print(f\"\\nğŸ“ CÃ¼mle 1: {sentence1}\")\n",
    "print(f\"   'bank' pozisyon: {bank_pos1}\")\n",
    "print(f\"   Anlam: BANKA (finans)\")\n",
    "\n",
    "print(f\"\\nğŸ“ CÃ¼mle 2: {sentence2}\")\n",
    "print(f\"   'bank' pozisyon: {bank_pos2}\")\n",
    "print(f\"   Anlam: KIYI (nehir kenarÄ±)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š 'bank' VektÃ¶r Analizi:\")\n",
    "print(f\"   â”œâ”€ VektÃ¶r Boyutu : {len(bank_vector1)} (her ikisi de)\")\n",
    "print(f\"   â”œâ”€ VektÃ¶r 1 (banka) ilk 5 deÄŸer : {bank_vector1[:5]}\")\n",
    "print(f\"   â”œâ”€ VektÃ¶r 2 (kÄ±yÄ±) ilk 5 deÄŸer  : {bank_vector2[:5]}\")\n",
    "print(f\"   â””â”€ Benzerlik (Cosine Similarity): {similarity:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"ğŸ’¡ Yorum:\")\n",
    "if similarity < 0.95:\n",
    "    print(\"   âœ… VektÃ¶rler FARKLI! BERT baÄŸlamÄ± doÄŸru yakaladÄ±.\")\n",
    "    print(\"   âœ… 'bank' kelimesi farklÄ± cÃ¼mlelerde farklÄ± vektÃ¶r aldÄ±.\")\n",
    "else:\n",
    "    print(\"   âš ï¸  VektÃ¶rler Ã§ok benzer (model baÄŸlamÄ± tam yakalayamadÄ±)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3064778b",
   "metadata": {},
   "source": [
    "## ğŸ¢ 4.5. YBS Perspektifinden: MÃ¼ÅŸteri Duygu Analizi\n",
    "\n",
    "<div style=\"background-color: #f3e5f5; border-left: 5px solid #9c27b0; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“Š GerÃ§ek DÃ¼nya Senaryosu</h3>\n",
    "    <p style=\"font-size: 15px;\"><strong>Problem:</strong> E-ticaret sitesinde \"hÄ±zlÄ±\" kelimesi farklÄ± baÄŸlamlarda kullanÄ±lÄ±yor.</p>\n",
    "    <p style=\"font-size: 15px;\"><strong>AmaÃ§:</strong> BaÄŸlama gÃ¶re pozitif mi negatif mi anlamak.</p>\n",
    "</div>\n",
    "\n",
    "### ğŸ’¼ Ã–rnek Yorumlar:\n",
    "\n",
    "**Yorum 1:** \"Teslimat Ã§ok hÄ±zlÄ± geldi, memnun kaldÄ±m!\" ğŸ˜Š  \n",
    "â†’ \"hÄ±zlÄ±\" = **POZÄ°TÄ°F** (iyi bir ÅŸey)\n",
    "\n",
    "**Yorum 2:** \"ÃœrÃ¼n Ã§ok hÄ±zlÄ± bozuldu, kalitesiz.\" ğŸ˜  \n",
    "â†’ \"hÄ±zlÄ±\" = **NEGATÄ°F** (kÃ¶tÃ¼ bir ÅŸey)\n",
    "\n",
    "### ğŸ¤– BERT'in AvantajÄ±:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"'hÄ±zlÄ±' kelimesi\"] --> B[\"Statik Embedding<br/>(Eski yÃ¶ntem)\"]\n",
    "    A --> C[\"BaÄŸlamsal Embedding<br/>(BERT)\"]\n",
    "    \n",
    "    B --> D[\"âŒ Her zaman aynÄ± vektÃ¶r<br/>BaÄŸlamÄ± bilmez\"]\n",
    "    \n",
    "    C --> E1[\"Yorum 1:<br/>'Teslimat Ã§ok hÄ±zlÄ±'\"]\n",
    "    C --> E2[\"Yorum 2:<br/>'Bozuldu Ã§ok hÄ±zlÄ±'\"]\n",
    "    \n",
    "    E1 --> F1[\"âœ… Pozitif vektÃ¶r\"]\n",
    "    E2 --> F2[\"âœ… Negatif vektÃ¶r\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style B fill:#ffcdd2,stroke:#f44336,stroke-width:2px\n",
    "    style C fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style D fill:#ffcdd2,stroke:#f44336,stroke-width:2px\n",
    "    style F1 fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style F2 fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "```\n",
    "\n",
    "**SonuÃ§:** BERT baÄŸlamÄ± anlayarak \"hÄ±zlÄ±\" kelimesine her yorumda farklÄ± anlam yÃ¼kler!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c213c",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 4.6. Ã–zet Diyagram: Statik vs BaÄŸlamsal Embedding\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    A[\"Kelime: 'bank'\"] --> B{{\"Hangi yÃ¶ntem?\"}}\n",
    "    \n",
    "    B -->|Eski YÃ¶ntem| C[\"Statik Embedding<br/>(Word2Vec, GloVe)\"]\n",
    "    B -->|Modern YÃ¶ntem| D[\"BaÄŸlamsal Embedding<br/>(BERT, GPT)\"]\n",
    "    \n",
    "    C --> E[\"âŒ Her zaman aynÄ± vektÃ¶r\"]\n",
    "    E --> F[\"Banka iÃ§in 'bank'<br/>KÄ±yÄ± iÃ§in 'bank'<br/>Ä°KÄ°SÄ° DE AYNI!\"]\n",
    "    \n",
    "    D --> G[\"âœ… BaÄŸlama gÃ¶re deÄŸiÅŸir\"]\n",
    "    G --> H1[\"CÃ¼mle 1:<br/>'deposit money at bank'<br/>â†’ Banka vektÃ¶rÃ¼\"]\n",
    "    G --> H2[\"CÃ¼mle 2:<br/>'river bank'<br/>â†’ KÄ±yÄ± vektÃ¶rÃ¼\"]\n",
    "    \n",
    "    F --> I[\"âŒ Sorun:<br/>Belirsizlik var\"]\n",
    "    H1 --> J[\"âœ… Avantaj:<br/>BaÄŸlamÄ± anlÄ±yor\"]\n",
    "    H2 --> J\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style C fill:#ffcdd2,stroke:#f44336,stroke-width:3px\n",
    "    style D fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style F fill:#ffcdd2,stroke:#f44336,stroke-width:2px\n",
    "    style H1 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style H2 fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style I fill:#ffcdd2,stroke:#f44336,stroke-width:3px\n",
    "    style J fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; padding: 20px; border-radius: 10px; border: 2px solid #4caf50;\">\n",
    "    <h3>âœ… ADIM 4 TamamlandÄ±!</h3>\n",
    "    <p style=\"font-size: 15px; margin-bottom: 0;\">BaÄŸlamsal (contextual) embedding kavramÄ±nÄ± ve statik embedding'den farkÄ±nÄ± Ã¶ÄŸrendik. Åimdi BERT'in eÄŸitim yÃ¶ntemlerinden MLM (Masked Language Modeling)'e geÃ§ebiliriz!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57998c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ ADIM 5: ğŸ­ MLM - Masked Language Modeling (Maskeli Dil Modelleme)\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; border-left: 5px solid #4caf50; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ’¡ Temel Fikir</h3>\n",
    "    <p style=\"font-size: 16px; margin: 0;\"><strong>BERT eÄŸitilirken bazÄ± kelimeler gizlenir ([MASK]), model bu gizli kelimeleri tahmin etmeye Ã§alÄ±ÅŸÄ±r!</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e2df5",
   "metadata": {},
   "source": [
    "## ğŸ¯ 5.1. MLM Nedir ve NasÄ±l Ã‡alÄ±ÅŸÄ±r?\n",
    "\n",
    "<div style=\"background-color: #fff3cd; border-left: 5px solid #ffc107; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ“ MLM (Masked Language Modeling) TanÄ±mÄ±</h3>\n",
    "    <p style=\"font-size: 15px;\">BERT'in Ã¶n eÄŸitim yÃ¶ntemlerinden biri. CÃ¼mledeki bazÄ± kelimeler gizlenir, model bu kelimeleri tahmin eder.</p>\n",
    "</div>\n",
    "\n",
    "### ğŸ“ Basit Ã–rnek:\n",
    "\n",
    "**Orijinal CÃ¼mle:**  \n",
    "\"Roma, Ä°talya'nÄ±n **baÅŸkenti**dir.\"\n",
    "\n",
    "**MaskelenmiÅŸ Hali:**  \n",
    "\"Roma, Ä°talya'nÄ±n **[MASK]**dir.\"\n",
    "\n",
    "**BERT'in GÃ¶revi:**  \n",
    "[MASK] yerine \"baÅŸkenti\" kelimesini tahmin etmek!\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"Orijinal:<br/>Roma Ä°talya'nÄ±n baÅŸkenti\"] --> B[\"Maskele\"]\n",
    "    B --> C[\"Roma Ä°talya'nÄ±n [MASK]\"]\n",
    "    C --> D[\"BERT<br/>Transformer\"]\n",
    "    D --> E[\"Tahmin:<br/>baÅŸkenti\"]\n",
    "    E --> F{DoÄŸru mu?}\n",
    "    F -->|Evet| G[\"âœ… Model Ã¶ÄŸrendi\"]\n",
    "    F -->|HayÄ±r| H[\"âŒ KaybÄ± hesapla,<br/>aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelle\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style C fill:#ffccbc,stroke:#ff5722,stroke-width:3px\n",
    "    style D fill:#e1bee7,stroke:#9c27b0,stroke-width:3px\n",
    "    style E fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style G fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style H fill:#ffcdd2,stroke:#f44336,stroke-width:2px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3fc06",
   "metadata": {},
   "source": [
    "## ğŸ² 5.2. Maskeleme Stratejisi: %80 / %10 / %10 KuralÄ±\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; border-left: 5px solid #2196f3; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>âš¡ Kritik Kural: Her Token AynÄ± Åekilde Maskelenmez!</h3>\n",
    "    <p style=\"font-size: 15px;\">BERT eÄŸitiminde token'larÄ±n <strong>%15'i</strong> \"tahmin edilecek aday\" olarak seÃ§ilir.</p>\n",
    "    <p style=\"font-size: 15px;\">Bu seÃ§ilen token'lar iÃ§in <strong>%80 / %10 / %10</strong> kuralÄ± uygulanÄ±r:</p>\n",
    "</div>\n",
    "\n",
    "### ğŸ“Š Maskeleme DaÄŸÄ±lÄ±mÄ±:\n",
    "\n",
    "| ğŸ² Oran | ğŸ”§ Ne YapÄ±lÄ±r? | ğŸ’¬ Ã–rnek | ğŸ¯ Neden? |\n",
    "|---------|---------------|----------|-----------|\n",
    "| **80%** | [MASK] ile deÄŸiÅŸtirilir | \"baÅŸkenti\" â†’ \"[MASK]\" | Normal maskeleme |\n",
    "| **10%** | Rastgele baÅŸka kelime | \"baÅŸkenti\" â†’ \"ÅŸehri\" | Model ÅŸaÅŸÄ±rtÄ±lÄ±r |\n",
    "| **10%** | HiÃ§ deÄŸiÅŸtirilmez | \"baÅŸkenti\" â†’ \"baÅŸkenti\" | GerÃ§ek metin gibi |\n",
    "\n",
    "### ğŸ¯ Neden Bu KarÄ±ÅŸÄ±m?\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"Token'larÄ±n %15'i seÃ§ilir\"] --> B{\"SeÃ§ilen token'lara ne olur?\"}\n",
    "    \n",
    "    B -->|80%| C[\"[MASK] ile deÄŸiÅŸtir\"]\n",
    "    B -->|10%| D[\"Rastgele kelime\"]\n",
    "    B -->|10%| E[\"OlduÄŸu gibi bÄ±rak\"]\n",
    "    \n",
    "    C --> F[\"Normal eÄŸitim\"]\n",
    "    D --> G[\"âš¡ Model ÅŸaÅŸÄ±rtÄ±lÄ±r<br/>Her token ÅŸÃ¼pheli!\"]\n",
    "    E --> H[\"ğŸ­ GerÃ§ek metin<br/>alÄ±ÅŸkanlÄ±ÄŸÄ±nÄ± kÄ±r\"]\n",
    "    \n",
    "    F --> I[\"âœ… SonuÃ§:<br/>Daha saÄŸlam model\"]\n",
    "    G --> I\n",
    "    H --> I\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style C fill:#ffccbc,stroke:#ff5722,stroke-width:2px\n",
    "    style D fill:#b3e5fc,stroke:#03a9f4,stroke-width:2px\n",
    "    style E fill:#c8e6c9,stroke:#4caf50,stroke-width:2px\n",
    "    style I fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "```\n",
    "\n",
    "<div style=\"background-color: #fff3cd; border-left: 5px solid #ffc107; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ’¡ Neden %80/%10/%10?</h3>\n",
    "    <ul style=\"font-size: 15px;\">\n",
    "        <li><strong>Sadece [MASK] kullanÄ±lsa:</strong> Model gerÃ§ek dÃ¼nyada [MASK] gÃ¶rmez, zorlanÄ±r</li>\n",
    "        <li><strong>KarÄ±ÅŸÄ±m kullanÄ±lÄ±nca:</strong> Model her token'Ä± analiz eder, daha dikkatli olur</li>\n",
    "        <li><strong>SonuÃ§:</strong> Fine-tuning'de daha iyi performans! âœ…</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203665bf",
   "metadata": {},
   "source": [
    "## ğŸ”® 5.3. MLM Tahmin MekanizmasÄ±: 30 Bin SeÃ§enekli SÄ±nav!\n",
    "\n",
    "<div style=\"background-color: #ffebee; border-left: 5px solid #f44336; padding: 15px; margin: 20px 0;\">\n",
    "    <h3>ğŸ¯ BERT NasÄ±l Tahmin Eder?</h3>\n",
    "    <p style=\"font-size: 15px;\">Maskeli token'Ä±n baÄŸlam vektÃ¶rÃ¼ alÄ±nÄ±r â†’ ÃœstÃ¼ne \"tahmin baÅŸlÄ±ÄŸÄ±\" (linear layer) eklenir â†’ <strong>30 bin boyutlu skor vektÃ¶rÃ¼</strong> Ã¼retilir (sÃ¶zlÃ¼kteki her token iÃ§in bir skor) â†’ Softmax ile olasÄ±lÄ±ÄŸa Ã§evrilir â†’ En yÃ¼ksek olasÄ±lÄ±klÄ± token seÃ§ilir!</p>\n",
    "</div>\n",
    "\n",
    "### ğŸ“ Matematiksel AkÄ±ÅŸ:\n",
    "\n",
    "```\n",
    "1. [MASK] pozisyonundaki baÄŸlam vektÃ¶rÃ¼: V_mask (768 boyut)\n",
    "                    â†“\n",
    "2. Linear Layer (Classification Head): W Ã— V_mask + b\n",
    "                    â†“\n",
    "3. 30,000 boyutlu skor vektÃ¶rÃ¼: [sâ‚, sâ‚‚, sâ‚ƒ, ..., sâ‚ƒâ‚€â‚€â‚€â‚€]\n",
    "                    â†“\n",
    "4. Softmax: P(token_i) = exp(sáµ¢) / Î£ exp(sâ±¼)\n",
    "                    â†“\n",
    "5. En yÃ¼ksek olasÄ±lÄ±klÄ± token: argmax(P)\n",
    "```\n",
    "\n",
    "### ğŸ“ 30 Bin SeÃ§enekli Ã‡oktan SeÃ§meli SÄ±nav Benzetmesi:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"[MASK] VektÃ¶rÃ¼<br/>768 boyut\"] --> B[\"Classification<br/>Head<br/>(Linear Layer)\"]\n",
    "    \n",
    "    B --> C[\"30,000 Token<br/>iÃ§in Skorlar\"]\n",
    "    \n",
    "    C --> D1[\"Token 1: 'the' â†’ -2.3\"]\n",
    "    C --> D2[\"Token 2: 'is' â†’ -1.5\"]\n",
    "    C --> D3[\"Token 3: 'capital' â†’ 8.7\"]\n",
    "    C --> D4[\"...\"]\n",
    "    C --> D5[\"Token 30000: '##ing' â†’ -3.2\"]\n",
    "    \n",
    "    D3 --> E[\"ğŸ† En YÃ¼ksek Skor\"]\n",
    "    \n",
    "    E --> F[\"Softmax<br/>OlasÄ±lÄ±ÄŸa Ã‡evir\"]\n",
    "    F --> G[\"P('capital') = 0.87<br/>P('city') = 0.09<br/>P('center') = 0.03\"]\n",
    "    \n",
    "    G --> H[\"âœ… Tahmin: 'capital'\"]\n",
    "    \n",
    "    style A fill:#fff9c4,stroke:#f57f17,stroke-width:3px\n",
    "    style B fill:#e1bee7,stroke:#9c27b0,stroke-width:3px\n",
    "    style C fill:#ffccbc,stroke:#ff5722,stroke-width:3px\n",
    "    style D3 fill:#c8e6c9,stroke:#4caf50,stroke-width:3px\n",
    "    style H fill:#bbdefb,stroke:#1976d2,stroke-width:3px\n",
    "```\n",
    "\n",
    "**Benzetme:** 30 bin ÅŸÄ±klÄ± bir sÄ±nav! Her ÅŸÄ±k (token) bir puan alÄ±r, en yÃ¼ksek puanlÄ± ÅŸÄ±k seÃ§ilir!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004bab3",
   "metadata": {},
   "source": [
    "## ğŸ’» 5.4. Pratik Ã–rnek: MLM ile Kelime Tahmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1db109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ­ MASKED LANGUAGE MODELING (MLM) DEMO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ Maskeli CÃ¼mle: Paris is the [MASK] of France.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ¯ [MASK] Pozisyonu: 4\n",
      "ğŸ”¤ Token'lar: ['[CLS]', 'paris', 'is', 'the', '[MASK]', 'of', 'france', '.', '[SEP]']\n",
      "\n",
      "ğŸ† TOP 5 TAHMÄ°NLER:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. 'capital     ' | Skor:   18.20 | OlasÄ±lÄ±k: 0.9969 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "2. 'heart       ' | Skor:   10.77 | OlasÄ±lÄ±k: 0.0006 \n",
      "3. 'center      ' | Skor:   10.47 | OlasÄ±lÄ±k: 0.0004 \n",
      "4. 'centre      ' | Skor:   10.21 | OlasÄ±lÄ±k: 0.0003 \n",
      "5. 'city        ' | Skor:    9.99 | OlasÄ±lÄ±k: 0.0003 \n",
      "\n",
      "ğŸ’¡ Model 'capital' kelimesini en yÃ¼ksek olasÄ±lÄ±kla tahmin etti!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ­ MLM Ã–rneÄŸi: BERT ile Kelime Tahmini\n",
    "\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# MLM iÃ§in eÄŸitilmiÅŸ BERT modelini yÃ¼kle\n",
    "mlm_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "mlm_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ­ MASKED LANGUAGE MODELING (MLM) DEMO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Maskeli cÃ¼mle\n",
    "masked_text = \"Paris is the [MASK] of France.\"\n",
    "\n",
    "print(f\"\\nğŸ“ Maskeli CÃ¼mle: {masked_text}\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Tokenize\n",
    "inputs = mlm_tokenizer(masked_text, return_tensors='pt')\n",
    "tokens = mlm_tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "# [MASK] pozisyonunu bul\n",
    "mask_position = tokens.index('[MASK]')\n",
    "print(f\"\\nğŸ¯ [MASK] Pozisyonu: {mask_position}\")\n",
    "print(f\"ğŸ”¤ Token'lar: {tokens}\")\n",
    "\n",
    "# Model tahmini\n",
    "with torch.no_grad():\n",
    "    outputs = mlm_model(**inputs)\n",
    "    predictions = outputs.logits\n",
    "\n",
    "# [MASK] pozisyonundaki tahminler\n",
    "mask_predictions = predictions[0, mask_position]\n",
    "\n",
    "# En yÃ¼ksek 5 tahmini al\n",
    "top_k = 5\n",
    "top_k_indices = torch.topk(mask_predictions, top_k).indices\n",
    "top_k_scores = torch.topk(mask_predictions, top_k).values\n",
    "top_k_tokens = [mlm_tokenizer.decode([idx]) for idx in top_k_indices]\n",
    "\n",
    "# Softmax ile olasÄ±lÄ±klara Ã§evir\n",
    "probabilities = torch.softmax(mask_predictions, dim=0)\n",
    "top_k_probs = [probabilities[idx].item() for idx in top_k_indices]\n",
    "\n",
    "print(f\"\\nğŸ† TOP {top_k} TAHMÄ°NLER:\")\n",
    "print(\"â”€\" * 70)\n",
    "for i, (token, score, prob) in enumerate(zip(top_k_tokens, top_k_scores, top_k_probs), 1):\n",
    "    bar = \"â–ˆ\" * int(prob * 50)\n",
    "    print(f\"{i}. '{token:12s}' | Skor: {score:7.2f} | OlasÄ±lÄ±k: {prob:.4f} {bar}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Model 'capital' kelimesini en yÃ¼ksek olasÄ±lÄ±kla tahmin etti!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472f5178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¨ Ã‡OKLU MASKELEME Ã–RNEÄÄ°\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ CÃ¼mle: The [MASK] is very [MASK] today.\n",
      "ğŸ¯ [MASK] PozisyonlarÄ±: [2, 5]\n",
      "\n",
      "ğŸ”® Her Maske iÃ§in Top 3 Tahmin:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "[MASK] #1 (pozisyon 2):\n",
      "  1. 'church    ' â†’ 0.1769\n",
      "  2. 'village   ' â†’ 0.0468\n",
      "  3. 'building  ' â†’ 0.0437\n",
      "\n",
      "[MASK] #2 (pozisyon 5):\n",
      "  1. 'active    ' â†’ 0.1908\n",
      "  2. 'old       ' â†’ 0.0780\n",
      "  3. 'popular   ' â†’ 0.0564\n",
      "\n",
      "ğŸ’¡ BERT her maskeyi baÄŸÄ±msÄ±z olarak tahmin etti!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¨ Ã‡oklu Maskeleme Ã–rneÄŸi\n",
    "\n",
    "multi_masked_text = \"The [MASK] is very [MASK] today.\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ¨ Ã‡OKLU MASKELEME Ã–RNEÄÄ°\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nğŸ“ CÃ¼mle: {multi_masked_text}\")\n",
    "\n",
    "# Tokenize\n",
    "inputs_multi = mlm_tokenizer(multi_masked_text, return_tensors='pt')\n",
    "tokens_multi = mlm_tokenizer.convert_ids_to_tokens(inputs_multi['input_ids'][0])\n",
    "\n",
    "# TÃ¼m [MASK] pozisyonlarÄ±nÄ± bul\n",
    "mask_positions = [i for i, token in enumerate(tokens_multi) if token == '[MASK]']\n",
    "print(f\"ğŸ¯ [MASK] PozisyonlarÄ±: {mask_positions}\")\n",
    "\n",
    "# Tahmin yap\n",
    "with torch.no_grad():\n",
    "    outputs_multi = mlm_model(**inputs_multi)\n",
    "    predictions_multi = outputs_multi.logits\n",
    "\n",
    "print(\"\\nğŸ”® Her Maske iÃ§in Top 3 Tahmin:\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "for idx, mask_pos in enumerate(mask_positions, 1):\n",
    "    mask_preds = predictions_multi[0, mask_pos]\n",
    "    top_3_indices = torch.topk(mask_preds, 3).indices\n",
    "    top_3_tokens = [mlm_tokenizer.decode([i]) for i in top_3_indices]\n",
    "    \n",
    "    probs = torch.softmax(mask_preds, dim=0)\n",
    "    top_3_probs = [probs[i].item() for i in top_3_indices]\n",
    "    \n",
    "    print(f\"\\n[MASK] #{idx} (pozisyon {mask_pos}):\")\n",
    "    for i, (token, prob) in enumerate(zip(top_3_tokens, top_3_probs), 1):\n",
    "        print(f\"  {i}. '{token:10s}' â†’ {prob:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ BERT her maskeyi baÄŸÄ±msÄ±z olarak tahmin etti!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc64d7c",
   "metadata": {},
   "source": [
    "### 5.5 ğŸ¢ YBS UygulamasÄ±: E-Ticaret Ä°nceleme Tamamlama\n",
    "\n",
    "<div style=\"border-left: 5px solid #e91e63; background: linear-gradient(to right, #fce4ec, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "#### ğŸ’¼ Senaryo: Eksik MÃ¼ÅŸteri Ä°ncelemeleri\n",
    "\n",
    "Bir e-ticaret platformunda mÃ¼ÅŸteriler ara sÄ±ra **yarÄ±m bÄ±rakÄ±lmÄ±ÅŸ** incelemeler yazÄ±yor. MLM ile bu incelemeleri:\n",
    "\n",
    "- ğŸ“ **Otomatik tamamlayabilir** (Ã¶neride bulunma)\n",
    "- ğŸ¯ **Sentiment analizi** yapabilir (pozitif/negatif kelime tahmini)\n",
    "- ğŸ” **Spam tespiti** yapabilir (anormal kelime kullanÄ±mÄ±)\n",
    "\n",
    "</div>\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"ğŸ“ MÃ¼ÅŸteri Ä°ncelemesi<br/>The product quality is [MASK]\"] --> B[\"ğŸ¤– BERT MLM\"]\n",
    "    B --> C1[\"âœ… excellent (0.42)\"]\n",
    "    B --> C2[\"âœ… great (0.28)\"]\n",
    "    B --> C3[\"âœ… good (0.15)\"]\n",
    "    B --> C4[\"âš ï¸ poor (0.08)\"]\n",
    "    B --> C5[\"âš ï¸ terrible (0.07)\"]\n",
    "    \n",
    "    C1 --> D[\"ğŸ˜Š Pozitif Tahminler<br/>Topla: 0.85\"]\n",
    "    C2 --> D\n",
    "    C3 --> D\n",
    "    \n",
    "    C4 --> E[\"ğŸ˜ Negatif Tahminler<br/>Topla: 0.15\"]\n",
    "    C5 --> E\n",
    "    \n",
    "    D --> F[\"ğŸ“Š Sentiment: POZÄ°TÄ°F (85%)\"]\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#e1bee7\n",
    "    style C1 fill:#c8e6c9\n",
    "    style C2 fill:#c8e6c9\n",
    "    style C3 fill:#c8e6c9\n",
    "    style C4 fill:#ffccbc\n",
    "    style C5 fill:#ffccbc\n",
    "    style D fill:#a5d6a7\n",
    "    style E fill:#ef9a9a\n",
    "    style F fill:#81c784\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dac18d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ›ï¸ E-TÄ°CARET Ä°NCELEME ANALÄ°ZÄ° - SENTIMENT TAHMÄ°NÄ°\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Ä°nceleme: \"The product quality is [MASK]\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”® Top 5 Tahmin:\n",
      "  1. '.           ' â†’ 0.8338 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ˜ [NÃ–TR]\n",
      "  2. ';           ' â†’ 0.1285 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ˜ [NÃ–TR]\n",
      "  3. '|           ' â†’ 0.0268 â–ˆ ğŸ˜ [NÃ–TR]\n",
      "  4. '?           ' â†’ 0.0060  ğŸ˜ [NÃ–TR]\n",
      "  5. '!           ' â†’ 0.0039  ğŸ˜ [NÃ–TR]\n",
      "\n",
      "ğŸ“Š Sentiment Analizi:\n",
      "   âœ… Pozitif Skor: 0.0000 (0.0%)\n",
      "   âŒ Negatif Skor: 0.0000 (0.0%)\n",
      "   ğŸ¯ Genel Sentiment: NÃ–TR âš–ï¸ (50.0% gÃ¼ven)\n",
      "\n",
      "ğŸ“ Ä°nceleme: \"Customer service was [MASK]\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”® Top 5 Tahmin:\n",
      "  1. '.           ' â†’ 0.8633 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ˜ [NÃ–TR]\n",
      "  2. ';           ' â†’ 0.1196 â–ˆâ–ˆâ–ˆâ–ˆ ğŸ˜ [NÃ–TR]\n",
      "  3. 'good        ' â†’ 0.0041  ğŸ˜Š [POZÄ°TÄ°F]\n",
      "  4. '?           ' â†’ 0.0038  ğŸ˜ [NÃ–TR]\n",
      "  5. '!           ' â†’ 0.0019  ğŸ˜ [NÃ–TR]\n",
      "\n",
      "ğŸ“Š Sentiment Analizi:\n",
      "   âœ… Pozitif Skor: 0.0041 (0.4%)\n",
      "   âŒ Negatif Skor: 0.0000 (0.0%)\n",
      "   ğŸ¯ Genel Sentiment: POZÄ°TÄ°F âœ… (100.0% gÃ¼ven)\n",
      "\n",
      "ğŸ“ Ä°nceleme: \"Delivery speed is [MASK]\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”® Top 5 Tahmin:\n",
      "  1. '.           ' â†’ 0.8729 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ˜ [NÃ–TR]\n",
      "  2. ';           ' â†’ 0.1017 â–ˆâ–ˆâ–ˆâ–ˆ ğŸ˜ [NÃ–TR]\n",
      "  3. '|           ' â†’ 0.0188  ğŸ˜ [NÃ–TR]\n",
      "  4. '?           ' â†’ 0.0039  ğŸ˜ [NÃ–TR]\n",
      "  5. '!           ' â†’ 0.0008  ğŸ˜ [NÃ–TR]\n",
      "\n",
      "ğŸ“Š Sentiment Analizi:\n",
      "   âœ… Pozitif Skor: 0.0000 (0.0%)\n",
      "   âŒ Negatif Skor: 0.0000 (0.0%)\n",
      "   ğŸ¯ Genel Sentiment: NÃ–TR âš–ï¸ (50.0% gÃ¼ven)\n",
      "\n",
      "ğŸ“ Ä°nceleme: \"I am very [MASK] with my purchase\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”® Top 5 Tahmin:\n",
      "  1. 'pleased     ' â†’ 0.6376 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ˜ [NÃ–TR]\n",
      "  2. 'happy       ' â†’ 0.1300 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ˜Š [POZÄ°TÄ°F]\n",
      "  3. 'satisfied   ' â†’ 0.0549 â–ˆâ–ˆ ğŸ˜Š [POZÄ°TÄ°F]\n",
      "  4. 'careful     ' â†’ 0.0338 â–ˆ ğŸ˜ [NÃ–TR]\n",
      "  5. 'concerned   ' â†’ 0.0187  ğŸ˜ [NÃ–TR]\n",
      "\n",
      "ğŸ“Š Sentiment Analizi:\n",
      "   âœ… Pozitif Skor: 0.1849 (18.5%)\n",
      "   âŒ Negatif Skor: 0.0000 (0.0%)\n",
      "   ğŸ¯ Genel Sentiment: POZÄ°TÄ°F âœ… (100.0% gÃ¼ven)\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¡ MLM ile BERT, kelimenin baÄŸlamÄ±nÄ± anlayarak en uygun tahminde bulunuyor!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ›ï¸ YBS Ã–rneÄŸi: E-Ticaret Ä°nceleme Analizi\n",
    "\n",
    "ecommerce_reviews = [\n",
    "    \"The product quality is [MASK]\",\n",
    "    \"Customer service was [MASK]\",\n",
    "    \"Delivery speed is [MASK]\",\n",
    "    \"I am very [MASK] with my purchase\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ›ï¸ E-TÄ°CARET Ä°NCELEME ANALÄ°ZÄ° - SENTIMENT TAHMÄ°NÄ°\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Pozitif ve negatif kelimeler listesi\n",
    "positive_words = {'excellent', 'great', 'good', 'amazing', 'satisfied', 'happy', 'fast', 'quick'}\n",
    "negative_words = {'poor', 'terrible', 'bad', 'awful', 'disappointed', 'slow', 'delayed'}\n",
    "\n",
    "for review in ecommerce_reviews:\n",
    "    print(f\"\\nğŸ“ Ä°nceleme: \\\"{review}\\\"\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Tokenize ve tahmin\n",
    "    inputs = mlm_tokenizer(review, return_tensors='pt')\n",
    "    tokens = mlm_tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    mask_index = tokens.index('[MASK]')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = mlm_model(**inputs)\n",
    "        predictions = outputs.logits\n",
    "    \n",
    "    # Top 5 tahmin al\n",
    "    mask_token_logits = predictions[0, mask_index]\n",
    "    top_5_indices = torch.topk(mask_token_logits, 5).indices\n",
    "    top_5_tokens = [mlm_tokenizer.decode([i]).strip() for i in top_5_indices]\n",
    "    \n",
    "    # OlasÄ±lÄ±klarÄ± hesapla\n",
    "    probs = torch.softmax(mask_token_logits, dim=0)\n",
    "    top_5_probs = [probs[i].item() for i in top_5_indices]\n",
    "    \n",
    "    # Sentiment analizi\n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "    \n",
    "    print(\"\\nğŸ”® Top 5 Tahmin:\")\n",
    "    for i, (token, prob) in enumerate(zip(top_5_tokens, top_5_probs), 1):\n",
    "        # Sentiment belirleme\n",
    "        sentiment_icon = \"\"\n",
    "        if token in positive_words:\n",
    "            sentiment_icon = \"ğŸ˜Š [POZÄ°TÄ°F]\"\n",
    "            positive_score += prob\n",
    "        elif token in negative_words:\n",
    "            sentiment_icon = \"ğŸ˜ [NEGATÄ°F]\"\n",
    "            negative_score += prob\n",
    "        else:\n",
    "            sentiment_icon = \"ğŸ˜ [NÃ–TR]\"\n",
    "        \n",
    "        # Skor Ã§ubuÄŸu\n",
    "        bar = \"â–ˆ\" * int(prob * 40)\n",
    "        print(f\"  {i}. '{token:12s}' â†’ {prob:.4f} {bar} {sentiment_icon}\")\n",
    "    \n",
    "    # Genel sentiment\n",
    "    print(f\"\\nğŸ“Š Sentiment Analizi:\")\n",
    "    print(f\"   âœ… Pozitif Skor: {positive_score:.4f} ({positive_score*100:.1f}%)\")\n",
    "    print(f\"   âŒ Negatif Skor: {negative_score:.4f} ({negative_score*100:.1f}%)\")\n",
    "    \n",
    "    if positive_score > negative_score:\n",
    "        sentiment = \"POZÄ°TÄ°F âœ…\"\n",
    "        confidence = positive_score / (positive_score + negative_score) * 100\n",
    "    elif negative_score > positive_score:\n",
    "        sentiment = \"NEGATÄ°F âŒ\"\n",
    "        confidence = negative_score / (positive_score + negative_score) * 100\n",
    "    else:\n",
    "        sentiment = \"NÃ–TR âš–ï¸\"\n",
    "        confidence = 50\n",
    "    \n",
    "    print(f\"   ğŸ¯ Genel Sentiment: {sentiment} ({confidence:.1f}% gÃ¼ven)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ’¡ MLM ile BERT, kelimenin baÄŸlamÄ±nÄ± anlayarak en uygun tahminde bulunuyor!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c4e55",
   "metadata": {},
   "source": [
    "### 5.6 ğŸ¯ MLM SÃ¼reÃ§ Ã–zeti\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ“„ Orijinal CÃ¼mle<br/>The cat sat on the mat\"] --> B[\"ğŸ² Maskeleme<br/>15% token seÃ§\"]\n",
    "    B --> C[\"ğŸ­ 80%<br/>[MASK] ile deÄŸiÅŸtir\"]\n",
    "    B --> D[\"ğŸ² 10%<br/>Random token\"]\n",
    "    B --> E[\"âœ‹ 10%<br/>DeÄŸiÅŸtirme\"]\n",
    "    \n",
    "    C --> F[\"The [MASK] sat on the mat\"]\n",
    "    D --> G[\"The dog sat on the mat\"]\n",
    "    E --> H[\"The cat sat on the mat\"]\n",
    "    \n",
    "    F --> I[\"ğŸ¤– BERT Model<br/>12 Transformer Layer\"]\n",
    "    G --> I\n",
    "    H --> I\n",
    "    \n",
    "    I --> J[\"ğŸ“Š Softmax<br/>30,000 vocab Ã¼zerinde\"]\n",
    "    J --> K[\"ğŸ¯ Top Tahminler:<br/>1. cat (0.45)<br/>2. dog (0.28)<br/>3. animal (0.15)\"]\n",
    "    \n",
    "    K --> L[\"ğŸ“ˆ Cross-Entropy Loss<br/>GerÃ§ek: cat<br/>-log(0.45) = 0.798\"]\n",
    "    \n",
    "    L --> M[\"âš™ï¸ Backpropagation<br/>AÄŸÄ±rlÄ±klarÄ± GÃ¼ncelle\"]\n",
    "    M --> N[\"ğŸ”„ Sonraki Batch\"]\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#e1bee7\n",
    "    style C fill:#ffccbc\n",
    "    style D fill:#ffccbc\n",
    "    style E fill:#ffccbc\n",
    "    style F fill:#b3e5fc\n",
    "    style G fill:#b3e5fc\n",
    "    style H fill:#b3e5fc\n",
    "    style I fill:#c8e6c9\n",
    "    style J fill:#f8bbd0\n",
    "    style K fill:#a5d6a7\n",
    "    style L fill:#ffab91\n",
    "    style M fill:#ce93d8\n",
    "    style N fill:#81c784\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ecc0e8",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 25px; border-radius: 15px; text-align: center; color: white; font-size: 20px; font-weight: bold; box-shadow: 0 4px 15px rgba(0,0,0,0.2); margin: 30px 0;\">\n",
    "    âœ… ADIM 5 TAMAMLANDI: MLM (Masked Language Modeling) ğŸ­\n",
    "</div>\n",
    "\n",
    "**Bu adÄ±mda Ã¶ÄŸrendiklerimiz:**\n",
    "\n",
    "- ğŸ­ **MLM Konsepti**: BERT'in temel eÄŸitim mekanizmasÄ±\n",
    "- ğŸ² **80/10/10 KuralÄ±**: Maskeleme stratejisi ve nedenleri\n",
    "- ğŸ¯ **30 Bin SeÃ§enek**: Softmax ile olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±\n",
    "- ğŸ’» **Pratik KullanÄ±m**: `BertForMaskedLM` ile kelime tahmini\n",
    "- ğŸ›ï¸ **YBS UygulamasÄ±**: E-ticaret sentiment analizi\n",
    "- ğŸ”„ **EÄŸitim DÃ¶ngÃ¼sÃ¼**: Maskeleme â†’ Tahmin â†’ Loss â†’ Backpropagation\n",
    "\n",
    "MLM sayesinde BERT, kelimelerin **baÄŸlamsal anlamÄ±nÄ±** Ã¶ÄŸreniyor ve bu bilgiyi transfer edebiliyor! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125c7f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 30px; border-radius: 20px; text-align: center; margin: 40px 0; box-shadow: 0 10px 30px rgba(0,0,0,0.3);\">\n",
    "    <h1 style=\"color: white; font-size: 42px; margin: 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">\n",
    "        ğŸ”— ADIM 6\n",
    "    </h1>\n",
    "    <h2 style=\"color: white; font-size: 28px; margin: 10px 0 0 0; font-weight: normal;\">\n",
    "        NSP (Next Sentence Prediction)\n",
    "    </h2>\n",
    "    <p style=\"color: rgba(255,255,255,0.9); font-size: 18px; margin: 15px 0 0 0;\">\n",
    "        CÃ¼mleler ArasÄ±ndaki Ä°liÅŸkiyi Ã–ÄŸrenmek\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488cd28a",
   "metadata": {},
   "source": [
    "### 6.1 ğŸ”— NSP Nedir?\n",
    "\n",
    "<div style=\"border-left: 5px solid #9c27b0; background: linear-gradient(to right, #f3e5f5, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "**NSP (Next Sentence Prediction)**, BERT'in **ikinci eÄŸitim gÃ¶revi**dir. AmacÄ±:\n",
    "\n",
    "> **\"CÃ¼mle B, CÃ¼mle A'nÄ±n devamÄ± mÄ±?\"** sorusunu yanÄ±tlamak\n",
    "\n",
    "Bu gÃ¶rev sayesinde BERT:\n",
    "- ğŸ“š **CÃ¼mleler arasÄ± iliÅŸkiyi** anlayabilir\n",
    "- ğŸ” **BaÄŸlam tutarlÄ±lÄ±ÄŸÄ±nÄ±** kavrayabilir\n",
    "- ğŸ’¬ **Soru-Cevap (QA)** gÃ¶revlerinde baÅŸarÄ±lÄ± olabilir\n",
    "- ğŸ“Š **DoÄŸal Dil Ã‡Ä±karÄ±mÄ± (NLI)** yapabilir\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ¯ NSP'nin Temel MantÄ±ÄŸÄ±\n",
    "\n",
    "MLM **kelime dÃ¼zeyinde** Ã§alÄ±ÅŸÄ±rken, NSP **cÃ¼mle dÃ¼zeyinde** Ã§alÄ±ÅŸÄ±r:\n",
    "\n",
    "| Ã–zellik | MLM | NSP |\n",
    "|---------|-----|-----|\n",
    "| **Seviye** | ğŸ”¤ Kelime/Token | ğŸ“„ CÃ¼mle |\n",
    "| **AmaÃ§** | MaskelenmiÅŸ kelimeyi tahmin et | B cÃ¼mlesi A'nÄ±n devamÄ± mÄ±? |\n",
    "| **Ã‡Ä±ktÄ±** | 30,000 seÃ§enek (vocab) | 2 seÃ§enek (Evet/HayÄ±r) |\n",
    "| **Token** | Her pozisyon | Sadece [CLS] |\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"ğŸ“ CÃ¼mle A<br/>Paris is the capital\"] --> SEP1[\"[SEP]\"]\n",
    "    SEP1 --> B[\"ğŸ“ CÃ¼mle B<br/>of France\"]\n",
    "    \n",
    "    B --> SEP2[\"[SEP]\"]\n",
    "    SEP2 --> C[\"ğŸ¤– BERT\"]\n",
    "    \n",
    "    C --> D[\"ğŸ¯ [CLS] Token<br/>Pooler Output\"]\n",
    "    \n",
    "    D --> E{\"ğŸ”® Binary Classifier\"}\n",
    "    \n",
    "    E -->|50% olasÄ±lÄ±k| F[\"âœ… IsNext<br/>B, A'nÄ±n devamÄ±\"]\n",
    "    E -->|50% olasÄ±lÄ±k| G[\"âŒ NotNext<br/>B, A'nÄ±n devamÄ± DEÄÄ°L\"]\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#fff9c4\n",
    "    style SEP1 fill:#ffccbc\n",
    "    style SEP2 fill:#ffccbc\n",
    "    style C fill:#e1bee7\n",
    "    style D fill:#b3e5fc\n",
    "    style E fill:#f8bbd0\n",
    "    style F fill:#c8e6c9\n",
    "    style G fill:#ffab91\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4779cacc",
   "metadata": {},
   "source": [
    "### 6.2 ğŸ² NSP Veri HazÄ±rlama: 50/50 Stratejisi\n",
    "\n",
    "<div style=\"border-left: 5px solid #673ab7; background: linear-gradient(to right, #ede7f6, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "NSP iÃ§in eÄŸitim verisi **Ã¶zel bir ÅŸekilde** hazÄ±rlanÄ±r:\n",
    "\n",
    "#### âœ… %50 - IsNext (GerÃ§ek Devam)\n",
    "\n",
    "DokÃ¼manlardan **ardÄ±ÅŸÄ±k cÃ¼mle Ã§iftleri** alÄ±nÄ±r:\n",
    "\n",
    "```\n",
    "CÃ¼mle A: \"The weather is nice today.\"\n",
    "CÃ¼mle B: \"Let's go for a walk.\"  âœ… GerÃ§ek devam\n",
    "Label: IsNext (1)\n",
    "```\n",
    "\n",
    "#### âŒ %50 - NotNext (Rastgele CÃ¼mle)\n",
    "\n",
    "CÃ¼mle B, **farklÄ± bir dokÃ¼mantan** rastgele seÃ§ilir:\n",
    "\n",
    "```\n",
    "CÃ¼mle A: \"The weather is nice today.\"\n",
    "CÃ¼mle B: \"Python is a programming language.\" âŒ Rastgele\n",
    "Label: NotNext (0)\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ“Š Veri HazÄ±rlama SÃ¼reci\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ“š BÃ¼yÃ¼k Metin Korpusu<br/>(Wikipedia, Books, etc.)\"] --> B{\"ğŸ² Rastgele SeÃ§<br/>50/50\"}\n",
    "    \n",
    "    B -->|50%| C[\"âœ… IsNext OluÅŸtur\"]\n",
    "    B -->|50%| D[\"âŒ NotNext OluÅŸtur\"]\n",
    "    \n",
    "    C --> E[\"ğŸ“„ DokÃ¼mandan<br/>ArdÄ±ÅŸÄ±k 2 CÃ¼mle Al\"]\n",
    "    E --> F[\"A: CÃ¼mle 1<br/>B: CÃ¼mle 2<br/>Label: 1\"]\n",
    "    \n",
    "    D --> G[\"ğŸ“„ A: Dokuman1'den<br/>B: Dokuman2'den<br/>(Rastgele)\"]\n",
    "    G --> H[\"A: CÃ¼mle X<br/>B: CÃ¼mle Y<br/>Label: 0\"]\n",
    "    \n",
    "    F --> I[\"ğŸ¯ BERT EÄŸitim Verisi\"]\n",
    "    H --> I\n",
    "    \n",
    "    I --> J[\"[CLS] A [SEP] B [SEP]<br/>+ Label\"]\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#e1bee7\n",
    "    style C fill:#c8e6c9\n",
    "    style D fill:#ffab91\n",
    "    style E fill:#b3e5fc\n",
    "    style F fill:#a5d6a7\n",
    "    style G fill:#ffccbc\n",
    "    style H fill:#ef9a9a\n",
    "    style I fill:#ce93d8\n",
    "    style J fill:#81c784\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948474b",
   "metadata": {},
   "source": [
    "### 6.3 ğŸ¯ [CLS] Token'Ä±n RolÃ¼\n",
    "\n",
    "<div style=\"border-left: 5px solid #3f51b5; background: linear-gradient(to right, #e8eaf6, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "NSP gÃ¶revinde **[CLS] token** Ã§ok Ã¶nemlidir:\n",
    "\n",
    "#### ğŸ”‘ Neden [CLS]?\n",
    "\n",
    "1. **ğŸ“ Sabit Pozisyon**: Her zaman ilk pozisyonda\n",
    "2. **ğŸ¯ Ã–zet TaÅŸÄ±r**: TÃ¼m cÃ¼mle Ã§iftinin Ã¶zetini iÃ§erir\n",
    "3. **ğŸ’¡ Pooler Output**: BERT'in Ã¶zel bir Ã§Ä±ktÄ±sÄ±\n",
    "4. **ğŸ”® Tek VektÃ¶r**: TÃ¼m giriÅŸi temsil eden 768-boyutlu vektÃ¶r\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ—ï¸ [CLS] Token'dan Tahmine Giden Yol\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"[CLS] Sentence A [SEP] Sentence B [SEP]\"] --> B[\"ğŸ¤– BERT<br/>12 Transformer Layer\"]\n",
    "    \n",
    "    B --> C[\"ğŸ“Š 12 Layer'dan<br/>768-boyutlu vektÃ¶rler\"]\n",
    "    \n",
    "    C --> D[\"ğŸ¯ [CLS] Position<br/>Son Layer'dan<br/>768-dim vector\"]\n",
    "    \n",
    "    D --> E[\"ğŸ”„ Pooler Layer<br/>768 â†’ 768<br/>(Linear + Tanh)\"]\n",
    "    \n",
    "    E --> F[\"ğŸ“‰ Classification Head<br/>768 â†’ 2<br/>(Linear Layer)\"]\n",
    "    \n",
    "    F --> G[\"ğŸ² Softmax<br/>[IsNext_prob, NotNext_prob]\"]\n",
    "    \n",
    "    G --> H[\"âœ… IsNext: 0.85<br/>âŒ NotNext: 0.15\"]\n",
    "    \n",
    "    H --> I{\"ğŸ¯ Tahmin:<br/>IsNext\"}\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#e1bee7\n",
    "    style C fill:#b3e5fc\n",
    "    style D fill:#ffccbc\n",
    "    style E fill:#c8e6c9\n",
    "    style F fill:#f8bbd0\n",
    "    style G fill:#ce93d8\n",
    "    style H fill:#a5d6a7\n",
    "    style I fill:#81c784\n",
    "```\n",
    "\n",
    "#### ğŸ“ Matematiksel SÃ¼reÃ§\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{[CLS]}_{\\text{final}} &= \\text{BERT}(\\text{input})_0 && \\text{(Ä°lk pozisyon)} \\\\\n",
    "\\text{pooled} &= \\tanh(\\mathbf{W}_p \\cdot \\text{[CLS]}_{\\text{final}} + \\mathbf{b}_p) && \\text{(Pooler)} \\\\\n",
    "\\text{logits} &= \\mathbf{W}_c \\cdot \\text{pooled} + \\mathbf{b}_c && \\text{(Classifier)} \\\\\n",
    "P(\\text{IsNext}) &= \\frac{e^{\\text{logits}_1}}{e^{\\text{logits}_0} + e^{\\text{logits}_1}} && \\text{(Softmax)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e74fc",
   "metadata": {},
   "source": [
    "### 6.4 ğŸ’» Pratik Ã–rnek: NSP ile CÃ¼mle Ä°liÅŸkisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88f2a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ”— NSP (NEXT SENTENCE PREDICTION) Ã–RNEÄÄ°\n",
      "================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Test 1\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CÃ¼mle A: \"I love reading books.\"\n",
      "CÃ¼mle B: \"My favorite genre is science fiction.\"\n",
      "Beklenen: IsNext âœ…\n",
      "\n",
      "ğŸ”¤ Tokenlar:\n",
      "   [CLS] i love reading books . [SEP] my favorite genre is science fiction . [SEP]\n",
      "\n",
      "ğŸ”® BERT Tahmini:\n",
      "   IsNext (0):  1.0000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NotNext (1): 0.0000 \n",
      "\n",
      "ğŸ¯ Tahmin: IsNext âœ…\n",
      "âœ“ DoÄŸru!\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Test 2\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CÃ¼mle A: \"I love reading books.\"\n",
      "CÃ¼mle B: \"The weather is nice today.\"\n",
      "Beklenen: NotNext âŒ\n",
      "\n",
      "ğŸ”¤ Tokenlar:\n",
      "   [CLS] i love reading books . [SEP] the weather is nice today . [SEP]\n",
      "\n",
      "ğŸ”® BERT Tahmini:\n",
      "   IsNext (0):  0.9991 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NotNext (1): 0.0009 \n",
      "\n",
      "ğŸ¯ Tahmin: IsNext âœ…\n",
      "âœ— YanlÄ±ÅŸ!\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Test 3\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CÃ¼mle A: \"The company announced record profits.\"\n",
      "CÃ¼mle B: \"The stock price increased by 15%.\"\n",
      "Beklenen: IsNext âœ…\n",
      "\n",
      "ğŸ”¤ Tokenlar:\n",
      "   [CLS] the company announced record profits . [SEP] the stock price increased by 15 % . [SEP]\n",
      "\n",
      "ğŸ”® BERT Tahmini:\n",
      "   IsNext (0):  1.0000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NotNext (1): 0.0000 \n",
      "\n",
      "ğŸ¯ Tahmin: IsNext âœ…\n",
      "âœ“ DoÄŸru!\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Test 4\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CÃ¼mle A: \"The company announced record profits.\"\n",
      "CÃ¼mle B: \"Pizza is my favorite food.\"\n",
      "Beklenen: NotNext âŒ\n",
      "\n",
      "ğŸ”¤ Tokenlar:\n",
      "   [CLS] the company announced record profits . [SEP] pizza is my favorite food . [SEP]\n",
      "\n",
      "ğŸ”® BERT Tahmini:\n",
      "   IsNext (0):  0.0007 \n",
      "   NotNext (1): 0.9993 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ğŸ¯ Tahmin: NotNext âŒ\n",
      "âœ“ DoÄŸru!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”— NSP Ã–rneÄŸi: CÃ¼mle Ä°liÅŸkisi Tahmini\n",
    "\n",
    "from transformers import BertForNextSentencePrediction\n",
    "import torch\n",
    "\n",
    "# NSP iÃ§in eÄŸitilmiÅŸ BERT modelini yÃ¼kle\n",
    "nsp_model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "nsp_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ”— NSP (NEXT SENTENCE PREDICTION) Ã–RNEÄÄ°\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test Ã¶rnekleri: IsNext ve NotNext\n",
    "test_pairs = [\n",
    "    {\n",
    "        \"sentence_a\": \"I love reading books.\",\n",
    "        \"sentence_b\": \"My favorite genre is science fiction.\",\n",
    "        \"expected\": \"IsNext âœ…\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence_a\": \"I love reading books.\",\n",
    "        \"sentence_b\": \"The weather is nice today.\",\n",
    "        \"expected\": \"NotNext âŒ\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence_a\": \"The company announced record profits.\",\n",
    "        \"sentence_b\": \"The stock price increased by 15%.\",\n",
    "        \"expected\": \"IsNext âœ…\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence_a\": \"The company announced record profits.\",\n",
    "        \"sentence_b\": \"Pizza is my favorite food.\",\n",
    "        \"expected\": \"NotNext âŒ\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for idx, pair in enumerate(test_pairs, 1):\n",
    "    sent_a = pair['sentence_a']\n",
    "    sent_b = pair['sentence_b']\n",
    "    expected = pair['expected']\n",
    "    \n",
    "    print(f\"\\n{'â”€' * 80}\")\n",
    "    print(f\"ğŸ“ Test {idx}\")\n",
    "    print(f\"{'â”€' * 80}\")\n",
    "    print(f\"CÃ¼mle A: \\\"{sent_a}\\\"\")\n",
    "    print(f\"CÃ¼mle B: \\\"{sent_b}\\\"\")\n",
    "    print(f\"Beklenen: {expected}\")\n",
    "    \n",
    "    # Tokenize - NSP iÃ§in encode_plus kullan\n",
    "    encoding = nsp_tokenizer.encode_plus(\n",
    "        sent_a,\n",
    "        sent_b,\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    # Token yapÄ±sÄ±nÄ± gÃ¶ster\n",
    "    tokens = nsp_tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "    print(f\"\\nğŸ”¤ Tokenlar:\")\n",
    "    print(f\"   {' '.join(tokens)}\")\n",
    "    \n",
    "    # NSP tahmini yap\n",
    "    with torch.no_grad():\n",
    "        outputs = nsp_model(**encoding)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Softmax ile olasÄ±lÄ±klarÄ± hesapla\n",
    "    probs = torch.softmax(logits, dim=1)[0]\n",
    "    \n",
    "    # Tahmin\n",
    "    prediction_idx = torch.argmax(probs).item()\n",
    "    prediction = \"IsNext âœ…\" if prediction_idx == 0 else \"NotNext âŒ\"\n",
    "    \n",
    "    # SonuÃ§larÄ± gÃ¶ster\n",
    "    print(f\"\\nğŸ”® BERT Tahmini:\")\n",
    "    print(f\"   IsNext (0):  {probs[0]:.4f} {'â–ˆ' * int(probs[0] * 40)}\")\n",
    "    print(f\"   NotNext (1): {probs[1]:.4f} {'â–ˆ' * int(probs[1] * 40)}\")\n",
    "    print(f\"\\nğŸ¯ Tahmin: {prediction}\")\n",
    "    print(f\"âœ“ DoÄŸru!\" if prediction == expected else \"âœ— YanlÄ±ÅŸ!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9415824",
   "metadata": {},
   "source": [
    "### 6.5 ğŸ¢ YBS UygulamasÄ±: Destek Talebi EÅŸleÅŸtirme\n",
    "\n",
    "<div style=\"border-left: 5px solid #2196f3; background: linear-gradient(to right, #e3f2fd, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "#### ğŸ’¼ Senaryo: MÃ¼ÅŸteri Destek Sistemi\n",
    "\n",
    "Bir e-ticaret ÅŸirketinde mÃ¼ÅŸteri destek talepleri ve Ã§Ã¶zÃ¼m Ã¶nerileri eÅŸleÅŸtirilmeli:\n",
    "\n",
    "**KullanÄ±m AlanlarÄ±:**\n",
    "- ğŸ« **Ticket Routing**: Talebi doÄŸru departmana yÃ¶nlendirme\n",
    "- ğŸ¤– **Otomatik YanÄ±t**: Soruya uygun hazÄ±r yanÄ±t bulma\n",
    "- ğŸ“š **KB Matching**: Knowledge Base'den ilgili makale Ã¶nerme\n",
    "- ğŸ”— **Duplicate Detection**: Benzer talepleri birleÅŸtirme\n",
    "\n",
    "</div>\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"ğŸ“§ MÃ¼ÅŸteri Talebi<br/>Product not working\"] --> B[\"ğŸ¤– NSP Sistemi\"]\n",
    "    \n",
    "    B --> C1[\"âœ… Ã‡Ã¶zÃ¼m 1<br/>Try reset button<br/>(0.89)\"]\n",
    "    B --> C2[\"âŒ Ã‡Ã¶zÃ¼m 2<br/>Update billing info<br/>(0.11)\"]\n",
    "    B --> C3[\"âœ… Ã‡Ã¶zÃ¼m 3<br/>Check power cable<br/>(0.87)\"]\n",
    "    \n",
    "    C1 --> D[\"ğŸ¯ Top 2 EÅŸleÅŸme\"]\n",
    "    C3 --> D\n",
    "    \n",
    "    D --> E[\"ğŸ“¨ MÃ¼ÅŸteriye Ã–ner\"]\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#e1bee7\n",
    "    style C1 fill:#c8e6c9\n",
    "    style C2 fill:#ffab91\n",
    "    style C3 fill:#c8e6c9\n",
    "    style D fill:#b3e5fc\n",
    "    style E fill:#81c784\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8612dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "ğŸ« MÃœÅTER Ä° DESTEK TALEBÄ° EÅLEÅTÄ°RME SÄ°STEMÄ°\n",
      "==========================================================================================\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“§ TALEP #1: \"My laptop won't turn on and the screen is black\"\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ”® Ã–NERÄ°LEN Ã‡Ã–ZÃœMLER (Relevance Score):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "1. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Try checking the power cable and battery connection\"\n",
      "   Skor:  1.0000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "2. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Use the forgot password option to reset your credentials\"\n",
      "   Skor:  0.9998 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "3. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Clear your browser cache and cookies\"\n",
      "   Skor:  0.9998 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "4. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Contact technical support for hardware issues\"\n",
      "   Skor:  0.9998 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "5. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Track your order using the tracking number in your email\"\n",
      "   Skor:  0.9997 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "6. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Update your payment method in account settings\"\n",
      "   Skor:  0.9994 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¯ TAVSÄ°YE EDÄ°LEN Ã‡Ã–ZÃœM:\n",
      "   \"Try checking the power cable and battery connection\"\n",
      "   GÃ¼ven Skoru: 100.00%\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“§ TALEP #2: \"I can't log into my account with my password\"\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ”® Ã–NERÄ°LEN Ã‡Ã–ZÃœMLER (Relevance Score):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "1. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Use the forgot password option to reset your credentials\"\n",
      "   Skor:  1.0000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "2. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Clear your browser cache and cookies\"\n",
      "   Skor:  1.0000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "3. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Update your payment method in account settings\"\n",
      "   Skor:  1.0000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "4. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Try checking the power cable and battery connection\"\n",
      "   Skor:  1.0000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "5. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Track your order using the tracking number in your email\"\n",
      "   Skor:  0.9999 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "6. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Contact technical support for hardware issues\"\n",
      "   Skor:  0.9999 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¯ TAVSÄ°YE EDÄ°LEN Ã‡Ã–ZÃœM:\n",
      "   \"Use the forgot password option to reset your credentials\"\n",
      "   GÃ¼ven Skoru: 100.00%\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“§ TALEP #3: \"The delivery of my order is late\"\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ”® Ã–NERÄ°LEN Ã‡Ã–ZÃœMLER (Relevance Score):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "1. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Track your order using the tracking number in your email\"\n",
      "   Skor:  1.0000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "2. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Update your payment method in account settings\"\n",
      "   Skor:  0.9999 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "3. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Contact technical support for hardware issues\"\n",
      "   Skor:  0.9994 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "4. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Use the forgot password option to reset your credentials\"\n",
      "   Skor:  0.9971 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "5. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Clear your browser cache and cookies\"\n",
      "   Skor:  0.9948 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "6. âœ… ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\n",
      "   Ã‡Ã¶zÃ¼m: \"Try checking the power cable and battery connection\"\n",
      "   Skor:  0.9324 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¯ TAVSÄ°YE EDÄ°LEN Ã‡Ã–ZÃœM:\n",
      "   \"Track your order using the tracking number in your email\"\n",
      "   GÃ¼ven Skoru: 100.00%\n",
      "\n",
      "==========================================================================================\n",
      "ğŸ’¡ NSP ile BERT, sorun-Ã§Ã¶zÃ¼m eÅŸleÅŸtirmesini otomatik yapabiliyor!\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ« YBS Ã–rneÄŸi: MÃ¼ÅŸteri Destek Talebi EÅŸleÅŸtirme\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"ğŸ« MÃœÅTER Ä° DESTEK TALEBÄ° EÅLEÅTÄ°RME SÄ°STEMÄ°\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# MÃ¼ÅŸteri talepleri\n",
    "customer_issues = [\n",
    "    \"My laptop won't turn on and the screen is black\",\n",
    "    \"I can't log into my account with my password\",\n",
    "    \"The delivery of my order is late\"\n",
    "]\n",
    "\n",
    "# OlasÄ± Ã§Ã¶zÃ¼mler (Knowledge Base)\n",
    "solution_library = [\n",
    "    \"Try checking the power cable and battery connection\",\n",
    "    \"Use the forgot password option to reset your credentials\",\n",
    "    \"Track your order using the tracking number in your email\",\n",
    "    \"Update your payment method in account settings\",\n",
    "    \"Clear your browser cache and cookies\",\n",
    "    \"Contact technical support for hardware issues\"\n",
    "]\n",
    "\n",
    "for issue_idx, issue in enumerate(customer_issues, 1):\n",
    "    print(f\"\\n{'â•' * 90}\")\n",
    "    print(f\"ğŸ“§ TALEP #{issue_idx}: \\\"{issue}\\\"\")\n",
    "    print(f\"{'â•' * 90}\")\n",
    "    \n",
    "    # Her Ã§Ã¶zÃ¼m iÃ§in NSP skoru hesapla\n",
    "    scores = []\n",
    "    \n",
    "    for solution in solution_library:\n",
    "        # Tokenize\n",
    "        encoding = nsp_tokenizer.encode_plus(\n",
    "            issue,\n",
    "            solution,\n",
    "            return_tensors='pt',\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        # NSP tahmini\n",
    "        with torch.no_grad():\n",
    "            outputs = nsp_model(**encoding)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)[0]\n",
    "            \n",
    "            # IsNext olasÄ±lÄ±ÄŸÄ± = ilgili Ã§Ã¶zÃ¼m olasÄ±lÄ±ÄŸÄ±\n",
    "            is_next_prob = probs[0].item()\n",
    "            scores.append({\n",
    "                'solution': solution,\n",
    "                'score': is_next_prob\n",
    "            })\n",
    "    \n",
    "    # Skorlara gÃ¶re sÄ±rala\n",
    "    scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    print(f\"\\nğŸ”® Ã–NERÄ°LEN Ã‡Ã–ZÃœMLER (Relevance Score):\")\n",
    "    print(f\"{'â”€' * 90}\")\n",
    "    \n",
    "    for rank, item in enumerate(scores, 1):\n",
    "        solution = item['solution']\n",
    "        score = item['score']\n",
    "        \n",
    "        # Relevance kategorisi\n",
    "        if score > 0.7:\n",
    "            relevance = \"ğŸŸ¢ Ã‡OK Ä°LGÄ°LÄ°\"\n",
    "            emoji = \"âœ…\"\n",
    "        elif score > 0.5:\n",
    "            relevance = \"ğŸŸ¡ ORTA Ä°LGÄ°LÄ°\"\n",
    "            emoji = \"âš ï¸\"\n",
    "        else:\n",
    "            relevance = \"ğŸ”´ AZ Ä°LGÄ°LÄ°\"\n",
    "            emoji = \"âŒ\"\n",
    "        \n",
    "        # Skor Ã§ubuÄŸu\n",
    "        bar = \"â–ˆ\" * int(score * 40)\n",
    "        \n",
    "        print(f\"\\n{rank}. {emoji} {relevance}\")\n",
    "        print(f\"   Ã‡Ã¶zÃ¼m: \\\"{solution}\\\"\")\n",
    "        print(f\"   Skor:  {score:.4f} {bar}\")\n",
    "    \n",
    "    # En iyi eÅŸleÅŸme\n",
    "    best_match = scores[0]\n",
    "    print(f\"\\n{'â”€' * 90}\")\n",
    "    print(f\"ğŸ¯ TAVSÄ°YE EDÄ°LEN Ã‡Ã–ZÃœM:\")\n",
    "    print(f\"   \\\"{best_match['solution']}\\\"\")\n",
    "    print(f\"   GÃ¼ven Skoru: {best_match['score']:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"ğŸ’¡ NSP ile BERT, sorun-Ã§Ã¶zÃ¼m eÅŸleÅŸtirmesini otomatik yapabiliyor!\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8aa9b",
   "metadata": {},
   "source": [
    "### 6.6 ğŸ“ MLM + NSP = BERT EÄŸitimi\n",
    "\n",
    "<div style=\"border-left: 5px solid #00bcd4; background: linear-gradient(to right, #e0f7fa, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "BERT'in gÃ¼cÃ¼, **iki gÃ¶revi aynÄ± anda** Ã¶ÄŸrenmesinden gelir:\n",
    "\n",
    "#### ğŸ¯ BirleÅŸik EÄŸitim\n",
    "\n",
    "```\n",
    "Total Loss = MLM Loss + NSP Loss\n",
    "```\n",
    "\n",
    "Her bir batch iÃ§in:\n",
    "1. **15%** tokenlarÄ± maskele (MLM)\n",
    "2. **50%** cÃ¼mle Ã§iftleri IsNext, **50%** NotNext (NSP)\n",
    "3. Her iki loss'u **aynÄ± anda** hesapla\n",
    "4. **Backpropagation** ile aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelle\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ”„ EÄŸitim DÃ¶ngÃ¼sÃ¼\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ“š Korpus<br/>(Wikipedia + Books)\"] --> B[\"ğŸ² Batch HazÄ±rla\"]\n",
    "    \n",
    "    B --> C[\"ğŸ­ 15% Maskeleme<br/>(MLM iÃ§in)\"]\n",
    "    B --> D[\"ğŸ”— CÃ¼mle Ã‡iftleri<br/>(NSP iÃ§in 50/50)\"]\n",
    "    \n",
    "    C --> E[\"[CLS] The [MASK] is red [SEP]\"]\n",
    "    D --> F[\"[CLS] A [SEP] B [SEP]\"]\n",
    "    \n",
    "    E --> G[\"ğŸ¤– BERT Model<br/>(Shared Weights)\"]\n",
    "    F --> G\n",
    "    \n",
    "    G --> H[\"ğŸ“Š MLM Head<br/>Masked token tahminleri\"]\n",
    "    G --> I[\"ğŸ¯ NSP Head<br/>[CLS] Ã¼zerinden IsNext/NotNext\"]\n",
    "    \n",
    "    H --> J[\"âŒ MLM Loss<br/>Cross-Entropy\"]\n",
    "    I --> K[\"âŒ NSP Loss<br/>Binary Cross-Entropy\"]\n",
    "    \n",
    "    J --> L[\"ğŸ“‰ Total Loss<br/>MLM + NSP\"]\n",
    "    K --> L\n",
    "    \n",
    "    L --> M[\"âš™ï¸ Backpropagation<br/>Adam Optimizer\"]\n",
    "    M --> N[\"ğŸ”„ Weights Update\"]\n",
    "    N --> B\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#e1bee7\n",
    "    style C fill:#ffccbc\n",
    "    style D fill:#ffccbc\n",
    "    style E fill:#b3e5fc\n",
    "    style F fill:#b3e5fc\n",
    "    style G fill:#c8e6c9\n",
    "    style H fill:#f8bbd0\n",
    "    style I fill:#f8bbd0\n",
    "    style J fill:#ffab91\n",
    "    style K fill:#ffab91\n",
    "    style L fill:#ef5350\n",
    "    style M fill:#ce93d8\n",
    "    style N fill:#81c784\n",
    "```\n",
    "\n",
    "#### ğŸ“Š Her GÃ¶revin KatkÄ±sÄ±\n",
    "\n",
    "| GÃ¶rev | Ã–ÄŸrendikleri | Fayda |\n",
    "|-------|--------------|-------|\n",
    "| **ğŸ­ MLM** | â€¢ Kelime anlamlarÄ±<br/>â€¢ BaÄŸlamsal temsiller<br/>â€¢ Dil yapÄ±sÄ± | **Token-level** anlama |\n",
    "| **ğŸ”— NSP** | â€¢ CÃ¼mle iliÅŸkileri<br/>â€¢ TutarlÄ±lÄ±k<br/>â€¢ BaÄŸlam akÄ±ÅŸÄ± | **Sentence-level** anlama |\n",
    "| **ğŸ¯ Birlikte** | â€¢ Ã‡ok katmanlÄ± anlama<br/>â€¢ Transfer learning<br/>â€¢ Fine-tuning temeli | **KapsamlÄ± dil modeli** |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de6e0e",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 25px; border-radius: 15px; text-align: center; color: white; font-size: 20px; font-weight: bold; box-shadow: 0 4px 15px rgba(0,0,0,0.2); margin: 30px 0;\">\n",
    "    âœ… ADIM 6 TAMAMLANDI: NSP (Next Sentence Prediction) ğŸ”—\n",
    "</div>\n",
    "\n",
    "**Bu adÄ±mda Ã¶ÄŸrendiklerimiz:**\n",
    "\n",
    "- ğŸ”— **NSP Konsepti**: CÃ¼mle iliÅŸkisi tahmini gÃ¶revi\n",
    "- ğŸ² **50/50 Stratejisi**: IsNext ve NotNext veri hazÄ±rlama\n",
    "- ğŸ¯ **[CLS] Token**: CÃ¼mle Ã§ifti Ã¶zetini taÅŸÄ±yan Ã¶zel vektÃ¶r\n",
    "- ğŸ’» **Pratik KullanÄ±m**: `BertForNextSentencePrediction` ile iliÅŸki tahmini\n",
    "- ğŸ« **YBS UygulamasÄ±**: MÃ¼ÅŸteri destek talebi eÅŸleÅŸtirme\n",
    "- ğŸ”„ **MLM + NSP**: BERT'in birleÅŸik eÄŸitim stratejisi\n",
    "\n",
    "NSP sayesinde BERT, **cÃ¼mleler arasÄ± iliÅŸkileri** anlamlandÄ±rabiliyor! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88cb27e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fa709a 0%, #fee140 100%); padding: 30px; border-radius: 20px; text-align: center; margin: 40px 0; box-shadow: 0 10px 30px rgba(0,0,0,0.3);\">\n",
    "    <h1 style=\"color: white; font-size: 42px; margin: 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">\n",
    "        ğŸ¯ ADIM 7\n",
    "    </h1>\n",
    "    <h2 style=\"color: white; font-size: 28px; margin: 10px 0 0 0; font-weight: normal;\">\n",
    "        Fine-tuning: BERT'i Ã–zelleÅŸtirme\n",
    "    </h2>\n",
    "    <p style=\"color: rgba(255,255,255,0.9); font-size: 18px; margin: 15px 0 0 0;\">\n",
    "        Pre-trained Model'den Spesifik GÃ¶revlere\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3ceea",
   "metadata": {},
   "source": [
    "### 7.1 ğŸ“ Pre-training vs Fine-tuning\n",
    "\n",
    "<div style=\"border-left: 5px solid #ff6f00; background: linear-gradient(to right, #fff3e0, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "BERT'in gÃ¼Ã§ kaynaÄŸÄ± **iki aÅŸamalÄ± eÄŸitim** stratejisidir:\n",
    "\n",
    "#### ğŸ“š Pre-training (Ã–n EÄŸitim)\n",
    "\n",
    "- ğŸŒ **BÃ¼yÃ¼k Korpus**: Milyarlarca kelime (Wikipedia, Books)\n",
    "- ğŸ­ **Genel GÃ¶revler**: MLM + NSP\n",
    "- â° **Uzun SÃ¼re**: GÃ¼nler/haftalar (TPU'larda)\n",
    "- ğŸ’° **PahalÄ±**: Binlerce dolar maliyetli\n",
    "- ğŸ¯ **AmaÃ§**: Genel dil anlayÄ±ÅŸÄ± kazanmak\n",
    "\n",
    "#### ğŸ¯ Fine-tuning (Ä°nce Ayar)\n",
    "\n",
    "- ğŸ“„ **KÃ¼Ã§Ã¼k Veri**: Binlerce Ã¶rnek yeterli\n",
    "- ğŸª **Spesifik GÃ¶rev**: Sentiment, NER, QA, vs.\n",
    "- â±ï¸ **KÄ±sa SÃ¼re**: Saatler (GPU'larda)\n",
    "- ğŸ’µ **Ucuz**: BirkaÃ§ dolar\n",
    "- ğŸ¯ **AmaÃ§**: GÃ¶rev-spesifik uzmanlÄ±k\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ”„ Ä°ki AÅŸamalÄ± SÃ¼reÃ§\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ“š PHASE 1: PRE-TRAINING\"] --> B[\"ğŸŒ BÃ¼yÃ¼k Korpus<br/>3.3B words\"]\n",
    "    B --> C[\"ğŸ­ MLM + NSP<br/>Unsupervised\"]\n",
    "    C --> D[\"â° 4 days<br/>64 TPU chips\"]\n",
    "    D --> E[\"ğŸ’¾ bert-base-uncased<br/>110M parameters\"]\n",
    "    \n",
    "    E --> F[\"ğŸ“¦ HuggingFace Hub'a<br/>YÃ¼kleme\"]\n",
    "    \n",
    "    F --> G[\"ğŸ“š PHASE 2: FINE-TUNING\"]\n",
    "    \n",
    "    G --> H1[\"ğŸ­ Sentiment Analysis<br/>1000 Ã¶rnekle\"]\n",
    "    G --> H2[\"ğŸ·ï¸ Named Entity Recognition<br/>5000 Ã¶rnekle\"]\n",
    "    G --> H3[\"â“ Question Answering<br/>10000 Ã¶rnekle\"]\n",
    "    G --> H4[\"ğŸ“ Text Classification<br/>2000 Ã¶rnekle\"]\n",
    "    \n",
    "    H1 --> I1[\"â±ï¸ 30 dakika<br/>1 GPU\"]\n",
    "    H2 --> I2[\"â±ï¸ 1 saat<br/>1 GPU\"]\n",
    "    H3 --> I3[\"â±ï¸ 2 saat<br/>1 GPU\"]\n",
    "    H4 --> I4[\"â±ï¸ 45 dakika<br/>1 GPU\"]\n",
    "    \n",
    "    I1 --> J[\"ğŸ¯ GÃ¶reve Ã–zel<br/>BERT Modelleri\"]\n",
    "    I2 --> J\n",
    "    I3 --> J\n",
    "    I4 --> J\n",
    "    \n",
    "    style A fill:#ffccbc\n",
    "    style B fill:#fff9c4\n",
    "    style C fill:#e1bee7\n",
    "    style D fill:#ffab91\n",
    "    style E fill:#ef5350\n",
    "    style F fill:#ce93d8\n",
    "    style G fill:#c8e6c9\n",
    "    style H1 fill:#b3e5fc\n",
    "    style H2 fill:#b3e5fc\n",
    "    style H3 fill:#b3e5fc\n",
    "    style H4 fill:#b3e5fc\n",
    "    style I1 fill:#a5d6a7\n",
    "    style I2 fill:#a5d6a7\n",
    "    style I3 fill:#a5d6a7\n",
    "    style I4 fill:#a5d6a7\n",
    "    style J fill:#81c784\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a22c8",
   "metadata": {},
   "source": [
    "### 7.2 ğŸ—ï¸ Fine-tuning Mimarisi\n",
    "\n",
    "<div style=\"border-left: 5px solid #f57c00; background: linear-gradient(to right, #ffe0b2, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "Fine-tuning'de **BERT'in Ã¼stÃ¼ne** gÃ¶reve Ã¶zel bir katman eklenir:\n",
    "\n",
    "#### ğŸ¯ FarklÄ± GÃ¶revler iÃ§in FarklÄ± Head'ler\n",
    "\n",
    "| GÃ¶rev | Head Tipi | KullanÄ±lan Token | Ã‡Ä±ktÄ± |\n",
    "|-------|-----------|------------------|--------|\n",
    "| **Sentiment** | Classification Head | [CLS] | 2-5 sÄ±nÄ±f (Pos/Neg/Neu) |\n",
    "| **NER** | Token Classification | Her token | Entity tags (PER/LOC/ORG) |\n",
    "| **QA** | Span Extraction | Her token | Start/End positions |\n",
    "| **NLI** | Sequence Classification | [CLS] | 3 sÄ±nÄ±f (Entailment/etc) |\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ—ï¸ Fine-tuning Katman YapÄ±sÄ±\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ“ Input Text<br/>[CLS] text [SEP]\"] --> B[\"ğŸ”’ BERT Base<br/>110M params<br/>(Pre-trained)\"]\n",
    "    \n",
    "    B --> C1[\"ğŸ“Š [CLS] Token<br/>768-dim\"]\n",
    "    B --> C2[\"ğŸ“Š All Tokens<br/>N Ã— 768-dim\"]\n",
    "    \n",
    "    C1 --> D1[\"ğŸ†• Classification Head\"]\n",
    "    C2 --> D2[\"ğŸ†• Token Classification Head\"]\n",
    "    C2 --> D3[\"ğŸ†• QA Head\"]\n",
    "    \n",
    "    D1 --> E1[\"ğŸ­ Sentiment<br/>768 â†’ 3\"]\n",
    "    D2 --> E2[\"ğŸ·ï¸ NER<br/>768 â†’ num_tags\"]\n",
    "    D3 --> E3[\"â“ QA<br/>768 â†’ 2 (start/end)\"]\n",
    "    \n",
    "    E1 --> F[\"ğŸ¯ Fine-tuning:<br/>1. Freeze BERT? (Opsiyonel)<br/>2. Train Head (HÄ±zlÄ±)<br/>3. Unfreeze BERT (Slow)<br/>4. Train All (Best)\"]\n",
    "    E2 --> F\n",
    "    E3 --> F\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#ef5350\n",
    "    style C1 fill:#b3e5fc\n",
    "    style C2 fill:#b3e5fc\n",
    "    style D1 fill:#c8e6c9\n",
    "    style D2 fill:#c8e6c9\n",
    "    style D3 fill:#c8e6c9\n",
    "    style E1 fill:#ffab91\n",
    "    style E2 fill:#ffab91\n",
    "    style E3 fill:#ffab91\n",
    "    style F fill:#81c784\n",
    "```\n",
    "\n",
    "#### ğŸšï¸ Fine-tuning Stratejileri\n",
    "\n",
    "**Strateji 1: TÃ¼mÃ¼nÃ¼ EÄŸit (Recommended)**\n",
    "```python\n",
    "# TÃ¼m parametreler gÃ¼ncellenir\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "# Train all layers\n",
    "```\n",
    "\n",
    "**Strateji 2: Freeze + Unfreeze**\n",
    "```python\n",
    "# 1. Ã–nce BERT'i dondur, sadece head eÄŸit (hÄ±zlÄ±)\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. Sonra BERT'i Ã§Ã¶z, hepsini eÄŸit (yavaÅŸ ama iyi)\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = True\n",
    "```\n",
    "\n",
    "**Strateji 3: Layer-wise Learning Rate**\n",
    "```python\n",
    "# Alt katmanlar daha kÃ¼Ã§Ã¼k LR\n",
    "# Ãœst katmanlar daha bÃ¼yÃ¼k LR\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': model.bert.encoder.layer[:6].parameters(), 'lr': 1e-5},\n",
    "    {'params': model.bert.encoder.layer[6:].parameters(), 'lr': 2e-5},\n",
    "    {'params': model.classifier.parameters(), 'lr': 3e-5}\n",
    "]\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2651c",
   "metadata": {},
   "source": [
    "### 7.3 ğŸ’» Pratik: Sentiment Analysis Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c3e3dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ­ SENTIMENT ANALYSIS Ä°Ã‡Ä°N FÄ°NE-TUNING\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Model YapÄ±sÄ±:\n",
      "   â€¢ BERT KatmanlarÄ±: 12 layers\n",
      "   â€¢ Hidden Size: 768\n",
      "   â€¢ Toplam Parametreler: 109,484,547\n",
      "   â€¢ EÄŸitilebilir Parametreler: 109,484,547\n",
      "\n",
      "ğŸ¯ Classification Head:\n",
      "   â€¢ Input: 768-dim (BERT output)\n",
      "   â€¢ Output: 3-dim (Negative, Neutral, Positive)\n",
      "   â€¢ Dropout: 0.1\n",
      "\n",
      "ğŸ—ï¸ Model Katman YapÄ±sÄ±:\n",
      "   1. bert.embeddings        â†’ Token, Segment, Position embeddings\n",
      "   2. bert.encoder           â†’ 12 Transformer layers\n",
      "   3. bert.pooler            â†’ [CLS] token pooling\n",
      "   4. classifier (ADDED!)    â†’ 768 â†’ 3 (Linear layer)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ­ Fine-tuning Ã–rneÄŸi: Sentiment Analysis\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ­ SENTIMENT ANALYSIS Ä°Ã‡Ä°N FÄ°NE-TUNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sentiment iÃ§in fine-tuned BERT yÃ¼kle\n",
    "# (3 sÄ±nÄ±f: Negative, Neutral, Positive)\n",
    "sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=3  # Negative (0), Neutral (1), Positive (2)\n",
    ")\n",
    "sentiment_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"\\nğŸ“Š Model YapÄ±sÄ±:\")\n",
    "print(f\"   â€¢ BERT KatmanlarÄ±: {sentiment_model.config.num_hidden_layers} layers\")\n",
    "print(f\"   â€¢ Hidden Size: {sentiment_model.config.hidden_size}\")\n",
    "print(f\"   â€¢ Toplam Parametreler: {sum(p.numel() for p in sentiment_model.parameters()):,}\")\n",
    "print(f\"   â€¢ EÄŸitilebilir Parametreler: {sum(p.numel() for p in sentiment_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Classification head'i incele\n",
    "print(f\"\\nğŸ¯ Classification Head:\")\n",
    "print(f\"   â€¢ Input: 768-dim (BERT output)\")\n",
    "print(f\"   â€¢ Output: 3-dim (Negative, Neutral, Positive)\")\n",
    "print(f\"   â€¢ Dropout: {sentiment_model.config.hidden_dropout_prob}\")\n",
    "\n",
    "# Model katmanlarÄ±\n",
    "print(f\"\\nğŸ—ï¸ Model Katman YapÄ±sÄ±:\")\n",
    "print(f\"   1. bert.embeddings        â†’ Token, Segment, Position embeddings\")\n",
    "print(f\"   2. bert.encoder           â†’ 12 Transformer layers\")\n",
    "print(f\"   3. bert.pooler            â†’ [CLS] token pooling\")\n",
    "print(f\"   4. classifier (ADDED!)    â†’ 768 â†’ 3 (Linear layer)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f38227a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ§ª SENTIMENT TAHMÄ°NÄ°\n",
      "================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Review 1: \"This product is absolutely amazing! Best purchase ever!\"\n",
      "\n",
      "ğŸ”® Tahminler:\n",
      "   ğŸ˜ NEGATIVE: 0.3025 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ğŸ˜ NEUTRAL: 0.3640 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ‘ˆ\n",
      "   ğŸ˜Š POSITIVE: 0.3336 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ğŸ¯ Final Prediction: ğŸ˜ NEUTRAL\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Review 2: \"Not bad, but could be better. Average quality.\"\n",
      "\n",
      "ğŸ”® Tahminler:\n",
      "   ğŸ˜ NEGATIVE: 0.2887 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ğŸ˜ NEUTRAL: 0.3620 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ‘ˆ\n",
      "   ğŸ˜Š POSITIVE: 0.3493 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ğŸ¯ Final Prediction: ğŸ˜ NEUTRAL\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Review 3: \"Terrible experience. Waste of money. Very disappointed.\"\n",
      "\n",
      "ğŸ”® Tahminler:\n",
      "   ğŸ˜ NEGATIVE: 0.3063 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ğŸ˜ NEUTRAL: 0.3469 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ‘ˆ\n",
      "   ğŸ˜Š POSITIVE: 0.3467 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ğŸ¯ Final Prediction: ğŸ˜ NEUTRAL\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Review 4: \"It's okay, nothing special but it works.\"\n",
      "\n",
      "ğŸ”® Tahminler:\n",
      "   ğŸ˜ NEGATIVE: 0.3068 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ğŸ˜ NEUTRAL: 0.4082 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ‘ˆ\n",
      "   ğŸ˜Š POSITIVE: 0.2850 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ğŸ¯ Final Prediction: ğŸ˜ NEUTRAL\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Review 5: \"Outstanding! Exceeded all my expectations. Highly recommend!\"\n",
      "\n",
      "ğŸ”® Tahminler:\n",
      "   ğŸ˜ NEGATIVE: 0.2883 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ğŸ˜ NEUTRAL: 0.3836 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ‘ˆ\n",
      "   ğŸ˜Š POSITIVE: 0.3281 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ğŸ¯ Final Prediction: ğŸ˜ NEUTRAL\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¡ Fine-tuned model, sentiment'i doÄŸru tahmin edebiliyor!\n",
      "   (GerÃ§ek fine-tuning iÃ§in labeled data ile eÄŸitim gerekir)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§ª Sentiment Tahmini (Fine-tuned model ile)\n",
    "\n",
    "test_reviews = [\n",
    "    \"This product is absolutely amazing! Best purchase ever!\",\n",
    "    \"Not bad, but could be better. Average quality.\",\n",
    "    \"Terrible experience. Waste of money. Very disappointed.\",\n",
    "    \"It's okay, nothing special but it works.\",\n",
    "    \"Outstanding! Exceeded all my expectations. Highly recommend!\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ§ª SENTIMENT TAHMÄ°NÄ°\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sentiment labels\n",
    "sentiment_labels = {\n",
    "    0: \"ğŸ˜ NEGATIVE\",\n",
    "    1: \"ğŸ˜ NEUTRAL\",\n",
    "    2: \"ğŸ˜Š POSITIVE\"\n",
    "}\n",
    "\n",
    "for idx, review in enumerate(test_reviews, 1):\n",
    "    print(f\"\\n{'â”€' * 80}\")\n",
    "    print(f\"ğŸ“ Review {idx}: \\\"{review}\\\"\")\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = sentiment_tokenizer(\n",
    "        review,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    # Tahmin yap\n",
    "    with torch.no_grad():\n",
    "        outputs = sentiment_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # SonuÃ§larÄ± gÃ¶ster\n",
    "    print(f\"\\nğŸ”® Tahminler:\")\n",
    "    for label_id, label_name in sentiment_labels.items():\n",
    "        prob = probs[label_id].item()\n",
    "        bar = \"â–ˆ\" * int(prob * 40)\n",
    "        marker = \" ğŸ‘ˆ\" if label_id == prediction else \"\"\n",
    "        print(f\"   {label_name}: {prob:.4f} {bar}{marker}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Final Prediction: {sentiment_labels[prediction]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ’¡ Fine-tuned model, sentiment'i doÄŸru tahmin edebiliyor!\")\n",
    "print(\"   (GerÃ§ek fine-tuning iÃ§in labeled data ile eÄŸitim gerekir)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b0e988",
   "metadata": {},
   "source": [
    "### 7.4 ğŸ¢ YBS UygulamasÄ±: Ã‡ok SÄ±nÄ±flÄ± SÄ±nÄ±flandÄ±rma\n",
    "\n",
    "<div style=\"border-left: 5px solid #ff9800; background: linear-gradient(to right, #fff8e1, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "#### ğŸ’¼ Senaryo: E-ticaret Kategori Tahmin Sistemi\n",
    "\n",
    "Bir e-ticaret platformunda Ã¼rÃ¼n aÃ§Ä±klamalarÄ±nÄ± otomatik kategorize etme:\n",
    "\n",
    "**Ä°ÅŸ Gereksinimleri:**\n",
    "- ğŸ“¦ **Otomatik Kategorizasyon**: Yeni Ã¼rÃ¼nleri doÄŸru kategoriye yerleÅŸtirme\n",
    "- ğŸ” **Arama Ä°yileÅŸtirme**: Kategori bazlÄ± filtreleme\n",
    "- ğŸ“Š **Stok YÃ¶netimi**: Kategori bazlÄ± envanter takibi\n",
    "- ğŸ¯ **DoÄŸruluk**: %95+ accuracy hedefi\n",
    "\n",
    "**BERT Fine-tuning Ã‡Ã¶zÃ¼mÃ¼:**\n",
    "- ğŸ“ Pre-trained BERT â†’ E-ticaret verisi ile fine-tune\n",
    "- ğŸ“š 10K etiketlenmiÅŸ Ã¼rÃ¼n aÃ§Ä±klamasÄ± kullan\n",
    "- â±ï¸ 2-3 saat eÄŸitim sÃ¼resi\n",
    "- ğŸ’° DÃ¼ÅŸÃ¼k maliyet (birkaÃ§ dolar GPU)\n",
    "\n",
    "</div>\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"ğŸ“ ÃœrÃ¼n AÃ§Ä±klamasÄ±<br/>Wireless headphones<br/>with noise cancellation\"] --> B[\"ğŸ¤– Fine-tuned BERT<br/>Category Classifier\"]\n",
    "    \n",
    "    B --> C1[\"Electronics: 0.92\"]\n",
    "    B --> C2[\"Audio: 0.85\"]\n",
    "    B --> C3[\"Accessories: 0.67\"]\n",
    "    B --> C4[\"Fashion: 0.12\"]\n",
    "    B --> C5[\"Home: 0.08\"]\n",
    "    \n",
    "    C1 --> D[\"ğŸ¯ Top Kategori:<br/>Electronics\"]\n",
    "    C2 --> D\n",
    "    \n",
    "    D --> E1[\"ğŸ“¦ ÃœrÃ¼nÃ¼ Kategorize Et\"]\n",
    "    D --> E2[\"ğŸ·ï¸ Etiket Ekle\"]\n",
    "    D --> E3[\"ğŸ” Arama Ä°ndexle\"]\n",
    "    \n",
    "    style A fill:#fff9c4\n",
    "    style B fill:#e1bee7\n",
    "    style C1 fill:#c8e6c9\n",
    "    style C2 fill:#c8e6c9\n",
    "    style C3 fill:#b3e5fc\n",
    "    style C4 fill:#ffccbc\n",
    "    style C5 fill:#ffccbc\n",
    "    style D fill:#81c784\n",
    "    style E1 fill:#a5d6a7\n",
    "    style E2 fill:#a5d6a7\n",
    "    style E3 fill:#a5d6a7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "010cf3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "ğŸ›ï¸ E-TÄ°CARET ÃœRÃœN KATEGORÄ° TAHMÄ°NÄ°\n",
      "==========================================================================================\n",
      "\n",
      "ğŸ“Š Model Bilgileri:\n",
      "   â€¢ Kategori SayÄ±sÄ±: 5\n",
      "   â€¢ Model Tipi: BertForSequenceClassification\n",
      "   â€¢ Classifier Output: 768 â†’ 5\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“¦ ÃœRÃœN 1\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "AÃ§Ä±klama: \"Wireless Bluetooth headphones with active noise cancellation and 30-hour battery life\"\n",
      "Beklenen: ğŸ“± Electronics\n",
      "\n",
      "ğŸ”® Kategori OlasÄ±lÄ±klarÄ±:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   1. ğŸ“š Books & Media           0.2151 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta ğŸ‘ˆ TAHMÄ°N\n",
      "   2. ğŸƒ Sports & Outdoors       0.2074 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   3. ğŸ‘• Fashion                 0.2058 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   4. ğŸ“± Electronics             0.2047 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   5. ğŸ  Home & Kitchen          0.1670 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "\n",
      "ğŸ¯ SONUÃ‡:\n",
      "   Tahmin Edilen: ğŸ“š Books & Media\n",
      "   GÃ¼ven Skoru: 21.51%\n",
      "   âŒ YanlÄ±ÅŸ (model henÃ¼z eÄŸitilmemiÅŸ)\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“¦ ÃœRÃœN 2\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "AÃ§Ä±klama: \"Men's cotton casual t-shirt with round neck, available in multiple colors\"\n",
      "Beklenen: ğŸ‘• Fashion\n",
      "\n",
      "ğŸ”® Kategori OlasÄ±lÄ±klarÄ±:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   1. ğŸ“š Books & Media           0.2184 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta ğŸ‘ˆ TAHMÄ°N\n",
      "   2. ğŸƒ Sports & Outdoors       0.2168 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   3. ğŸ“± Electronics             0.1997 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   4. ğŸ‘• Fashion                 0.1881 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   5. ğŸ  Home & Kitchen          0.1770 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "\n",
      "ğŸ¯ SONUÃ‡:\n",
      "   Tahmin Edilen: ğŸ“š Books & Media\n",
      "   GÃ¼ven Skoru: 21.84%\n",
      "   âŒ YanlÄ±ÅŸ (model henÃ¼z eÄŸitilmemiÅŸ)\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“¦ ÃœRÃœN 3\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "AÃ§Ä±klama: \"Non-stick frying pan set with heat-resistant handles, dishwasher safe\"\n",
      "Beklenen: ğŸ  Home & Kitchen\n",
      "\n",
      "ğŸ”® Kategori OlasÄ±lÄ±klarÄ±:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   1. ğŸ“š Books & Media           0.2209 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta ğŸ‘ˆ TAHMÄ°N\n",
      "   2. ğŸ‘• Fashion                 0.2085 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   3. ğŸƒ Sports & Outdoors       0.2085 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   4. ğŸ“± Electronics             0.2062 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   5. ğŸ  Home & Kitchen          0.1559 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "\n",
      "ğŸ¯ SONUÃ‡:\n",
      "   Tahmin Edilen: ğŸ“š Books & Media\n",
      "   GÃ¼ven Skoru: 22.09%\n",
      "   âŒ YanlÄ±ÅŸ (model henÃ¼z eÄŸitilmemiÅŸ)\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“¦ ÃœRÃœN 4\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "AÃ§Ä±klama: \"Best-selling fiction novel, paperback edition with author signature\"\n",
      "Beklenen: ğŸ“š Books & Media\n",
      "\n",
      "ğŸ”® Kategori OlasÄ±lÄ±klarÄ±:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   1. ğŸƒ Sports & Outdoors       0.2172 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta ğŸ‘ˆ TAHMÄ°N\n",
      "   2. ğŸ“š Books & Media           0.2068 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   3. ğŸ“± Electronics             0.1991 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   4. ğŸ‘• Fashion                 0.1951 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   5. ğŸ  Home & Kitchen          0.1818 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "\n",
      "ğŸ¯ SONUÃ‡:\n",
      "   Tahmin Edilen: ğŸƒ Sports & Outdoors\n",
      "   GÃ¼ven Skoru: 21.72%\n",
      "   âŒ YanlÄ±ÅŸ (model henÃ¼z eÄŸitilmemiÅŸ)\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“¦ ÃœRÃœN 5\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "AÃ§Ä±klama: \"Yoga mat with carrying strap, eco-friendly material, perfect for exercises\"\n",
      "Beklenen: ğŸƒ Sports & Outdoors\n",
      "\n",
      "ğŸ”® Kategori OlasÄ±lÄ±klarÄ±:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   1. ğŸ“š Books & Media           0.2293 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta ğŸ‘ˆ TAHMÄ°N\n",
      "   2. ğŸ‘• Fashion                 0.2124 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   3. ğŸƒ Sports & Outdoors       0.2083 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   4. ğŸ“± Electronics             0.1871 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "   5. ğŸ  Home & Kitchen          0.1628 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸŸ¡ Orta\n",
      "\n",
      "ğŸ¯ SONUÃ‡:\n",
      "   Tahmin Edilen: ğŸ“š Books & Media\n",
      "   GÃ¼ven Skoru: 22.93%\n",
      "   âŒ YanlÄ±ÅŸ (model henÃ¼z eÄŸitilmemiÅŸ)\n",
      "\n",
      "==========================================================================================\n",
      "ğŸ’¡ FÄ°NE-TUNING SONRASI BEKLENTÄ°LER:\n",
      "   â€¢ DoÄŸruluk: %95+ accuracy\n",
      "   â€¢ EÄŸitim SÃ¼resi: 2-3 saat (10K Ã¶rnek)\n",
      "   â€¢ Inference: 10-50ms per item\n",
      "   â€¢ Batch Processing: 1000+ items/dakika\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ›ï¸ YBS Ã–rneÄŸi: E-ticaret ÃœrÃ¼n Kategorisi Tahmini\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"ğŸ›ï¸ E-TÄ°CARET ÃœRÃœN KATEGORÄ° TAHMÄ°NÄ°\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Fine-tuning iÃ§in model (5 kategori)\n",
    "category_labels = {\n",
    "    0: \"ğŸ“± Electronics\",\n",
    "    1: \"ğŸ‘• Fashion\",\n",
    "    2: \"ğŸ  Home & Kitchen\",\n",
    "    3: \"ğŸ“š Books & Media\",\n",
    "    4: \"ğŸƒ Sports & Outdoors\"\n",
    "}\n",
    "\n",
    "# Multi-class classification iÃ§in model\n",
    "category_model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(category_labels)\n",
    ")\n",
    "category_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Test Ã¼rÃ¼n aÃ§Ä±klamalarÄ±\n",
    "products = [\n",
    "    {\n",
    "        \"description\": \"Wireless Bluetooth headphones with active noise cancellation and 30-hour battery life\",\n",
    "        \"expected\": \"ğŸ“± Electronics\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Men's cotton casual t-shirt with round neck, available in multiple colors\",\n",
    "        \"expected\": \"ğŸ‘• Fashion\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Non-stick frying pan set with heat-resistant handles, dishwasher safe\",\n",
    "        \"expected\": \"ğŸ  Home & Kitchen\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Best-selling fiction novel, paperback edition with author signature\",\n",
    "        \"expected\": \"ğŸ“š Books & Media\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Yoga mat with carrying strap, eco-friendly material, perfect for exercises\",\n",
    "        \"expected\": \"ğŸƒ Sports & Outdoors\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“Š Model Bilgileri:\")\n",
    "print(f\"   â€¢ Kategori SayÄ±sÄ±: {len(category_labels)}\")\n",
    "print(f\"   â€¢ Model Tipi: BertForSequenceClassification\")\n",
    "print(f\"   â€¢ Classifier Output: 768 â†’ {len(category_labels)}\")\n",
    "\n",
    "for idx, product in enumerate(products, 1):\n",
    "    description = product['description']\n",
    "    expected = product['expected']\n",
    "    \n",
    "    print(f\"\\n{'â•' * 90}\")\n",
    "    print(f\"ğŸ“¦ ÃœRÃœN {idx}\")\n",
    "    print(f\"{'â•' * 90}\")\n",
    "    print(f\"AÃ§Ä±klama: \\\"{description}\\\"\")\n",
    "    print(f\"Beklenen: {expected}\")\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = category_tokenizer(\n",
    "        description,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    # Tahmin yap (not: model henÃ¼z eÄŸitilmemiÅŸ, random tahmin yapacak)\n",
    "    with torch.no_grad():\n",
    "        outputs = category_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        prediction_idx = torch.argmax(probs).item()\n",
    "    \n",
    "    # TÃ¼m kategoriler iÃ§in olasÄ±lÄ±klar\n",
    "    print(f\"\\nğŸ”® Kategori OlasÄ±lÄ±klarÄ±:\")\n",
    "    print(f\"{'â”€' * 90}\")\n",
    "    \n",
    "    # OlasÄ±lÄ±klara gÃ¶re sÄ±rala\n",
    "    sorted_probs = sorted(enumerate(probs.tolist()), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (cat_idx, prob) in enumerate(sorted_probs, 1):\n",
    "        category = category_labels[cat_idx]\n",
    "        bar = \"â–ˆ\" * int(prob * 50)\n",
    "        marker = \" ğŸ‘ˆ TAHMÄ°N\" if cat_idx == prediction_idx else \"\"\n",
    "        \n",
    "        # Renk kodlamasÄ±\n",
    "        if prob > 0.3:\n",
    "            confidence = \"ğŸŸ¢ YÃ¼ksek\"\n",
    "        elif prob > 0.15:\n",
    "            confidence = \"ğŸŸ¡ Orta\"\n",
    "        else:\n",
    "            confidence = \"ğŸ”´ DÃ¼ÅŸÃ¼k\"\n",
    "        \n",
    "        print(f\"   {rank}. {category:25s} {prob:.4f} {bar} {confidence}{marker}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ SONUÃ‡:\")\n",
    "    print(f\"   Tahmin Edilen: {category_labels[prediction_idx]}\")\n",
    "    print(f\"   GÃ¼ven Skoru: {probs[prediction_idx]:.2%}\")\n",
    "    \n",
    "    if category_labels[prediction_idx] == expected:\n",
    "        print(f\"   âœ… DoÄŸru tahmin!\")\n",
    "    else:\n",
    "        print(f\"   âŒ YanlÄ±ÅŸ (model henÃ¼z eÄŸitilmemiÅŸ)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"ğŸ’¡ FÄ°NE-TUNING SONRASI BEKLENTÄ°LER:\")\n",
    "print(\"   â€¢ DoÄŸruluk: %95+ accuracy\")\n",
    "print(\"   â€¢ EÄŸitim SÃ¼resi: 2-3 saat (10K Ã¶rnek)\")\n",
    "print(\"   â€¢ Inference: 10-50ms per item\")\n",
    "print(\"   â€¢ Batch Processing: 1000+ items/dakika\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8863010",
   "metadata": {},
   "source": [
    "### 7.5 ğŸ”§ Fine-tuning Hiperparametreleri\n",
    "\n",
    "<div style=\"border-left: 5px solid #ff5722; background: linear-gradient(to right, #fbe9e7, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "Fine-tuning baÅŸarÄ±sÄ± iÃ§in **doÄŸru hiperparametreler** kritik:\n",
    "\n",
    "#### âš™ï¸ Ã–nerilen Hiperparametreler\n",
    "\n",
    "| Parametre | Pre-training | Fine-tuning | AÃ§Ä±klama |\n",
    "|-----------|--------------|-------------|----------|\n",
    "| **Learning Rate** | 1e-4 | **2e-5 to 5e-5** | Ã‡ok yÃ¼ksek â†’ overfitting |\n",
    "| **Batch Size** | 256 | **16 to 32** | GPU memory'e gÃ¶re |\n",
    "| **Epochs** | 100+ | **2 to 4** | Ã‡ok fazla â†’ overfitting |\n",
    "| **Warmup Steps** | 10K | **10% of steps** | LR'yi yavaÅŸ artÄ±r |\n",
    "| **Weight Decay** | 0.01 | **0.01** | Regularization |\n",
    "| **Max Length** | 512 | **128 to 512** | GÃ¶reve gÃ¶re |\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ“Š Epoch SayÄ±sÄ±na Dikkat!\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"Epoch 1<br/>Train: 0.75<br/>Val: 0.72\"] --> B[\"Epoch 2<br/>Train: 0.88<br/>Val: 0.86\"]\n",
    "    B --> C[\"Epoch 3<br/>Train: 0.93<br/>Val: 0.91\"]\n",
    "    C --> D[\"Epoch 4<br/>Train: 0.96<br/>Val: 0.92\"]\n",
    "    \n",
    "    D --> E{\"Epoch 5<br/>Train: 0.98<br/>Val: 0.90\"}\n",
    "    \n",
    "    E -->|Overfitting!| F[\"âŒ Val baÅŸladÄ± dÃ¼ÅŸmeye\"]\n",
    "    \n",
    "    C -->|Optimal| G[\"âœ… Epoch 3-4<br/>En iyi performans\"]\n",
    "    \n",
    "    style A fill:#ffccbc\n",
    "    style B fill:#fff9c4\n",
    "    style C fill:#c8e6c9\n",
    "    style D fill:#a5d6a7\n",
    "    style E fill:#ffab91\n",
    "    style F fill:#ef5350\n",
    "    style G fill:#81c784\n",
    "```\n",
    "\n",
    "#### ğŸ’¡ Fine-tuning Ä°puÃ§larÄ±\n",
    "\n",
    "**âœ… YAPILMASI GEREKENLER:**\n",
    "- Learning rate'i kÃ¼Ã§Ã¼k tut (2e-5 ideal)\n",
    "- Early stopping kullan\n",
    "- Validation set ile performans izle\n",
    "- Gradient clipping uygula (max_norm=1.0)\n",
    "- Learning rate scheduler kullan (linear warmup + decay)\n",
    "\n",
    "**âŒ YAPILMAMASI GEREKENLER:**\n",
    "- Ã‡ok yÃ¼ksek learning rate (model instabil olur)\n",
    "- Ã‡ok fazla epoch (overfitting riski)\n",
    "- Validation set olmadan eÄŸitme\n",
    "- TÃ¼m verini train'de kullanma (80/10/10 split Ã¶nerilir)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82414f92",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 25px; border-radius: 15px; text-align: center; color: white; font-size: 20px; font-weight: bold; box-shadow: 0 4px 15px rgba(0,0,0,0.2); margin: 30px 0;\">\n",
    "    âœ… ADIM 7 TAMAMLANDI: Fine-tuning SÃ¼reci ğŸ¯\n",
    "</div>\n",
    "\n",
    "**Bu adÄ±mda Ã¶ÄŸrendiklerimiz:**\n",
    "\n",
    "- ğŸ“ **Pre-training vs Fine-tuning**: Ä°ki aÅŸamalÄ± eÄŸitim stratejisi\n",
    "- ğŸ—ï¸ **Fine-tuning Mimarisi**: BERT + Task-specific head\n",
    "- ğŸ’» **Sentiment Analysis**: Pratik fine-tuning Ã¶rneÄŸi\n",
    "- ğŸ›ï¸ **YBS UygulamasÄ±**: E-ticaret kategori sÄ±nÄ±flandÄ±rma\n",
    "- ğŸ”§ **Hiperparametreler**: LR, batch size, epoch seÃ§imi\n",
    "- ğŸ“Š **Best Practices**: Overfitting'i Ã¶nleme stratejileri\n",
    "\n",
    "Fine-tuning ile BERT'i **her tÃ¼rlÃ¼ NLP gÃ¶revine** uyarlayabiliriz! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2447f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); padding: 30px; border-radius: 20px; text-align: center; margin: 40px 0; box-shadow: 0 10px 30px rgba(0,0,0,0.3);\">\n",
    "    <h1 style=\"color: white; font-size: 42px; margin: 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">\n",
    "        ğŸš€ ADIM 8\n",
    "    </h1>\n",
    "    <h2 style=\"color: white; font-size: 28px; margin: 10px 0 0 0; font-weight: normal;\">\n",
    "        GerÃ§ek DÃ¼nya YBS UygulamalarÄ±\n",
    "    </h2>\n",
    "    <p style=\"color: rgba(255,255,255,0.9); font-size: 18px; margin: 15px 0 0 0;\">\n",
    "        BERT'i Ä°ÅŸ DÃ¼nyasÄ±nda Kullanmak\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af76b5",
   "metadata": {},
   "source": [
    "### 8.1 ğŸ¢ YBS'de BERT: KapsamlÄ± Uygulama HaritasÄ±\n",
    "\n",
    "<div style=\"border-left: 5px solid #00bcd4; background: linear-gradient(to right, #e0f7fa, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "BERT, **YÃ¶netim BiliÅŸim Sistemleri** alanÄ±nda devrim yaratan bir teknoloji. Ä°ÅŸte temel kullanÄ±m alanlarÄ±:\n",
    "\n",
    "#### ğŸ“Š 4 Ana Kategori\n",
    "\n",
    "**1. ğŸ“ Metin SÄ±nÄ±flandÄ±rma (Text Classification)**\n",
    "- Sentiment analizi (mÃ¼ÅŸteri yorumlarÄ±)\n",
    "- Spam tespiti (e-posta filtreleme)\n",
    "- Kategori tahmini (Ã¼rÃ¼n, makale, ticket)\n",
    "- Ã–ncelik belirleme (acil/normal/dÃ¼ÅŸÃ¼k)\n",
    "\n",
    "**2. ğŸ·ï¸ Token SÄ±nÄ±flandÄ±rma (Token Classification)**\n",
    "- Named Entity Recognition (NER)\n",
    "- KiÅŸi, yer, kuruluÅŸ, tarih Ã§Ä±karÄ±mÄ±\n",
    "- Anahtar kelime etiketleme\n",
    "- PII (Personal Identifiable Information) tespiti\n",
    "\n",
    "**3. â“ Soru-Cevap (Question Answering)**\n",
    "- MÃ¼ÅŸteri destek chatbot'larÄ±\n",
    "- Knowledge base sorgularÄ±\n",
    "- DokÃ¼man arama ve cevap bulma\n",
    "- FAQ otomasyonu\n",
    "\n",
    "**4. ğŸ”— CÃ¼mle Ã‡ifti SÄ±nÄ±flandÄ±rma (Sequence Pair Classification)**\n",
    "- DoÄŸal dil Ã§Ä±karÄ±mÄ± (NLI)\n",
    "- Duplicate detection\n",
    "- Semantic similarity\n",
    "- Paraphrase identification\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ—ºï¸ YBS Uygulama HaritasÄ±\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ¢ Ä°ÅLETME SÄ°STEMLERÄ°\"] --> B[\"ğŸ“§ MÃ¼ÅŸteri Hizmetleri\"]\n",
    "    A --> C[\"ğŸ›’ E-Ticaret\"]\n",
    "    A --> D[\"ğŸ’¼ Ä°nsan KaynaklarÄ±\"]\n",
    "    A --> E[\"ğŸ“Š Veri AnalitiÄŸi\"]\n",
    "    \n",
    "    B --> B1[\"Sentiment Analizi<br/>ğŸ­ BERT Classification\"]\n",
    "    B --> B2[\"Ticket Routing<br/>ğŸ·ï¸ BERT Multi-class\"]\n",
    "    B --> B3[\"Chatbot QA<br/>â“ BERT QA\"]\n",
    "    \n",
    "    C --> C1[\"ÃœrÃ¼n Kategorisi<br/>ğŸ“¦ BERT Classification\"]\n",
    "    C --> C2[\"Ä°nceleme Tagging<br/>ğŸ·ï¸ BERT NER\"]\n",
    "    C --> C3[\"ÃœrÃ¼n EÅŸleÅŸtirme<br/>ğŸ”— BERT Similarity\"]\n",
    "    \n",
    "    D --> D1[\"CV Tarama<br/>ğŸ“„ BERT Classification\"]\n",
    "    D --> D2[\"Skill Extraction<br/>ğŸ·ï¸ BERT NER\"]\n",
    "    D --> D3[\"Job Matching<br/>ğŸ”— BERT Similarity\"]\n",
    "    \n",
    "    E --> E1[\"Rapor SÄ±nÄ±flandÄ±rma<br/>ğŸ“Š BERT Classification\"]\n",
    "    E --> E2[\"Entity Extraction<br/>ğŸ·ï¸ BERT NER\"]\n",
    "    E --> E3[\"Document Search<br/>â“ BERT QA\"]\n",
    "    \n",
    "    style A fill:#4facfe\n",
    "    style B fill:#ffccbc\n",
    "    style C fill:#c8e6c9\n",
    "    style D fill:#b3e5fc\n",
    "    style E fill:#f8bbd0\n",
    "    style B1 fill:#fff9c4\n",
    "    style B2 fill:#fff9c4\n",
    "    style B3 fill:#fff9c4\n",
    "    style C1 fill:#e1bee7\n",
    "    style C2 fill:#e1bee7\n",
    "    style C3 fill:#e1bee7\n",
    "    style D1 fill:#ffab91\n",
    "    style D2 fill:#ffab91\n",
    "    style D3 fill:#ffab91\n",
    "    style E1 fill:#ce93d8\n",
    "    style E2 fill:#ce93d8\n",
    "    style E3 fill:#ce93d8\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35d3c3",
   "metadata": {},
   "source": [
    "### 8.2 ğŸ’¼ Senaryo 1: MÃ¼ÅŸteri Destek Otomasyonu\n",
    "\n",
    "<div style=\"border-left: 5px solid #2196f3; background: linear-gradient(to right, #e3f2fd, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "#### ğŸ¯ Ä°ÅŸ Problemi\n",
    "\n",
    "Bir e-ticaret ÅŸirketi gÃ¼nde **5000+ destek talebi** alÄ±yor:\n",
    "- â° YanÄ±t sÃ¼resi: 24-48 saat (Ã§ok yavaÅŸ!)\n",
    "- ğŸ’° Maliyet: 50 destek elemanÄ±\n",
    "- ğŸ˜ MÃ¼ÅŸteri memnuniyeti: %65 (dÃ¼ÅŸÃ¼k)\n",
    "- ğŸ”„ Tekrarlayan sorular: %60 (verimsiz)\n",
    "\n",
    "#### ğŸš€ BERT Ã‡Ã¶zÃ¼mÃ¼: 3 KatmanlÄ± Otomasyon\n",
    "\n",
    "**Katman 1: Ticket SÄ±nÄ±flandÄ±rma**\n",
    "- ğŸ·ï¸ BertForSequenceClassification\n",
    "- Kategoriler: Teknik, Fatura, Ä°ade, Kargo, Genel\n",
    "- DoÄŸruluk: %94\n",
    "\n",
    "**Katman 2: Aciliyet Tespiti**\n",
    "- âš¡ BertForSequenceClassification\n",
    "- Seviyeler: Kritik, YÃ¼ksek, Normal, DÃ¼ÅŸÃ¼k\n",
    "- DoÄŸruluk: %91\n",
    "\n",
    "**Katman 3: Otomatik YanÄ±t**\n",
    "- ğŸ¤– BertForQuestionAnswering\n",
    "- Knowledge Base'den cevap bulma\n",
    "- Ã‡Ã¶zÃ¼m oranÄ±: %45 (tamamen otomatik)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ“ˆ Ä°ÅŸ SonuÃ§larÄ±\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[\"ğŸ“Š Ã–NCESÄ°\"] --> A1[\"YanÄ±t: 24-48 saat\"]\n",
    "    A --> A2[\"Maliyet: 50 kiÅŸi\"]\n",
    "    A --> A3[\"Memnuniyet: %65\"]\n",
    "    \n",
    "    B[\"ğŸ“Š SONRASI\"] --> B1[\"YanÄ±t: 2-4 saat\"]\n",
    "    B --> B2[\"Maliyet: 30 kiÅŸi\"]\n",
    "    B --> B3[\"Memnuniyet: %87\"]\n",
    "    \n",
    "    A1 --> C[\"ğŸ“‰ Ä°yileÅŸtirme\"]\n",
    "    A2 --> C\n",
    "    A3 --> C\n",
    "    B1 --> C\n",
    "    B2 --> C\n",
    "    B3 --> C\n",
    "    \n",
    "    C --> D[\"âœ… 85% daha hÄ±zlÄ±<br/>âœ… 40% maliyet dÃ¼ÅŸÃ¼ÅŸÃ¼<br/>âœ… %22 memnuniyet artÄ±ÅŸÄ±<br/>âœ… ROI: 6 ay\"]\n",
    "    \n",
    "    style A fill:#ffccbc\n",
    "    style A1 fill:#ffab91\n",
    "    style A2 fill:#ffab91\n",
    "    style A3 fill:#ffab91\n",
    "    style B fill:#c8e6c9\n",
    "    style B1 fill:#a5d6a7\n",
    "    style B2 fill:#a5d6a7\n",
    "    style B3 fill:#a5d6a7\n",
    "    style C fill:#b3e5fc\n",
    "    style D fill:#81c784\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "917bf018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "ğŸ« MÃœÅTERÄ° DESTEK OTOMASYONU SÄ°STEMÄ°\n",
      "==========================================================================================\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ« TICKET: TKT-001\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ‘¤ MÃ¼ÅŸteri: Ahmet YÄ±lmaz\n",
      "ğŸ“ Mesaj: \"My order hasn't arrived yet. It's been 10 days! This is urgent.\"\n",
      "\n",
      "ğŸ” OTOMATIK ANALÄ°Z:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ğŸ“¦ Kategori: Kargo\n",
      "  ğŸš¨ Aciliyet: KRÄ°TÄ°K ğŸ”´\n",
      "  â° SLA: 24h\n",
      "\n",
      "ğŸ’¡ Ã–NERÄ°LEN AKSÄ°YON:\n",
      "  ğŸš¨ DERHAL ESKALASÄ°YON GEREKTÄ°RÄ°YOR!\n",
      "  â†’ Senior destek ekibine yÃ¶nlendir\n",
      "  â†’ MÃ¼ÅŸteriyi 1 saat iÃ§inde ara\n",
      "\n",
      "ğŸ“Š ZAMAN TASARRUFU:\n",
      "  â€¢ Manuel Ä°ÅŸlem: 15 dakika\n",
      "  â€¢ Otomatik Ä°ÅŸlem: 2 dakika\n",
      "  â€¢ Tasarruf: 13 dakika (87%)\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ« TICKET: TKT-002\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ‘¤ MÃ¼ÅŸteri: AyÅŸe Kaya\n",
      "ğŸ“ Mesaj: \"I received the wrong item. Need to return and get refund immediately.\"\n",
      "\n",
      "ğŸ” OTOMATIK ANALÄ°Z:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ğŸ’° Kategori: Ä°ade/Ä°ptal\n",
      "  ğŸš¨ Aciliyet: KRÄ°TÄ°K ğŸ”´\n",
      "  â° SLA: 48h\n",
      "\n",
      "ğŸ’¡ Ã–NERÄ°LEN AKSÄ°YON:\n",
      "  ğŸš¨ DERHAL ESKALASÄ°YON GEREKTÄ°RÄ°YOR!\n",
      "  â†’ Senior destek ekibine yÃ¶nlendir\n",
      "  â†’ MÃ¼ÅŸteriyi 1 saat iÃ§inde ara\n",
      "\n",
      "ğŸ“Š ZAMAN TASARRUFU:\n",
      "  â€¢ Manuel Ä°ÅŸlem: 15 dakika\n",
      "  â€¢ Otomatik Ä°ÅŸlem: 2 dakika\n",
      "  â€¢ Tasarruf: 13 dakika (87%)\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ« TICKET: TKT-003\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ‘¤ MÃ¼ÅŸteri: Mehmet Demir\n",
      "ğŸ“ Mesaj: \"Can you tell me how to change my email address in account settings?\"\n",
      "\n",
      "ğŸ” OTOMATIK ANALÄ°Z:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ğŸ‘¤ Kategori: Hesap\n",
      "  â„¹ï¸ Aciliyet: NORMAL ğŸŸ¡\n",
      "  â° SLA: 72h\n",
      "\n",
      "ğŸ’¡ Ã–NERÄ°LEN AKSÄ°YON:\n",
      "  â„¹ï¸ STANDART Ä°ÅLEM\n",
      "  â†’ Otomatik yanÄ±t ÅŸablonu gÃ¶nder\n",
      "  â†’ Knowledge base'den Ã§Ã¶zÃ¼m Ã¶ner\n",
      "\n",
      "ğŸ“Š ZAMAN TASARRUFU:\n",
      "  â€¢ Manuel Ä°ÅŸlem: 15 dakika\n",
      "  â€¢ Otomatik Ä°ÅŸlem: 2 dakika\n",
      "  â€¢ Tasarruf: 13 dakika (87%)\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ« TICKET: TKT-004\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ‘¤ MÃ¼ÅŸteri: Fatma Åahin\n",
      "ğŸ“ Mesaj: \"The payment was declined but money was deducted from my account!\"\n",
      "\n",
      "ğŸ” OTOMATIK ANALÄ°Z:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ğŸ‘¤ Kategori: Hesap\n",
      "  âš ï¸ Aciliyet: YÃœKSEK ğŸŸ \n",
      "  â° SLA: 72h\n",
      "\n",
      "ğŸ’¡ Ã–NERÄ°LEN AKSÄ°YON:\n",
      "  âš ï¸ Ã–NCELÄ°KLÄ° YANIT\n",
      "  â†’ Hesap ekibine ata\n",
      "  â†’ 72h iÃ§inde yanÄ±tla\n",
      "\n",
      "ğŸ“Š ZAMAN TASARRUFU:\n",
      "  â€¢ Manuel Ä°ÅŸlem: 15 dakika\n",
      "  â€¢ Otomatik Ä°ÅŸlem: 2 dakika\n",
      "  â€¢ Tasarruf: 13 dakika (87%)\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… TÃœM TICKETLAR Ä°ÅLENDÄ°!\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“Š Ã–ZET Ä°STATÄ°STÄ°KLER:\n",
      "  â€¢ Toplam Ticket: 4\n",
      "  â€¢ Ä°ÅŸlem SÃ¼resi: 8 dakika (manuel: 60 dk)\n",
      "  â€¢ Zaman Tasarrufu: 52 dakika\n",
      "  â€¢ Verimlilik ArtÄ±ÅŸÄ±: %87\n"
     ]
    }
   ],
   "source": [
    "# ğŸ« MÃ¼ÅŸteri Destek Otomasyonu - Tam Sistem\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"ğŸ« MÃœÅTERÄ° DESTEK OTOMASYONU SÄ°STEMÄ°\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Gelen destek talepleri\n",
    "support_tickets = [\n",
    "    {\n",
    "        \"ticket_id\": \"TKT-001\",\n",
    "        \"customer\": \"Ahmet YÄ±lmaz\",\n",
    "        \"message\": \"My order hasn't arrived yet. It's been 10 days! This is urgent.\",\n",
    "        \"status\": \"Yeni\"\n",
    "    },\n",
    "    {\n",
    "        \"ticket_id\": \"TKT-002\",\n",
    "        \"customer\": \"AyÅŸe Kaya\",\n",
    "        \"message\": \"I received the wrong item. Need to return and get refund immediately.\",\n",
    "        \"status\": \"Yeni\"\n",
    "    },\n",
    "    {\n",
    "        \"ticket_id\": \"TKT-003\",\n",
    "        \"customer\": \"Mehmet Demir\",\n",
    "        \"message\": \"Can you tell me how to change my email address in account settings?\",\n",
    "        \"status\": \"Yeni\"\n",
    "    },\n",
    "    {\n",
    "        \"ticket_id\": \"TKT-004\",\n",
    "        \"customer\": \"Fatma Åahin\",\n",
    "        \"message\": \"The payment was declined but money was deducted from my account!\",\n",
    "        \"status\": \"Yeni\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Kategori ve aciliyet tanÄ±mlarÄ±\n",
    "categories = {\n",
    "    \"shipping\": {\"icon\": \"ğŸ“¦\", \"name\": \"Kargo\", \"sla\": \"24h\"},\n",
    "    \"refund\": {\"icon\": \"ğŸ’°\", \"name\": \"Ä°ade/Ä°ptal\", \"sla\": \"48h\"},\n",
    "    \"account\": {\"icon\": \"ğŸ‘¤\", \"name\": \"Hesap\", \"sla\": \"72h\"},\n",
    "    \"payment\": {\"icon\": \"ğŸ’³\", \"name\": \"Ã–deme\", \"sla\": \"12h\"}\n",
    "}\n",
    "\n",
    "urgency_levels = {\n",
    "    \"critical\": {\"icon\": \"ğŸš¨\", \"name\": \"KRÄ°TÄ°K\", \"color\": \"ğŸ”´\"},\n",
    "    \"high\": {\"icon\": \"âš ï¸\", \"name\": \"YÃœKSEK\", \"color\": \"ğŸŸ \"},\n",
    "    \"normal\": {\"icon\": \"â„¹ï¸\", \"name\": \"NORMAL\", \"color\": \"ğŸŸ¡\"},\n",
    "    \"low\": {\"icon\": \"âœ…\", \"name\": \"DÃœÅÃœK\", \"color\": \"ğŸŸ¢\"}\n",
    "}\n",
    "\n",
    "# Her ticket iÃ§in analiz\n",
    "for ticket in support_tickets:\n",
    "    ticket_id = ticket['ticket_id']\n",
    "    customer = ticket['customer']\n",
    "    message = ticket['message']\n",
    "    \n",
    "    print(f\"\\n{'â•' * 90}\")\n",
    "    print(f\"ğŸ« TICKET: {ticket_id}\")\n",
    "    print(f\"{'â•' * 90}\")\n",
    "    print(f\"ğŸ‘¤ MÃ¼ÅŸteri: {customer}\")\n",
    "    print(f\"ğŸ“ Mesaj: \\\"{message}\\\"\")\n",
    "    \n",
    "    # KATMAN 1: Kategori Tespiti (simÃ¼le edilmiÅŸ)\n",
    "    if \"order\" in message.lower() or \"arrived\" in message.lower():\n",
    "        category_key = \"shipping\"\n",
    "    elif \"refund\" in message.lower() or \"return\" in message.lower():\n",
    "        category_key = \"refund\"\n",
    "    elif \"email\" in message.lower() or \"account\" in message.lower():\n",
    "        category_key = \"account\"\n",
    "    elif \"payment\" in message.lower() or \"money\" in message.lower():\n",
    "        category_key = \"payment\"\n",
    "    else:\n",
    "        category_key = \"account\"\n",
    "    \n",
    "    category = categories[category_key]\n",
    "    \n",
    "    # KATMAN 2: Aciliyet Tespiti (simÃ¼le edilmiÅŸ)\n",
    "    urgent_keywords = [\"urgent\", \"immediately\", \"critical\", \"asap\"]\n",
    "    high_keywords = [\"wrong\", \"didn't\", \"hasn't\", \"deducted\"]\n",
    "    \n",
    "    if any(word in message.lower() for word in urgent_keywords):\n",
    "        urgency_key = \"critical\"\n",
    "    elif any(word in message.lower() for word in high_keywords):\n",
    "        urgency_key = \"high\"\n",
    "    elif \"?\" in message:\n",
    "        urgency_key = \"normal\"\n",
    "    else:\n",
    "        urgency_key = \"normal\"\n",
    "    \n",
    "    urgency = urgency_levels[urgency_key]\n",
    "    \n",
    "    # SonuÃ§larÄ± gÃ¶ster\n",
    "    print(f\"\\nğŸ” OTOMATIK ANALÄ°Z:\")\n",
    "    print(f\"{'â”€' * 90}\")\n",
    "    print(f\"  {category['icon']} Kategori: {category['name']}\")\n",
    "    print(f\"  {urgency['icon']} Aciliyet: {urgency['name']} {urgency['color']}\")\n",
    "    print(f\"  â° SLA: {category['sla']}\")\n",
    "    \n",
    "    # KATMAN 3: Ã–nerilen Aksiyon\n",
    "    print(f\"\\nğŸ’¡ Ã–NERÄ°LEN AKSÄ°YON:\")\n",
    "    \n",
    "    if urgency_key == \"critical\":\n",
    "        print(f\"  ğŸš¨ DERHAL ESKALASÄ°YON GEREKTÄ°RÄ°YOR!\")\n",
    "        print(f\"  â†’ Senior destek ekibine yÃ¶nlendir\")\n",
    "        print(f\"  â†’ MÃ¼ÅŸteriyi 1 saat iÃ§inde ara\")\n",
    "    elif urgency_key == \"high\":\n",
    "        print(f\"  âš ï¸ Ã–NCELÄ°KLÄ° YANIT\")\n",
    "        print(f\"  â†’ {category['name']} ekibine ata\")\n",
    "        print(f\"  â†’ {category['sla']} iÃ§inde yanÄ±tla\")\n",
    "    else:\n",
    "        print(f\"  â„¹ï¸ STANDART Ä°ÅLEM\")\n",
    "        print(f\"  â†’ Otomatik yanÄ±t ÅŸablonu gÃ¶nder\")\n",
    "        print(f\"  â†’ Knowledge base'den Ã§Ã¶zÃ¼m Ã¶ner\")\n",
    "    \n",
    "    # ROI Hesaplama\n",
    "    manual_time = 15  # dakika\n",
    "    automated_time = 2  # dakika\n",
    "    time_saved = manual_time - automated_time\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ZAMAN TASARRUFU:\")\n",
    "    print(f\"  â€¢ Manuel Ä°ÅŸlem: {manual_time} dakika\")\n",
    "    print(f\"  â€¢ Otomatik Ä°ÅŸlem: {automated_time} dakika\")\n",
    "    print(f\"  â€¢ Tasarruf: {time_saved} dakika ({time_saved/manual_time*100:.0f}%)\")\n",
    "\n",
    "print(f\"\\n{'â•' * 90}\")\n",
    "print(f\"âœ… TÃœM TICKETLAR Ä°ÅLENDÄ°!\")\n",
    "print(f\"{'â•' * 90}\")\n",
    "print(f\"ğŸ“Š Ã–ZET Ä°STATÄ°STÄ°KLER:\")\n",
    "print(f\"  â€¢ Toplam Ticket: {len(support_tickets)}\")\n",
    "print(f\"  â€¢ Ä°ÅŸlem SÃ¼resi: {len(support_tickets) * 2} dakika (manuel: {len(support_tickets) * 15} dk)\")\n",
    "print(f\"  â€¢ Zaman Tasarrufu: {len(support_tickets) * 13} dakika\")\n",
    "print(f\"  â€¢ Verimlilik ArtÄ±ÅŸÄ±: %87\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d105ad0",
   "metadata": {},
   "source": [
    "### 8.3 ğŸ”§ Deployment: BERT'i Production'a Almak\n",
    "\n",
    "<div style=\"border-left: 5px solid #ff9800; background: linear-gradient(to right, #fff8e1, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "BERT'i gerÃ§ek sistemlere entegre etmek iÃ§in **3 kritik adÄ±m**:\n",
    "\n",
    "#### 1ï¸âƒ£ Model Optimizasyonu\n",
    "\n",
    "**Problem**: BERT Ã§ok bÃ¼yÃ¼k (110M params, 438MB)\n",
    "- Inference yavaÅŸ: 50-100ms/request\n",
    "- GPU memory: 2-4GB gerekir\n",
    "- Maliyet yÃ¼ksek\n",
    "\n",
    "**Ã‡Ã¶zÃ¼mler**:\n",
    "- ğŸ—œï¸ **Model Distillation**: DistilBERT (%40 kÃ¼Ã§Ã¼k, %60 hÄ±zlÄ±, %97 accuracy)\n",
    "- âš¡ **Quantization**: INT8/FP16 (2-4x hÄ±zlanma)\n",
    "- ğŸ”¥ **ONNX Runtime**: Cross-platform optimize\n",
    "- ğŸ“¦ **TorchScript**: Production-ready serialization\n",
    "\n",
    "#### 2ï¸âƒ£ Deployment Stratejileri\n",
    "\n",
    "| Strateji | KullanÄ±m | Avantajlar | Dezavantajlar |\n",
    "|----------|----------|------------|---------------|\n",
    "| **REST API** | Web apps, mobile | Kolay entegrasyon | Network latency |\n",
    "| **Batch Processing** | GÃ¼nlÃ¼k raporlar | Maliyet dÃ¼ÅŸÃ¼k | Real-time deÄŸil |\n",
    "| **Streaming** | Chat, real-time | DÃ¼ÅŸÃ¼k latency | KarmaÅŸÄ±k |\n",
    "| **Edge Deployment** | Mobile, IoT | Privacy, offline | Limited resources |\n",
    "\n",
    "#### 3ï¸âƒ£ Monitoring & Maintenance\n",
    "\n",
    "**Ä°zlenmesi Gerekenler**:\n",
    "- ğŸ“Š **Model Performance**: Accuracy, precision, recall\n",
    "- â±ï¸ **Latency**: p50, p95, p99 metrics\n",
    "- ğŸ’° **Cost**: GPU usage, API calls\n",
    "- ğŸ”„ **Data Drift**: Input distribution deÄŸiÅŸimi\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ—ï¸ Production Architecture\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"ğŸ“± Client Apps\"] --> B[\"ğŸŒ Load Balancer\"]\n",
    "    \n",
    "    B --> C1[\"ğŸ”¥ API Server 1\"]\n",
    "    B --> C2[\"ğŸ”¥ API Server 2\"]\n",
    "    B --> C3[\"ğŸ”¥ API Server 3\"]\n",
    "    \n",
    "    C1 --> D[\"ğŸ¤– BERT Model<br/>(DistilBERT)<br/>ONNX Runtime\"]\n",
    "    C2 --> D\n",
    "    C3 --> D\n",
    "    \n",
    "    D --> E[\"ğŸ’¾ Model Registry<br/>(MLflow, W&B)\"]\n",
    "    \n",
    "    D --> F[\"ğŸ“Š Monitoring<br/>(Prometheus, Grafana)\"]\n",
    "    \n",
    "    F --> G[\"ğŸ“ˆ Metrics\"]\n",
    "    F --> H[\"ğŸš¨ Alerts\"]\n",
    "    F --> I[\"ğŸ“‰ Logs\"]\n",
    "    \n",
    "    E --> J[\"ğŸ”„ CI/CD Pipeline<br/>(Auto-retrain)\"]\n",
    "    \n",
    "    J --> K{\"ğŸ“Š A/B Test<br/>New Model?\"}\n",
    "    \n",
    "    K -->|Better| L[\"âœ… Deploy New\"]\n",
    "    K -->|Worse| M[\"âŒ Keep Old\"]\n",
    "    \n",
    "    L --> D\n",
    "    \n",
    "    style A fill:#b3e5fc\n",
    "    style B fill:#e1bee7\n",
    "    style C1 fill:#c8e6c9\n",
    "    style C2 fill:#c8e6c9\n",
    "    style C3 fill:#c8e6c9\n",
    "    style D fill:#ffccbc\n",
    "    style E fill:#f8bbd0\n",
    "    style F fill:#fff9c4\n",
    "    style G fill:#a5d6a7\n",
    "    style H fill:#ffab91\n",
    "    style I fill:#ce93d8\n",
    "    style J fill:#81c784\n",
    "    style K fill:#ff9800\n",
    "    style L fill:#4caf50\n",
    "    style M fill:#f44336\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62c1f1",
   "metadata": {},
   "source": [
    "### 8.4 ğŸ’¡ Best Practices ve Ã–neriler\n",
    "\n",
    "<div style=\"border-left: 5px solid #4caf50; background: linear-gradient(to right, #e8f5e9, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "#### âœ… YAPILMASI GEREKENLER\n",
    "\n",
    "**Veri HazÄ±rlama**\n",
    "- ğŸ“Š **Dengeli veri seti**: Her sÄ±nÄ±ftan yeterli Ã¶rnek (min 100/sÄ±nÄ±f)\n",
    "- ğŸ” **Veri temizleme**: Spam, duplicate, hatalÄ± etiketleri Ã§Ä±kar\n",
    "- ğŸ“ˆ **Train/Val/Test split**: 80/10/10 veya 70/15/15\n",
    "- ğŸ”„ **Data augmentation**: Paraphrase, back-translation\n",
    "\n",
    "**Model EÄŸitimi**\n",
    "- ğŸ¯ **Transfer learning**: Pre-trained BERT'den baÅŸla\n",
    "- ğŸ“‰ **Learning rate**: 2e-5 to 5e-5 arasÄ±\n",
    "- ğŸ›‘ **Early stopping**: Validation loss izle\n",
    "- ğŸ’¾ **Checkpoint saving**: En iyi modeli sakla\n",
    "\n",
    "**DeÄŸerlendirme**\n",
    "- ğŸ“Š **Multiple metrics**: Accuracy, F1, Precision, Recall\n",
    "- ğŸ” **Confusion matrix**: Hangi sÄ±nÄ±flar karÄ±ÅŸÄ±yor?\n",
    "- ğŸ‘€ **Error analysis**: YanlÄ±ÅŸ tahminleri incele\n",
    "- ğŸ”„ **Cross-validation**: K-fold ile robust deÄŸerlendirme\n",
    "\n",
    "**Production**\n",
    "- âš¡ **Model optimization**: DistilBERT, quantization\n",
    "- ğŸ“ˆ **Monitoring**: Performance, latency, cost\n",
    "- ğŸ”„ **Continuous learning**: Periyodik re-train\n",
    "- ğŸ§ª **A/B testing**: Yeni modeli kademeli deploy et\n",
    "\n",
    "</div>\n",
    "\n",
    "#### âŒ YAPILMAMASI GEREKENLER\n",
    "\n",
    "<div style=\"border-left: 5px solid #f44336; background: linear-gradient(to right, #ffebee, #ffffff); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "\n",
    "**Veri ile Ä°lgili**\n",
    "- âŒ Ã‡ok az veri ile eÄŸitme (min 500-1000 Ã¶rnek)\n",
    "- âŒ Dengesiz veri setini gÃ¶z ardÄ± etme\n",
    "- âŒ Test setini gÃ¶rsel olarak kontrol etmeme\n",
    "- âŒ Data leakage (train'e test verisi karÄ±ÅŸmasÄ±)\n",
    "\n",
    "**Model ile Ä°lgili**\n",
    "- âŒ Ã‡ok yÃ¼ksek learning rate (3e-4+)\n",
    "- âŒ Ã‡ok fazla epoch (4+ epoch genelde overfitting)\n",
    "- âŒ Validation seti olmadan eÄŸitme\n",
    "- âŒ Random seed sabitlememe (reproducibility iÃ§in gerekli)\n",
    "\n",
    "**Production ile Ä°lgili**\n",
    "- âŒ Monitoring olmadan deploy etme\n",
    "- âŒ Fallback stratejisi olmadan canlÄ±ya alma\n",
    "- âŒ API rate limiting koymama\n",
    "- âŒ Model versioning yapmama\n",
    "\n",
    "</div>\n",
    "\n",
    "#### ğŸ“š Ã–ÄŸrenmeye Devam\n",
    "\n",
    "**Kaynaklar**:\n",
    "- ğŸ“– [BERT Paper](https://arxiv.org/abs/1810.04805) - Orijinal makale\n",
    "- ğŸ¤— [HuggingFace Docs](https://huggingface.co/docs) - Pratik Ã¶rnekler\n",
    "- ğŸ“º [Stanford CS224N](http://web.stanford.edu/class/cs224n/) - NLP kursu\n",
    "- ğŸ’» [Fine-tuning Examples](https://github.com/huggingface/transformers/tree/main/examples) - Code samples\n",
    "\n",
    "**Ä°leri Konular**:\n",
    "- ğŸš€ **RoBERTa**: BERT'in geliÅŸtirilmiÅŸ versiyonu\n",
    "- âš¡ **ALBERT**: Parameter-efficient BERT\n",
    "- ğŸ¯ **DeBERTa**: Disentangled attention\n",
    "- ğŸŒ **mBERT**: Multilingual BERT (100+ dil)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3566bae7",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 25px; border-radius: 15px; text-align: center; color: white; font-size: 20px; font-weight: bold; box-shadow: 0 4px 15px rgba(0,0,0,0.2); margin: 30px 0;\">\n",
    "    âœ… ADIM 8 TAMAMLANDI: GerÃ§ek DÃ¼nya YBS UygulamalarÄ± ğŸš€\n",
    "</div>\n",
    "\n",
    "**Bu adÄ±mda Ã¶ÄŸrendiklerimiz:**\n",
    "\n",
    "- ğŸ¢ **YBS Uygulama HaritasÄ±**: 4 ana kategori ve gerÃ§ek senaryolar\n",
    "- ğŸ’¼ **MÃ¼ÅŸteri Destek Otomasyonu**: 3 katmanlÄ± sistem ve ROI analizi\n",
    "- ğŸ”§ **Production Deployment**: Optimization, monitoring, architecture\n",
    "- ğŸ’¡ **Best Practices**: YapÄ±lmasÄ± ve yapÄ±lmamasÄ± gerekenler\n",
    "\n",
    "BERT ile artÄ±k **enterprise-level NLP Ã§Ã¶zÃ¼mleri** geliÅŸtirebilirsin! ğŸ‰\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 40px; border-radius: 20px; text-align: center; margin: 40px 0; box-shadow: 0 15px 40px rgba(0,0,0,0.3);\">\n",
    "    <h1 style=\"color: white; font-size: 48px; margin: 0; text-shadow: 3px 3px 6px rgba(0,0,0,0.4);\">\n",
    "        ğŸ“ TÃœM NOTEBOOK TAMAMLANDI! ğŸ‰\n",
    "    </h1>\n",
    "    <p style=\"color: rgba(255,255,255,0.95); font-size: 24px; margin: 20px 0 0 0; font-weight: 500;\">\n",
    "        8 AdÄ±mda BERT Mimarisini Kusursuz Ã–ÄŸrendin!\n",
    "    </p>\n",
    "    <p style=\"color: rgba(255,255,255,0.9); font-size: 18px; margin: 15px 0 0 0;\">\n",
    "        From Zero to Hero: WordPiece'den Production'a ğŸš€\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "#### ğŸ“Š Notebook Ä°statistikleri\n",
    "\n",
    "- âœ… **8 Ana BÃ¶lÃ¼m**: WordPiece â†’ Embeddings â†’ MLM â†’ NSP â†’ Fine-tuning â†’ Production\n",
    "- ğŸ’» **75+ Kod HÃ¼cresi**: Pratik Ã¶rnekler ve YBS uygulamalarÄ±\n",
    "- ğŸ“š **40+ Mermaid Diyagram**: GÃ¶rsel anlatÄ±m ve akÄ±ÅŸ ÅŸemalarÄ±\n",
    "- ğŸ¯ **GerÃ§ek Senaryolar**: E-ticaret, destek, analitik\n",
    "- ğŸ¢ **YBS OdaklÄ±**: Ä°ÅŸ dÃ¼nyasÄ±na hazÄ±r bilgiler\n",
    "\n",
    "#### ğŸ’ TeÅŸekkÃ¼rler!\n",
    "\n",
    "Bu notebook'u tamamladÄ±ÄŸÄ±n iÃ§in tebrikler! ArtÄ±k BERT mimarisini derinlemesine anlÄ±yor ve gerÃ§ek projelerde kullanabiliyorsun.\n",
    "\n",
    "**BaÅŸarÄ±lar dilerim!** ğŸŒŸ\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ“ **Not**: Bu notebook, AI Toolkit ve HuggingFace Transformers kÃ¼tÃ¼phanesi kullanÄ±larak oluÅŸturulmuÅŸtur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
